{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a282cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keybert in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from keybert) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from keybert) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from keybert) (1.24.4)\n",
      "Requirement already satisfied: rich>=10.4.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from keybert) (13.5.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from rich>=10.4.0->keybert) (2.15.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from rich>=10.4.0->keybert) (4.7.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (3.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.33.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from sentence-transformers>=0.3.8->keybert) (2.0.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.15.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.17.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.12.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2023.9.2)\n",
      "Requirement already satisfied: requests in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (23.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from tqdm->sentence-transformers>=0.3.8->keybert) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.3.3)\n",
      "Requirement already satisfied: click in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.1.7)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers>=0.3.8->keybert)\n",
      "  Using cached torch-2.0.1-cp38-cp38-win_amd64.whl (172.4 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0\n",
      "    Uninstalling torch-2.0.0:\n",
      "      Successfully uninstalled torch-2.0.0\n",
      "Successfully installed torch-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformer-smaller-training-vocab 0.3.2 requires torch!=2.0.1,<3.0.0,>=1.8.0, but you have torch 2.0.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (0.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from flair) (2.8.2)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from flair) (2.0.1)\n",
      "Requirement already satisfied: gensim>=3.8.0 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (4.3.2)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from flair) (4.66.1)\n",
      "Requirement already satisfied: segtok>=1.5.7 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (1.5.11)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (3.7.3)\n",
      "Requirement already satisfied: mpld3==0.3 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from flair) (1.3.1)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (2.1.0)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (1.2.14)\n",
      "Requirement already satisfied: hyperopt>=0.2.7 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (0.2.7)\n",
      "Requirement already satisfied: boto3 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (1.28.53)\n",
      "Requirement already satisfied: transformers[sentencepiece]>=4.18.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from flair) (4.33.2)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (0.3.4)\n",
      "Requirement already satisfied: regex in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from flair) (2023.8.8)\n",
      "Requirement already satisfied: tabulate in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (0.9.0)\n",
      "Requirement already satisfied: langdetect in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (1.0.9)\n",
      "Requirement already satisfied: lxml in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from flair) (4.9.2)\n",
      "Requirement already satisfied: ftfy in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (6.1.1)\n",
      "Requirement already satisfied: janome in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (0.5.0)\n",
      "Requirement already satisfied: gdown==4.4.0 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (4.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from flair) (0.17.2)\n",
      "Requirement already satisfied: conllu>=4.0 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (4.5.3)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (10.1.0)\n",
      "Requirement already satisfied: wikipedia-api in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (0.6.0)\n",
      "Requirement already satisfied: pptree in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (3.1)\n",
      "Requirement already satisfied: pytorch-revgrad in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (0.2.0)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.1 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from flair) (0.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from gdown==4.4.0->flair) (3.12.4)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from gdown==4.4.0->flair) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from gdown==4.4.0->flair) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from gdown==4.4.0->flair) (4.12.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from bpemb>=0.3.2->flair) (1.24.4)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from bpemb>=0.3.2->flair) (0.1.99)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from deprecated>=1.2.4->flair) (1.15.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from gensim>=3.8.0->flair) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from gensim>=3.8.0->flair) (6.4.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (2023.9.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (23.1)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from hyperopt>=0.2.7->flair) (3.1)\n",
      "Requirement already satisfied: future in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from hyperopt>=0.2.7->flair) (0.18.3)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from hyperopt>=0.2.7->flair) (2.2.1)\n",
      "Requirement already satisfied: py4j in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from hyperopt>=0.2.7->flair) (0.10.9.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib>=2.2.3->flair) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib>=2.2.3->flair) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib>=2.2.3->flair) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from matplotlib>=2.2.3->flair) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib>=2.2.3->flair) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from matplotlib>=2.2.3->flair) (5.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (3.2.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from tqdm>=4.26.0->flair) (0.4.6)\n",
      "Collecting torch!=1.8,>=1.5.0 (from flair)\n",
      "  Using cached torch-2.0.0-cp38-cp38-win_amd64.whl (172.3 MB)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from transformers[sentencepiece]>=4.18.0->flair) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from transformers[sentencepiece]>=4.18.0->flair) (0.3.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from transformers[sentencepiece]>=4.18.0->flair) (4.24.3)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.53 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from boto3->flair) (1.31.53)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from boto3->flair) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from boto3->flair) (0.6.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from botocore<1.32.0,>=1.31.53->boto3->flair) (1.26.16)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=2.2.3->flair) (3.11.0)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from transformers[sentencepiece]>=4.18.0->flair) (0.23.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from beautifulsoup4->gdown==4.4.0->flair) (2.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from jinja2->torch!=1.8,>=1.5.0->flair) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\liber\\appdata\\roaming\\python\\python38\\site-packages (from requests[socks]->gdown==4.4.0->flair) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from accelerate>=0.20.3->transformers[sentencepiece]>=4.18.0->flair) (5.9.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\liber\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.15.2 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert\n",
    "!pip install --user flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0c00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from keybert import KeyBERT\n",
    "from flair.embeddings import TransformerDocumentEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef937148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_writer</th>\n",
       "      <th>date_writer</th>\n",
       "      <th>title</th>\n",
       "      <th>book_writer</th>\n",
       "      <th>book_company</th>\n",
       "      <th>book_date</th>\n",
       "      <th>report_text</th>\n",
       "      <th>is_classic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>조장환</td>\n",
       "      <td>2023/09/21</td>\n",
       "      <td>노르웨이의 숲</td>\n",
       "      <td>무라카미 하루키</td>\n",
       "      <td>민음사</td>\n",
       "      <td>2013/09/02</td>\n",
       "      <td>\"그때 나는 보잉 747기기 좌석에 앉아있었다.\" 1982년에 자신을 회...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>갱근</td>\n",
       "      <td>2023/09/20</td>\n",
       "      <td>역행자 (돈·시간·운명으로부터 완전한 자유를 얻는 7단계 인생 공략집)</td>\n",
       "      <td>자청</td>\n",
       "      <td>웅진지식하우스</td>\n",
       "      <td>2022/05/30</td>\n",
       "      <td>이 책은 제가 경제에 대해 아는것이 없다보니 알아보려고 이것저것 찾아보다가제가...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>예봄이</td>\n",
       "      <td>2023/09/20</td>\n",
       "      <td>덧니가 보고 싶어 (정세랑 장편소설)</td>\n",
       "      <td>정세랑</td>\n",
       "      <td>난다</td>\n",
       "      <td>2019/11/05</td>\n",
       "      <td>개강이 실감 나지 않았던 지난 3주를 흘려보내고 나니 인제야 학교 다니는 일상...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>떠다니는 윤슬</td>\n",
       "      <td>2023/09/20</td>\n",
       "      <td>파친코 1~2권 세트 (전2권, 개정판│애플TV 드라마 '24 May 2018파친코...</td>\n",
       "      <td>이민진</td>\n",
       "      <td>인플루엔셜</td>\n",
       "      <td>2022/08/25</td>\n",
       "      <td>파친코는 일본의 도박성 대중오락이다. 파친코라는 이름은 게임할 때 생기는 마...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아우룸</td>\n",
       "      <td>2023/09/20</td>\n",
       "      <td>생의 한가운데</td>\n",
       "      <td>루이제 린저</td>\n",
       "      <td>문예출판사</td>\n",
       "      <td>1998/01/20</td>\n",
       "      <td>생을 다루는 예술 작품은 참으로 많다. 톨스토이의 [이반 일리치의 죽음]이 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  report_writer date_writer  \\\n",
       "0           조장환  2023/09/21   \n",
       "1            갱근  2023/09/20   \n",
       "2           예봄이  2023/09/20   \n",
       "3       떠다니는 윤슬  2023/09/20   \n",
       "4           아우룸  2023/09/20   \n",
       "\n",
       "                                               title book_writer book_company  \\\n",
       "0                                            노르웨이의 숲    무라카미 하루키          민음사   \n",
       "1            역행자 (돈·시간·운명으로부터 완전한 자유를 얻는 7단계 인생 공략집)          자청      웅진지식하우스   \n",
       "2                               덧니가 보고 싶어 (정세랑 장편소설)         정세랑           난다   \n",
       "3  파친코 1~2권 세트 (전2권, 개정판│애플TV 드라마 '24 May 2018파친코...         이민진        인플루엔셜   \n",
       "4                                            생의 한가운데      루이제 린저        문예출판사   \n",
       "\n",
       "    book_date                                        report_text is_classic  \n",
       "0  2013/09/02        \"그때 나는 보잉 747기기 좌석에 앉아있었다.\" 1982년에 자신을 회...        NaN  \n",
       "1  2022/05/30     이 책은 제가 경제에 대해 아는것이 없다보니 알아보려고 이것저것 찾아보다가제가...        NaN  \n",
       "2  2019/11/05     개강이 실감 나지 않았던 지난 3주를 흘려보내고 나니 인제야 학교 다니는 일상...        NaN  \n",
       "3  2022/08/25      파친코는 일본의 도박성 대중오락이다. 파친코라는 이름은 게임할 때 생기는 마...        NaN  \n",
       "4  1998/01/20      생을 다루는 예술 작품은 참으로 많다. 톨스토이의 [이반 일리치의 죽음]이 ...        NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./fivecart_total_pre.csv\", encoding='utf-8')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4ac5f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_writer</th>\n",
       "      <th>date_writer</th>\n",
       "      <th>title</th>\n",
       "      <th>book_writer</th>\n",
       "      <th>book_company</th>\n",
       "      <th>book_date</th>\n",
       "      <th>report_text</th>\n",
       "      <th>is_classic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>조장환</td>\n",
       "      <td>2023/09/21</td>\n",
       "      <td>노르웨이의 숲</td>\n",
       "      <td>무라카미 하루키</td>\n",
       "      <td>민음사</td>\n",
       "      <td>2013/09/02</td>\n",
       "      <td>\"그때 나는 보잉 747기기 좌석에 앉아있었다.\" 1982년에 자신을 회...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>갱근</td>\n",
       "      <td>2023/09/20</td>\n",
       "      <td>역행자 (돈·시간·운명으로부터 완전한 자유를 얻는 7단계 인생 공략집)</td>\n",
       "      <td>자청</td>\n",
       "      <td>웅진지식하우스</td>\n",
       "      <td>2022/05/30</td>\n",
       "      <td>이 책은 제가 경제에 대해 아는것이 없다보니 알아보려고 이것저것 찾아보다가제가...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>예봄이</td>\n",
       "      <td>2023/09/20</td>\n",
       "      <td>덧니가 보고 싶어 (정세랑 장편소설)</td>\n",
       "      <td>정세랑</td>\n",
       "      <td>난다</td>\n",
       "      <td>2019/11/05</td>\n",
       "      <td>개강이 실감 나지 않았던 지난 3주를 흘려보내고 나니 인제야 학교 다니는 일상...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>떠다니는 윤슬</td>\n",
       "      <td>2023/09/20</td>\n",
       "      <td>파친코 1~2권 세트 (전2권, 개정판│애플TV 드라마 '24 May 2018파친코...</td>\n",
       "      <td>이민진</td>\n",
       "      <td>인플루엔셜</td>\n",
       "      <td>2022/08/25</td>\n",
       "      <td>파친코는 일본의 도박성 대중오락이다. 파친코라는 이름은 게임할 때 생기는 마...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아우룸</td>\n",
       "      <td>2023/09/20</td>\n",
       "      <td>생의 한가운데</td>\n",
       "      <td>루이제 린저</td>\n",
       "      <td>문예출판사</td>\n",
       "      <td>1998/01/20</td>\n",
       "      <td>생을 다루는 예술 작품은 참으로 많다. 톨스토이의 [이반 일리치의 죽음]이 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21862</th>\n",
       "      <td>icaros</td>\n",
       "      <td>2009/11/02</td>\n",
       "      <td>사치의 나라 럭셔리 코리아</td>\n",
       "      <td>김난도</td>\n",
       "      <td>미래의창</td>\n",
       "      <td>2007/03/29</td>\n",
       "      <td>사치의 나라 럭셔리 코리아   김남도 지음 출판사 : 미래의 창 2007년  ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21863</th>\n",
       "      <td>icaros</td>\n",
       "      <td>2009/11/02</td>\n",
       "      <td>렉스</td>\n",
       "      <td>캐슬린 루이스</td>\n",
       "      <td>Human&amp;Books</td>\n",
       "      <td>2008/12/05</td>\n",
       "      <td>렉스 / 한 서번트 이야기 / REX : A Mother, Her Autist...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21864</th>\n",
       "      <td>icaros</td>\n",
       "      <td>2009/11/02</td>\n",
       "      <td>나의 아들 달라이라마</td>\n",
       "      <td>캐둡된돕</td>\n",
       "      <td>한언</td>\n",
       "      <td>2000/11/25</td>\n",
       "      <td>나의 아들 달라이라마 ( DALAI LAMA MY SON )    캐둡된둡 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21865</th>\n",
       "      <td>불산</td>\n",
       "      <td>2009/11/02</td>\n",
       "      <td>바리데기</td>\n",
       "      <td>황석영</td>\n",
       "      <td>창비</td>\n",
       "      <td>2007/07/13</td>\n",
       "      <td>바리데기 -분쟁과 굶주림 속에 고통받는 모든 이들을 위한 굿-   아직 한 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21866</th>\n",
       "      <td>로모</td>\n",
       "      <td>2009/11/02</td>\n",
       "      <td>우뇌좌뇌 리더십</td>\n",
       "      <td>메리 루 데코스터드</td>\n",
       "      <td>마젤란</td>\n",
       "      <td>2009/09/28</td>\n",
       "      <td>\" 우뇌는 미래에 촛점을 두는 반면, 좌뇌는 지금의 현실에 주목한다...\"보통...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21867 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_writer date_writer  \\\n",
       "0               조장환  2023/09/21   \n",
       "1                갱근  2023/09/20   \n",
       "2               예봄이  2023/09/20   \n",
       "3           떠다니는 윤슬  2023/09/20   \n",
       "4               아우룸  2023/09/20   \n",
       "...             ...         ...   \n",
       "21862        icaros  2009/11/02   \n",
       "21863        icaros  2009/11/02   \n",
       "21864        icaros  2009/11/02   \n",
       "21865            불산  2009/11/02   \n",
       "21866            로모  2009/11/02   \n",
       "\n",
       "                                                   title book_writer  \\\n",
       "0                                                노르웨이의 숲    무라카미 하루키   \n",
       "1                역행자 (돈·시간·운명으로부터 완전한 자유를 얻는 7단계 인생 공략집)          자청   \n",
       "2                                   덧니가 보고 싶어 (정세랑 장편소설)         정세랑   \n",
       "3      파친코 1~2권 세트 (전2권, 개정판│애플TV 드라마 '24 May 2018파친코...         이민진   \n",
       "4                                                생의 한가운데      루이제 린저   \n",
       "...                                                  ...         ...   \n",
       "21862                                     사치의 나라 럭셔리 코리아         김난도   \n",
       "21863                                                 렉스     캐슬린 루이스   \n",
       "21864                                        나의 아들 달라이라마        캐둡된돕   \n",
       "21865                                               바리데기         황석영   \n",
       "21866                                           우뇌좌뇌 리더십  메리 루 데코스터드   \n",
       "\n",
       "      book_company   book_date  \\\n",
       "0              민음사  2013/09/02   \n",
       "1          웅진지식하우스  2022/05/30   \n",
       "2               난다  2019/11/05   \n",
       "3            인플루엔셜  2022/08/25   \n",
       "4            문예출판사  1998/01/20   \n",
       "...            ...         ...   \n",
       "21862         미래의창  2007/03/29   \n",
       "21863  Human&Books  2008/12/05   \n",
       "21864           한언  2000/11/25   \n",
       "21865           창비  2007/07/13   \n",
       "21866          마젤란  2009/09/28   \n",
       "\n",
       "                                             report_text is_classic  \n",
       "0            \"그때 나는 보잉 747기기 좌석에 앉아있었다.\" 1982년에 자신을 회...        NaN  \n",
       "1         이 책은 제가 경제에 대해 아는것이 없다보니 알아보려고 이것저것 찾아보다가제가...        NaN  \n",
       "2         개강이 실감 나지 않았던 지난 3주를 흘려보내고 나니 인제야 학교 다니는 일상...        NaN  \n",
       "3          파친코는 일본의 도박성 대중오락이다. 파친코라는 이름은 게임할 때 생기는 마...        NaN  \n",
       "4          생을 다루는 예술 작품은 참으로 많다. 톨스토이의 [이반 일리치의 죽음]이 ...        NaN  \n",
       "...                                                  ...        ...  \n",
       "21862     사치의 나라 럭셔리 코리아   김남도 지음 출판사 : 미래의 창 2007년  ...        NaN  \n",
       "21863     렉스 / 한 서번트 이야기 / REX : A Mother, Her Autist...        NaN  \n",
       "21864      나의 아들 달라이라마 ( DALAI LAMA MY SON )    캐둡된둡 ...        NaN  \n",
       "21865      바리데기 -분쟁과 굶주림 속에 고통받는 모든 이들을 위한 굿-   아직 한 ...        NaN  \n",
       "21866     \" 우뇌는 미래에 촛점을 두는 반면, 좌뇌는 지금의 현실에 주목한다...\"보통...        NaN  \n",
       "\n",
       "[21867 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5ad724e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    생을 다루는 예술 작품은 참으로 많다. 톨스토이의 [이반 일리치의 죽음]이 가장 심도깊게 생의 의미를 다룬 작품이라 할 수 있고, 이외에도 무라카미 하루키의 [노르웨이의 숲], 양귀자의 [모순], 헤르만 헤세의 [싯다르타]나 [데미안], 로맹 가리의 [자기 앞의 생], 좀 변칙적이긴 하나 아인 랜드의 [파운틴헤드] 등을 삶의 의미를 파헤치는 문학 작품의 예시로 들 수 있을 것이다. 애초에 예술이란 것이 삶의 어느 구석에서든 그 의미가 무엇인가를 고찰하는 것과 절대로 무관할 수는 없는 노릇이기에 모든 예술 작품은 곧 삶을 되새기는 것이라고 요약할 수 있겠으나, 그중에서도 위에 언급한 소설들처럼 직접적으로 생을 중심 주제로 제시하고 전개해나가는 부류들은 나름의 장르를 형성하고 있다고 볼 수 있다. 이들 소설은 기본적으로 생애라는 것에서 인간이 느끼는 방황을 제시하고, 그 방황에 해답은 없다고 결론 내리는 작품도 있고 방황에 굴복하여 패배감이 스며든 해답을 내리는 작품도 있고 방황을 극복하고 때려잡을 작가 고유의 완전한 해답을 제시하는 작품도 있다. <생의 한가운데>는 이중에서 일종의 굴복적인 해답을 제시하는 갈래로 분류될 수 있을 것이다.   이 소설은 니나라는 중심 주인공이 있고 그녀를 관찰하는 언니의 시점에서 줄거리가 전개된다. 니나가 작중 시점 37살에 이르기까지의 인생 항로를 그녀가 10대일 때부터 긴밀한 관계를 맺어온 슈타인이라는 약 20살 연상의 남자의 일기를 통해 언니는 훑게 되는데, 중간중간 니나가 쓴 자전적 소설이 삽입되어 그녀의 인생을 빗대어 말해주기도 하고 슈타인의 일기뿐만 아니라 니나의 편지같은 다른 글 형식으로도 니나라는 인물의 삶과 인간상을 형성한다. 그럼으로써 소설 내내 드러나는 니나의 두드러진 특성이 나오는데, 니나는 근본적으로 인간의 부유하는 욕망을 모조리 긍정하려는 인간이라는 점이다. 인간은 참으로 다방면의 욕구를 가지고 있고 많은 경우에 서로 모순되고 상충되는 욕망들까지 동시에 여러개를 지닐 수가 있는 존재다. 간단하게는 다이어트를 원하면서도 치킨을 먹고 싶고, 심각하게는 저 사람과 결혼하고 싶지만 아이는 다른 사람과 갖고 싶은 경우도 충분히 있을 수 있다. 여기서 대다수의 사람들은 하나를 포기하고 하나를 선택한다. 하지만 그러지 못하고 불륜을 저지르거나 다이어트를 실패하는 경우도 수두룩하다. 이런 사람들은 인간으로서 어딘가 잘못됐기 때문에 이러한 모순에 처해지는 것일까? 이런 지점에서 니나는 인간은 결국 짐승이기 때문에 상반되는 욕망들에서 무언가를 선택하는 것은 매우 거짓되고 인위적인 행위이며, 그 모든 욕망들을 최선을 다해서 살아내는 것만이 생을 온전히 느낄 수 있는 유일한 방법임을 역설한다. 니나의 언니가 니나의 삶에 부러움과 유혹을 느끼면서도 이해가 안되는 두려움과 답답함을 가지는 것도 이런 맥락에서다. 20세기 중반의 독일 여성으로서 안정적인 남편을 선택하여 무료하지만 안온한 삶을 누릴 기회가 니나에게 무수히 있었음에도 니나는 어떠한 기회도 확정시키지 않은 채 버리고, 정해진 삶의 형태 없이 그때 그때 자신의 본능이 이끄는대로 주위 환경을 송두리째 바꿔버리고, 결국에 작가 루이제 린저가 말하는 야만에 끌리는 여자의 본능적 특성으로 어리석은 남편을 만나 결혼하고 금방 이혼하지만 애가 생겨버리고, 어떠한 직업도 원하지 않으며 그나마 자아의 탐색과 연결되는 글짓기로 생업을 이어나가는 니나의 모습이 언니로서는 한심하면서도 격정적이고 동정이 되면서도 비웃고 싶어지는 행각이었을 것이다.   결론적으로 작가는 니나를 인간이 취할 수 있는 가장 진실된 모습으로 그려내면서 소설을 끝마친다. 그리고 나는 작가의 시선이 내 삶에 전혀 들어맞지 않음을 발견한다. 허나 니나의 짐승적 인간 면모에 대한 집념어린 추구는 그녀에게 있어서는 진실된 자세였음을 이해한다. 내가 짐승이라는 어휘로 니나를 서술하는 이유는 그녀가 자신의 순간순간의 충동에 맞서게 해주는 인간의 인위적 판단 능력을 매우 무시하면서 마치 날 것의 욕구를 그대로 풀며 살아가는 짐승들과 비슷한 태도를 보여주기 때문이다. 이런 태도가 들춰내는 좋은 점들도 분명 있다. 특히 니나의 언니의 껍데기같은 결혼생활에 대한 근본적 불안을 인식하게 해준다거나 하는 점에서 니나의 태도는 어떤 사람들에게는 우러러볼 수 있는 긍정적 효과도 많이 가지고 있음을 인지한다. 허나 나는 인간의 사물을 멋대로 재단하는 논리력, 현실에 존재않는 것을 꾸며내는 상상력, 스스로가 그릇되다고 여기는 충동을 억제하고 소멸시킬 줄 아는 강제력, 이러한 인위적인 인간 이성의 부산물들을 매우 좋아하고 그것들로 인해 살아가기에 니나의 삶의 방식을 이해하되 따라할 필요는 없음을 느낀다. 나는 종국에 인간의 극복과 완전한 성장을 믿는다. [파운틴헤드], [싯다르타], 무엇보다도 [이반 일리치의 죽음]에 삶의 지침을 느끼는 이유는 그러한 인간의 비루한 짐승적 본능에 대한 완전한 극복과 초월을 노래하기 때문이다. 허나 니나의 삶에선 이런 가치들이 거짓된 것이기에, 슈타인과도 끝끝내 맞지 않는 부품이었으며 그러한 영원한 어긋남을 인정하는 것이 생의 깨달음이며 인간적 원숙의 경지라고 인식한다. 인간의 본성은 극복하거나 개조하거나 반성할 필요없이 고통과 슬픔 잘못 모두 그대로 밀고나가는 것이 진실 그자체의 생이라는 말을 한다. 하지만 나는 언제나 이것보다는 생을 대하는 더 나은 방법이 존재함을 위의 세 권의 책들로 인해 강렬하게 깨닫는다. 그리고 <생의 한가운데>의 문체는 나쁠 것도 좋을 것도 없는 평범한 문체였기에 문학적으로 감명받을 구석은 많이 없었다.   '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = data['report_text'][4]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b1cf9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2726"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['report_text'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본 키버트 라이브러리 제공 모델로 시도, unigram, bigram, trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b8f0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellist = ['all-mpnet-base-v2', 'distiluse-base-multilingual-cased-v1', 'klue/roberta-base', 'klue/roberta-small', 'klue/roberta-large', 'klue/bert-base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d8a792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7590646f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./kw_model_base.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(kw_model, './kw_model_base.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "050daf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./kw_model_all-mpnet-base-v2.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model_0 = KeyBERT(modellist[0])\n",
    "joblib.dump(kw_model_0, './kw_model_all-mpnet-base-v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6712ebdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./kw_model_distiluse-base-multilingual-cased-v1.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model_1 = KeyBERT(modellist[1])\n",
    "joblib.dump(kw_model_1, './kw_model_distiluse-base-multilingual-cased-v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5ea3782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./kw_model_klue_roberta-base.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model_2 = KeyBERT(TransformerDocumentEmbeddings(modellist[2]))\n",
    "joblib.dump(kw_model_2, './kw_model_klue_roberta-base.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16658a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./kw_model_klue_roberta-small.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model_3 = KeyBERT(TransformerDocumentEmbeddings(modellist[3]))\n",
    "joblib.dump(kw_model_3, './kw_model_klue_roberta-small.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "073b7177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████| 375/375 [00:00<00:00, 53.6kB/s]\n",
      "C:\\Users\\liber\\anaconda3\\envs\\fiveCart\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\liber\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████| 248k/248k [00:01<00:00, 189kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|███████████████████████████████████████████| 752k/752k [00:01<00:00, 446kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████| 173/173 [00:00<00:00, 34.6kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████| 547/547 [00:00<00:00, 118kB/s]\n",
      "Downloading model.safetensors: 100%|██████████████████████████████████████████████| 1.35G/1.35G [13:47<00:00, 1.63MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./kw_model_klue_roberta-large.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model_4 = KeyBERT(TransformerDocumentEmbeddings(modellist[4]))\n",
    "joblib.dump(kw_model_4, './kw_model_klue_roberta-large.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a4b27de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./kw_model_klue_bert-base.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model_5 = KeyBERT(TransformerDocumentEmbeddings(modellist[5]))\n",
    "joblib.dump(kw_model_4, './kw_model_klue_bert-base.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3177d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('./kw_model_base.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6936a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13.4 s\n",
      "Wall time: 9.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kw_model = loaded_model\n",
    "keywords_1 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "keywords_2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "keywords_3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bebe933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.8 s\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kw_model = KeyBERT()\n",
    "keywords_1 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "keywords_2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "keywords_3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "092aff81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이성의', 0.506), ('일리치의', 0.5), ('인물의', 0.4869), ('다방면의', 0.4782), ('일종의', 0.4704)]\n",
      "[('인간 이성의', 0.5413), ('인간의 극복과', 0.5398), ('인식한다 인간의', 0.5259), ('구석에서든 의미가', 0.5255), ('종국에 인간의', 0.5162)]\n",
      "[('인간은 참으로 다방면의', 0.5761), ('데미안 로맹 가리의', 0.5497), ('형식으로도 니나라는 인물의', 0.549), ('생의 한가운데 문체는', 0.5473), ('생의 의미를 다룬', 0.5458)]\n"
     ]
    }
   ],
   "source": [
    "print(keywords_1)\n",
    "print(keywords_2)\n",
    "print(keywords_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sbert-net performance sentence embedding 가장 높은 모델로 시도, unigram, bigram, trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7280d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 27s\n",
      "Wall time: 48.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelname = 'all-mpnet-base-v2'\n",
    "kw_model = KeyBERT(modelname)\n",
    "keywords_1 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "keywords_2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "keywords_3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9600e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('구석에서든', 0.7151), ('순간순간의', 0.6937), ('부산물들을', 0.6759), ('굴복적인', 0.6678), ('구석은', 0.6659)]\n",
      "[('종국에 인간의', 0.7426), ('자신의 순간순간의', 0.7413), ('한가운데 문체는', 0.7407), ('구석에서든 의미가', 0.7394), ('한가운데 이중에서', 0.737)]\n",
      "[('종국에 인간의 극복과', 0.7548), ('나는 종국에 인간의', 0.7532), ('그녀가 자신의 순간순간의', 0.7488), ('무언가를 선택하는 것은', 0.7462), ('순간순간의 충동에 맞서게', 0.7453)]\n"
     ]
    }
   ],
   "source": [
    "print(keywords_1)\n",
    "print(keywords_2)\n",
    "print(keywords_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fbd70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sbert-net 다국어 모델로 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e043c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22.1 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelname = 'distiluse-base-multilingual-cased-v1'\n",
    "kw_model = KeyBERT(modelname)\n",
    "keywords_1 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "keywords_2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "keywords_3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf18d36b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('예술이란', 0.3257), ('작품의', 0.3041), ('작품이라', 0.2935), ('예술', 0.2833), ('작품은', 0.2721)]\n",
      "[('예술 작품은', 0.3762), ('애초에 예술이란', 0.3645), ('다룬 작품이라', 0.3627), ('다루는 예술', 0.3605), ('예술이란 것이', 0.3405)]\n",
      "[('생을 다루는 예술', 0.4942), ('다루는 예술 작품은', 0.4223), ('작품도 있다 생의', 0.4176), ('예술 작품은 참으로', 0.407), ('예술 작품은 삶을', 0.3922)]\n"
     ]
    }
   ],
   "source": [
    "print(keywords_1)\n",
    "print(keywords_2)\n",
    "print(keywords_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#klue/roberta-base 모델로 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f42f20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_b = TransformerDocumentEmbeddings('klue/roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2bd063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 53s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kw_model = KeyBERT(model=roberta_b)\n",
    "keywords_1 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "keywords_2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "keywords_3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16b48d6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('점이다', 0.9655), ('일기뿐만', 0.9653), ('작품이라', 0.9649), ('것은', 0.9646), ('것이다', 0.9644)]\n",
      "[('것이다 결론적으로', 0.9715), ('때문이다 이런', 0.9686), ('살아가기에 니나의', 0.967), ('있다 이들', 0.9669), ('슈타인의 일기뿐만', 0.9667)]\n",
      "[('것이다 결론적으로 작가는', 0.9708), ('때문이다 이런 태도가', 0.9699), ('행각이었을 것이다 결론적으로', 0.9695), ('것이다 소설은 니나라는', 0.9689), ('때문이다 허나 니나의', 0.9687)]\n"
     ]
    }
   ],
   "source": [
    "print(keywords_1)\n",
    "print(keywords_2)\n",
    "print(keywords_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f263d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#klue/roberta-small 모델로 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76faa3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_s = TransformerDocumentEmbeddings('klue/roberta-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f555f2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 11s\n",
      "Wall time: 40.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kw_model = KeyBERT(model=roberta_s)\n",
    "keywords_1 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "keywords_2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "keywords_3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cce1003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('예술이란', 0.789), ('있어서는', 0.787), ('변칙적이긴', 0.7827), ('그중에서도', 0.7827), ('형식으로도', 0.7797)]\n",
      "[('니나의 편지같은', 0.8232), ('인간상을 형성한다', 0.8228), ('방법임을 역설한다', 0.8212), ('집념어린 추구는', 0.8181), ('형식으로도 니나라는', 0.8159)]\n",
      "[('삶과 인간상을 형성한다', 0.847), ('소설은 기본적으로 생애라는', 0.8468), ('소설들처럼 직접적으로 생을', 0.842), ('대한 집념어린 추구는', 0.8405), ('진실된 자세였음을 이해한다', 0.8399)]\n"
     ]
    }
   ],
   "source": [
    "print(keywords_1)\n",
    "print(keywords_2)\n",
    "print(keywords_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ca8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#klue/klue/bert-base 모델로 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f83c3696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████| 289/289 [00:00<00:00, 72.1kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████| 425/425 [00:00<00:00, 85.7kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████████████████████████████████████| 248k/248k [00:00<00:00, 1.18MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████████████████████████████████████| 495k/495k [00:00<00:00, 9.57MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████| 125/125 [00:00<00:00, 11.2kB/s]\n",
      "Downloading model.safetensors: 100%|████████████████████████████████████████████████| 445M/445M [00:12<00:00, 35.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "bert_b = TransformerDocumentEmbeddings('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6da4882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 24s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kw_model = KeyBERT(model=bert_b)\n",
    "keywords_1 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "keywords_2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "keywords_3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52dd9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_roberta_large = joblib.load('./kw_model_klue_roberta-large.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab0a5c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9min 17s\n",
      "Wall time: 5min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kw_model = loaded_model_roberta_large\n",
    "keywords_1 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "keywords_2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "keywords_3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8126da08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('37살에', 0.9653), ('슈타인이라는', 0.9648), ('격정적이고', 0.9646), ('변칙적이긴', 0.9643), ('소설들처럼', 0.9636)]\n",
      "[('점이다 인간은', 0.969), ('것이다 결론적으로', 0.9687), ('것이다 애초에', 0.9685), ('슈타인이라는 20살', 0.9667), ('시점 37살에', 0.9661)]\n",
      "[('것이다 애초에 예술이란', 0.9734), ('인간이라는 점이다 인간은', 0.9713), ('행각이었을 것이다 결론적으로', 0.9713), ('있을 것이다 소설은', 0.9708), ('때문이다 이런 태도가', 0.9686)]\n"
     ]
    }
   ],
   "source": [
    "print(keywords_1)\n",
    "print(keywords_2)\n",
    "print(keywords_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab918568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_value_mean(keywords):\n",
    "    res = 0\n",
    "    for i in keywords:\n",
    "        res += i[1]\n",
    "    return res/len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "844e0e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97108"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_value_mean(keywords_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e0bf50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_doc_ext(data):\n",
    "    cnt = len(data)\n",
    "    rand_list = []\n",
    "    to10 = 0\n",
    "    while to10<10:\n",
    "        n = random.randrange(0, cnt)\n",
    "        if(n in rand_list):\n",
    "            continue\n",
    "        else:\n",
    "            rand_list.append(n)\n",
    "            to10+=1     \n",
    "    doc_list = [[i for j in range(2)] for i in rand_list]\n",
    "    j=0\n",
    "    for i in rand_list:\n",
    "        doc_list[j][1] = data.loc[i,'report_text']\n",
    "        j+=1\n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f03a057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyBERT_model(modelname, doc):\n",
    "    start = time.time()\n",
    "    kw_model = KeyBERT(model=modelname)\n",
    "    keywords_1 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "    keywords_2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "    keywords_3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=None)\n",
    "    print(keywords_1)\n",
    "    print(keywords_2)\n",
    "    print(keywords_3)\n",
    "    print(f\"{time.time()-start:.4f} sec\") # 수행시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3dcd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyBERT_model_whole(model, doc):\n",
    "    start = time.time()\n",
    "    kw_model = model\n",
    "    keywords_1 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "    keywords_2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "    keywords_3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=None)\n",
    "    print(keywords_1)\n",
    "    print(\"keywords_1:\", cos_value_mean(keywords_1))\n",
    "    print(keywords_2)\n",
    "    print(\"keywords_2:\", cos_value_mean(keywords_2))\n",
    "    print(keywords_3)\n",
    "    print(\"keywords_3:\", cos_value_mean(keywords_3))\n",
    "    print(f\"{time.time()-start:.4f} sec\") # 수행시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3146b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##랜덤 문서 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fd426e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = random_doc_ext(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d9d77b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8385,\n",
       "  '    단순한 암기보다는 전후 관계를 파악하거나 왜 그럴 수밖에 없는 지를 논리적으로 따져보며 공부했을 때 보다 명료하고 오래 기억을 할 수 있다. 더 나아가면 아직 배우지 않은 부분에 대해서 예측을 할 수 있는 수준까지 있는데, 특히 역사부문에서 두드러지게 나타나는 특성이다. 우리는 흔히 ‘역사를 통해 배운다.’ 라는 말을 하고는 하는데 오늘날까지의 발자취를 돌아보며 현재를 이해하고, 또 미래까지 엿볼 수 있다는 기대감이 깃들어있다.     우리가 가장 궁금해 하는 미래는 무엇보다 우리 자신이기 때문에 인류의 역사는 언제나 관심의 대상이었다. 그러나 우리는 인간 그 자체보다는 문명의 발전에 치우쳐 공부한 경향이 있다. 농업혁명, 과학혁명, 산업혁명 그리고 정보혁명과 같이 대부분의 내용은 우리가 어떻게 오늘날의 문명을 갖췄고 또 어떤 기술의 발견이 이를 이끌었는지에 관한 내용이 우리가 자주 마주하게 되는 인류 역사의 내용이다. 반면 데드먼드 모리스는 ‘털 없는 원숭이’를 통해서 인간의 문명이 아니라 인간 그 자체에 대해 관찰한 결과를 이야기한다. 인간을 지칭하는 ‘털 없는 원숭이’라는 용어에서부터 그가 어떤 방식으로 인류에 대해 말하고 싶어 하는지를 알 수 있다. 서론에서 말하듯, 우리가 ‘검은 발 다람쥐’ 에 대해 조사하고 싶다면 우선적으로 하는 일은 유사한 다른 여러 다람쥐 종들과는 구별되는 특성을 찾는 것이다. 검은 발 다람쥐의 구별되는 특성이 ‘검은 발’인 것처럼 그는 인간을 원숭이나 침팬지와 같은 유사한 영장류와 구분하여 ‘털 없는 원숭이’로서 객관적으로 인간을 바라보고자 한다. 적나라하게 분석되는 털 없는 원숭이에 대해 읽다보면 인간으로서 부정하고 싶은 충동이 들게 되지만, 논리적으로 관찰되고 전개되는 내용을 읽다보면 쉽사리 부정할 수 없을 만큼 스스로에 대해 새로운 시각을 갖게 된다.   8개의 챕터로 이루어진 책에서 가장 인상 깊은 챕터를 꼽는다면 단연 1챕터와 2챕터일 것이다. 1챕터 ‘기원’에서는 오늘날의 인간 호모 사피엔스의 등장을 기존과 차별되는 독특한 관점에서 재구성한다. 일반적으로 우리가 현생인류의 등장에 대해 배울 때는 도구의 사용, 불의 사용과 같은 기술에 초점을 둔다면 이 책에서는 우리가 다른 영장류와 두드러지게 다른 특성인 ‘왜 털이 없는가?’ 에 초점을 맞춘다. 여러 역사적 과학적 발견을 통해 밝혀진 사실들을 근거를 통한 우리의 기원에 대한 추측은 왜 이에 대해 지금껏 궁금해 하지 않았는지 놀랄 만큼 매력적이다. 곤충을 먹는 식충류에서 시작한 영장류, 빙하기로 인해 줄어든 숲, 숲에 남기를 선택한 영장류과 육지로 나서게 된 영장류. 숲속에 적응한 동물의 특성과 육식을 하는 동물의 특성이 혼재하게 된 영장류와 같은 합리적인 생활환경 변화의 추측부터, 털이 없는 이유가 될 수 있는 다양한 이유들 중에서 조개를 먹기 위해 바다를 자주 들어가다 보니 몸이 유선형이 되고, 직립하게 되었으며 손 감각이 발달하게 되었으리라는 합리적 추측까지 듣다보면 설득되는 우리의 기원은 신비롭고 동시에 재미있었다. 저자는 자신이 가장 옳다고 믿는 한 가지 이론을 제시하기 보다는 다양한 근거와 이론을 보여주며 독자의 상상력을 자극한다.   2챕터 ‘짝짓기’는 1챕터 기원만큼이나 참신하나 동시에 주제가 주제인 만큼 민망하기도 하다. 굳이 민망하다는 표현을 쓰게 되는 이유는 우리가 얼마나 성적인 동물인지를 밝혀내는 과정이 논리적인만큼 우리가 얼마나 ‘동물’인지 깨닫게 되기 때문이다. 인간은 인간 자체로서의 존엄성이 있다기보다 그저 성공한 ‘동물’에 불과함을 적나라하게 느낄 수 있다. 당연하게만 생각했던 우리의 생김새 하나하나에 숨겨져 있는 성적 신호들이 얼마나 많은 지를 합리적인 근거들을 바탕으로 깨달을 수 있다.      물론 절대적인 신이 등장하여 인류에 대해 하나하나 밝혀주지 않는 이상 저자의 말이 절대적인 사실이라고 말할 수는 없을 것이다. 그러나 충분히 합리적인 근거들과 전개되는 내용 속에서 우리는 인류에 대해 독특한 관점을 통해 바라볼 수 있다. 우리가 이룩한 문명들에 대해 이해하고 관심을 가지는 것도 중요하지만, 우리 자체가 어떤 생명체인지를 파악하여 이 급변하는 문명 속에서 어떤 반응을 보이게 될지 파악하는 것의 중요성도 결코 간과되어서는 안 될 것이다. 오늘날 우리가 아는 문명사회의 인류의 역사는 수백만 년 전의 인류의 기원에 비하면 티끌만큼이나 짧은 역사이다. 기나긴 역사 속에서 자리 잡은 우리의 본성을 고작 수천 년 동안 쌓아올린 이성만으로 완벽히 통제할 수 있으리란 생각이 얼마나 오만할 수 있는지 저자는 말해주고 있다. 우리는 우리 자신에 대해 더 알아볼 필요가 있다.   '],\n",
       " [4732,\n",
       "  \"        얼마전 성균관대에서 개최된 체육대회에서 이과학생들이 내건 플래카드가 문과학생들을 비하하는 내용이라는 지적을 받았다. 물론 이는 캠퍼스가 이원화 되어 있는 성균관대학교에서 일어날 법한 해프닝 이지만, 사실 이는 비단 성균관대학교 뿐만 아니라, 우리 사회의 학문간 유리 현상을 단적으로 보여주는 예라고 볼 수 있다. 21세기 사회는 모든 것이 기술, 공학, 과학 등을 중심으로 움직인다. 새로운 기술이 경제적 가치를 창출하며, 새로운 기술이 삶의 방식을 변화시킨다. 하지만, 기술의 영향력에 비해, 그에 관한 전문지식을 가진 사람은 소수에 불과하며, 특히 이과적 학문, 공학 등에 지식이 없는 일반적인 사람 들은 수식으로 가득찬 세계에 막연한 두려움을 느끼곤한다. 이런 시류에 비추어본다면, '기술', '과학' 과 가장 거리가 먼 '옳음', '진리' 등을 탐구하는, 일반적으로 가장 ‘문과적’ 이라고 인식되고 있는 철학이 현대사회와 동떨어진 학문이라고 생각하는 것은 어떻게 보면 당연한 일이다.    나 역시 ‘생활속의 양자’ 수업을 수강하고, ‘부분과 전체’ 책을 읽기전까지는 과학, 특히 가장 미시적인 세계를 다루는 양자역학은 내가 현재 공부하고 있는 학문과 매우 동떨어진 것이라고 생각했다. 하지만, 수업과 책을 통해 양자역학, 나아가 과학 역시 삶에 대한 이해, 진리에 대한 추구에 기반을 둔, 지금껏 내가 살아온 세상에 기반을 두고 있는 것임을 강하게 느낄 수 있었다. 아인슈타인과 하이젠베르크가 나누었던 측정, 존재, 지식, 언어 등에 관한 대화에서는 그들이 언급하는 철학적인 내용이 그저 두 천재과학자의 현학적인 대화인 줄로만 알았다. 하지만, 그들이 나눈 대화를 읽을수록, 그들이 주장하고 수학적으로 증명하려고 하는 주장, 가설들은 모두 철학에 그 뿌리를 두고 있음을 알 수 있었다.   특히 하이젠베르크는 아인슈타인이 상대성이론을 창안할 때 철학자 마흐의 ‘사고의 경제성’ 개념을 활용하여 사고는 관찰을 종합하는 것임을 지적하며 양자역학을 거부하는 아인슈타인을 정중히 비판한다. 이에, 마흐의 ‘관찰’ 개념이 엄격하지 않다고 논박하는 아인슈타인의 논쟁은 그들이 고안한 수식만큼이나 어려웠지만, 세계를 구성하고 있는 원리를 탐구하는 과학의 시발점이 분명 철학이었음을 보여준다. 또한 하이젠베르크 역시 양자역학을 집대성하던 당시, 칸트의 인과율 개념을 도입하여 과학자들과 무수한 토론을 거쳤다. 이처럼, 대부분의 천재 과학자들이 새로운 개념을 고안할 때 철학 개념을 활용한다는 것과 그 개념을 바탕으로 사유한다는 것은 과학과 우리 일상생활의 심리적 거리를 줄여주었다.   나아가 하이젠베르크는 철학을 넘어서, 일상생활 속에서 과학의 역할과 의미를 생각하였다. 물론 이것은 당시 세계 2차대전의 소용돌이 속에 있었던 그의 시대적 상황을 충분히 반영한 것이기도 하였다. 실험실에 항상 상주하며, 그것이 사회적으로 어떤 파급력을 끼칠지 고려하지 않은채 주어진 수식과 해 만을 탐구하는 고리타분한 과학자의 이미지와는 달리, 하이젠베르크는 본인의 연구, 지식, 나아가 과학이 사회적으로 어떤 파급력을 가질지 매우 숙고하였다. 하이젠베르크는 ‘오토한’이 우라늄의 자연붕괴와 연쇄반응 가능성을 확인하였을 때, 그것이 무기화될 수 있음을 직감하였다. 그래서 조국의 패망을 방조한다는 죄책감, 과학자로서 새로운 발견에 대한 지적 호기심과 세계 시민으로서 대량살상무기 개발에 관여하지 않으려는 양심사이에서 엄청난 고민을 하였던 것으로 보인다. 이런 고민에서 과학자의 인간적인 면모와 과학자로서의 자부심, 책임감을 엿볼 수 있었다.  마지막으로, 하이젠베르크는 그의 인생 후반기에 사회적인 영향력을 발휘하는 것에 대해 두려워하지 않았다. 물론, 이 과정에서 정치의 어려움을 토로하는 모습도 보이지만 오히려 그런 모습이 그의 인간적인 면모를 드러낸다. 세계 2차 대전 이후, 조국의 재건을 위해 과학자를 규합하고 연구소 개발에 관여하는 모습에서 그가 정말 노벨상을 수상한 과학자가 맞나 의문도 들었다. 또한, 2차 대전 당시 원자력 기술에 대해 숙고와 고심하는 태도를 보였다면, 2차 대전 후에는 무기화에는 적극 반대하고 원자력 기술 개발에만 찬성하는 모습에서 과학자의 발전된 사회적인 역할을 엿볼 수 있었다. '괴팅겐 18 '선언에서 볼 수 있는 결연함과 감동은 그 어떤 정치인에게서도 느낄 수 없던 것이었다.  ‘생활속의 양자’ 수업과 ‘부분과 전체’ 책의 공통점은 어렵다는 것이다. 하지만, 그보다 더 중요한 점은 설령 그것이 매우 난해하고 이해하기 힘든 것일지라도, 분명 우리 현실에 맞닿아 있는 것임을 인식시켜 준 것이었다. 과학자는 일상생활에서 촉발된 그의 지적 호기심을 철학이라는 틀에 맞춰 사유하기 시작한다. 또한 그들도, 당장 눈앞에 주어져 있는 수식과 실험에만 몰두하는 것이 아니고, 그의 수식과 실험이 촉발할 영향력에 대해 깊이 숙고한다. 나아가, 과학자는 과학이 올바른 방향으로 쓰이지 않을 때 저항하고, 올바른 과학의 방향이 무엇인지 제시하기도 한다. 이것은 우리 사회의 모든 학문, 정치가 작동하는 방식과 동일하다.      \"],\n",
       " [7212,\n",
       "  '          『도덕과 입법의 원칙에 대한 서론』, 경계를 넘나드는 공리주의      2014310297      국어국문학과 장재영              『도덕과 입법의 원칙에 대한 서론』은 공리주의를 통한 입법의 가능성과 그 방법에 대해 다룬 책이다. 제러미 밴담은 공리주의적 법 체계의 가능성을 감수성, 의도성, 의식, 동기, 성향 등 상당히 자의적으로 나누어진 측면을 통해 고려하고 설명한다. 그리고 그 서문에서 그는 ‘입법 과학’이라는 용어를 사용하였다. ‘입법 과학’은 쉽게 연상할 수 있는 용어는 아니며 오늘날 그렇게 자주 사용되는 용어 또한 아니다. 입법과 과학이라는, 이질적인 두 개념의 결합을 통해 만들어진 단어이기 때문이리라. 저자는 진심으로 ‘과학적 보편성에 위배되지 않는 원칙을 통한 입법’의 가능성을 믿었던 것 같다. 그는 그것을 공리주의로 실현하고자 했다.       오늘날 평범한 대한민국의 국민이라면 공리주의라는 개념을 어디서 접하게 될까? 나의 경우에는 중학교 3학년 도덕시간에 교과서에서 제러미 밴담과 존 스튜어트 밀, 그리고 공리주의라는 개념을 처음 만났다. 영국의 경험주의라는 주제 아래였다. 그러한 교과 과정을 통해 아마 일반인들은 제러미 밴담을 철학 사상가로, 공리주의를 철학 사상으로 인식하고 있을 것이다.       그 당시 나는 데카르트나 홉스, 칸트 등과 함께 공리주의에 대해 공부했었는데, 다른 사상보다는 훨씬 쉽게 이해할 수 있었다. 우선, 존재론이나 형이상학과 같은, 인간과 세계 혹은 그 밖을 이루고 있는 학술 이론보다는 사회와 공동체에 쉽게 적용할 수 있어서 그랬을 것이다. 루소나 홉스의 사회 이론도 교과서에 수록되어 있었으나 공리주의의 ‘최대 다수의 최대 행복’ 과 같이 직관적인 원칙으로 정리할 수 없었던 것도 그 이유이다. 즉 나에게 공리주의란 단순히 이해하기 편한 사회과학적 철학 사상이었다.       그러한 나에게 『도덕과 입법의 원칙에 대한 서론』의 공리주의는 상당히 신선하게 다가왔다. 물론 책에서 제시하는 원칙이나 사례 중에는 비판의 대상이 될 만한 것들도 있지만, 나는 공리주의의 간학문적 성향에 주목하고 싶다. 이 책의 공리주의는 사고의 대상이자 철학 사상이 아니다. 능동적으로 다른 분야의 학문을 끌어와 주장을 펼쳐나가는 사상의 모습을 보인다.       가령 의도성에 관한 논의를 다루는 8장(p.185)의 각주에서 밴담은 “…운동에는 항상 세 가지 고려 사항이 있다. 1)운동하는 물체의 양, 2)운동하는 방향, 3)운동하는 속도…” 라고 기술하며 이는 당대의 과학적 지식을 가져 온 것이다. 그는 그 양, 방향, 속도의 세 가지 기준에 따라 행동의 의도성을 분석하는데, 그가 행동 의도를 나누는 방법은 매우 미시적이고 섬세하여 마치 심리학 이론에 대해 서술하는 것처럼 보일 수 있다. 결국 이러한 방식을 통해 그는 법의 기준을 정하고자 했으며, 책의 끝까지 “공리주의적 관점에서, 과학적으로 타당한 근거에 의해서 인간의 행동 심리를 분석하고 그를 통해 법의 기틀을 다진다”는 자세를 유지한다. 이른바 ‘입법 과학’ 인 것이다.       철학적 사상이 과학적인, 혹은 실증적 방법으로 연구된 학문의 도움을 받는 것은 상당히 희귀한 일이다. 1970년대 포스트모더니즘이 대두된 이래로 이리가레이, 크리스테바, 라캉, 가타리 등의 사상가들이 본인의 사상을 과학이나 수학의 이론으로 뒷받침하려 하거나 과학 이론을 철학적으로 설명하고자 시도했다. 결과적으로 그러한 움직임은 앨런 소칼의 지적 사기 사건 이후로 크게 위축되었고, 인문학적 연구들에서 과학이나 수학의 흔적은 거의 사라졌다. 비슷한 맥락에서 심리학 혹은 사회학 연구 중 비실증적인 접근법을 사용한 학문들은 과학적 증거보다는 사유와 논리에 기반하고 있기 때문에 학계에서는 문학적 저작의 취급을 받고 인문학의 이름 아래에서 뭉뚱그려진다. 결국 학계 전체에서는 학문간의 고립이 이루어지고 있는 것이다. 같은 분야 이외의 이론이 참조되는 경우는 흔치 않다.       이러한 현대의 관점에서 밴담과 공리주의는 매우 도전적으로 보인다. 그렇다 하더라도 그의 저작은 체계적으로 다듬어져 있다. 인간의 성향을 다양한 분야로 나누고, 그 분야 내부적으로도 인간의 모든 행동 양식을 정리하여 항목화하고자 노력했다. 예를 들어 본문 222p에서부터는 “쾌락과 고통의 목록에 대응하는 동기의 목록” 에 대해 다루고 있는데, 미각, 성적 감각, 부유함 등 13가지의 쾌락을 통해 인간의 모든 쾌락을 표현하고자 했다. 이렇듯 공리주의를 체계적인 사상으로 만들고자 하는 밴담의 노력이 간학문적 결과를 산출해냈고, 그의 저작들은 후계자를 맞이하여 마침내 공리주의는 자타공인 확고한 철학 사상으로 자리매김 할 수 있었다.       공리주의가 입법 원칙이 되기에 적합한 사상이었다는 것 또한 작용했다. 나는 이 책을 통해 입법 혹은 사법 과정은 그 정립과 집행에 있어 다양한 학문과 사상을 참조하는 것이 상당히 중요하다고 생각하게 되었다. 밴담의 인간 분석은 꽤 공들인 것이었지만 결국 자의적 분류에 그치고 말았다. 예전보다 훨씬 다양한 법이 존재하는 현대 사회의 입법에 있어 해당 분야의 전문 지식은 반드시 필요할 것이며, 이 지점에서 다양한 학문이 협동할 수 있는 장이 열릴 수 있다. 이 책은 그 지점에 대해 다루는 예시로 제시되기에 손색이 없다.          '],\n",
       " [17986,\n",
       "  '   [귀신과 제사]를 읽고 2010311196 임 상 희‘귀신과 제사’는 제목에 걸맞게 어두운 표지를 하고 있다. 귀신이라는 말이 들어가는 제목에 끌려 선택하게 된 ‘귀신과 제사’라는 책은 제사 대상이 되는 귀신(神)의 존재와 제사 의례의 유교적 종교성을 조명하는 글이다. 우리 집도 또한 현재 제사를 지내고 있는 집안으로 매년 몇 달에 한 번씩 지내는 제사를 통해 제사에 대해 관심도 많고 많이 알고 있다고 생각하였다. 하지만 왜 제사를 지내는 지, 무엇을 위해 제사를 지내는 지에 대해서는 생각도 해보지 못하였고 이 책을 읽으면서야 비로소 생각하게 되었다. 나는 ‘귀신과 제사’ 책에서 다룬 귀신의 존재, 제사, 조상 숭배, 주자학 그리고 한국 유교 등에 대해서 다룬 것 중에서 내가 가장 관심 있는 조상 숭배와 한국 유교에 대한 글이 가장 인상 깊었다.이 책의 대부분에서는 유교에 대해서 다루었고 가장 인상 깊었던 것은 한국 유교에 대한 것이었다. 현재 나는 유학과 직업윤리라는 수업을 듣고 있기 때문에 유학 또는 유교라는 글자에 관심이 많아졌고 책에서도 관심이 있고 흥미롭게 읽었다. 한국 유교의 특성은 세 가지로 나눌 수 있다. 첫 번째로 긍정으로 이 세계와 자기 존재를 근원적으로 긍정하는 사유 방법을 통하여 세계를 이해나는 것이다. 하지만 이러한 긍정 속에는 방어를 통해 보존을 추구하는 사유를 드러내고 있어 무기력함을 나타낼 수도 있다. 두 번째로는 의리의 순정성이다. 의리란 선악과 시비를 나누는 것인데 이렇게 한국의 유교에서는 도덕적 가치 규범이 확립되었을 때 그 기준을 순수하게 지키려는 의리를 높이 샀다. 마지막으로 한국 유교의 특징으로는 융화이다. 융화는 위에서 언급한 순정성과는 대립되는 의미이지만 절충적이고 포용적인 성격으로 조화와 균형을 통해 통합을 추구하는 사상이다. 우리 한국의 유교는 이렇게 세 가지 특징을 가지고 균형을 이루면서 작용하고 있다.이 책을 읽음으로써 나는 한국의 유교에 대해서 정확히 알 수 있었다. 그리고 한국의 역사가 한국 유교의 특성과 연관이 있다는 것에 가장 깜짝 놀랐다. 한국 유교의 특징 중의 하나인 긍정을 통해 우리나라의 사대 의식을 알 수 있었다. 긍정의 단점 중의 하나는 바로 변혁을 통한 창조를 추구하는 것이 아니라 방어를 통해 보존을 추구하는 특징을 가지고 있다. 자기 긍정 의식으로 스스로 개혁하거나 혁명을 하려는 의지가 약하고 외세에 의존하면서 자기를 보존해왔던 우리나라의 지난 역사와 연관되어있다. 또한 가장 호전적이고 잔인한 당파 싸움이 한국 유교의 특성과 관련이 있었다. 도덕적 가치 규범이 확립되었을 때 그 기준을 순수하게 지키려는 의지를 의리의 순정성으로 받아들여졌다. 이러한 특징이 당파싸움의 이유에 적용이 된다면 이는 단순히 호전적이고 잔인한 당파적 분열이 아니라 의리의 규범을 순수하게 고착시키려는 집념을 표출하는 것이었다. 이렇게 한국의 유교를 이해함으로 나는 한국의 역사적 일들에 대한 근원과 우리나라의 특성 등을 더욱 자세히 알게 되었다. 우리나라의 특성이 유교에도 잘 나타나 있다는 것을 알 수 있고 유학을 배우고 파악함에 있어 문화도 또한 배울 수 있다고 생각되었다. 한국 유교와 더불어 이 책에서는 제사에 대해서 이야기 하고 있다. 나는 우리가 제사를 지내는 가장 큰 이유 중에 하나가 조상님을 숭배하기 위해서 라고 생각한다. 그렇다면 조상 숭배의 유교적 의미를 무엇일까 이 책에서는 조상 숭배는 유교적 생명관, 도덕적 의미 그리고 사회적 기능으로 의미를 파악할 수 있다고 하였다. 유교적 관점에서 인간은 심성과 신체로 되어있는데 신체는 부모님으로부터 오는 것이라 하였다. 그러므로 부모는 하늘과 더불어 인간 생명의 근원으로 더 나아가 조상은 나의 생명의 근원이 된다. 그렇기 때문에 조상 숭배를 하는 것은 자기 생명을 존중하는 것이라 하였다. 도덕적으로 인간은 조상과 부모로부터 부여받은 큰 은혜를 지고 있다고 생각하고 그 은혜를 보답하는 것이 정당한 도리라고 생각하여야 한다. 그리고 이 은혜를 조상 숭배를 통해 도리를 다 할 수 있다고 하였다. 또한 조상 숭배를 함으로써 조상이 모든 후손들의 정점으로서 그 혈통의 근원이면서 혈통을 통합시켜주는 중심으로 받아들여 질 수 있다고 하였다. 이로써 우리는 조상 숭배의 근원과 이유, 의미를 알았다. 하지만 점점 현대로 갈수록 조상을 숭배하는 것들이 줄어들고 있다. 예로써 점점 제사를 지내는 집안이 없어져 간다는 것이다. 또한 제사를 지낸다고 해도 그 형식이 많이 간소화되다 못해 성의가 없어지고 있다. 몇 달 전에 본 가장 충격적인 기사는 제사 음식을 올려놓는 곳에 음식 사진이나 음식 사진을 띄운 휴대폰을 놓았다는 기사였다. 이러한 제사를 조상을 숭배하기 위해서 지내는 제사라고 할 수 없다. 이렇게 점점 변해가다가 조상을 숭배하는 문화가 사라져 간다면 위에서 언급했듯이 혈통을 통합할 수 있는 것들이 사라지고 조상과 부모로부터 받은 은혜를 잊게 돼서 더 나아가 자기 생명을 존중하는 것까지 사라질 수도 있는 것이다. 우리는 조상 숭배가 사라지게 놔둘 수는 없다. 전통이 무너지는 것을 막기 위해서 제사 이외에도 조상을 숭배할 수 있는 것들을 찾아보아야 한다. 제사가 너무 번거롭다면 설날 등 일 년의 한번 차례를 지내는 등으로 조상 숭배에 대한 마음을 표현할 수 있다. 또한 우리는 조상 숭배에 대한 명확한 인식이 필요하다. 왜 조상을 숭배해야 하는 지, 무엇을 위해서 해야 하는 지, 어떻게 해야 하는 지 등 명확하게 알게 된다면 우리는 조상 숭배의 중요성을 인식하고 의식을 바꿀 수 있다. 이러한 노력을 통해 현대에 사라져 가는 유교 의식과 사상을 다시 우리의 생활에 스며들게 할 수 있을 것이다.     '],\n",
       " [18618,\n",
       "  \"   [위대한 설계]    이 책이 좀 철학적이라는 소리를 들었었는데 책을 읽기전에 제목의 의미에 대해 생각해 보았으나 전혀 감이 잡히지 않았다. 그러나 이 책은 현대물리학이 지금까지 발전해온 과정을 한 눈에 알아보기 쉽게 설명해 놓았으며 말로만 듣던 상대성이론과 양자이론 등에 대해 아주 쉽게 설명해 놓았다. 또 모형의존적 실재론과 같은 개념을 잘 설명해주어 세상을 바라보는 안목을 키워주기에 충분했다. 또 더욱 놀라운 것은 이러한 내용들을 바탕으로 궁극적으로 우리가 왜 존재하는지에 대해 그럴싸한 답변까지 내어 놓고 있다.  호킹은 적어도 잠정적으로는 현재의 물리학이 어드정도 매듭이 지어지는 완성단계에 도달했다는 입장이라는데 나로선 처음에 정말이라는 의문이 먼저 앞섰지만 책을 읽어가면서 동감할 수밖에 없었다. 현대 과학의 위대함을 충분히 이 한권이면 느낄 수 있을것이다. 이외에도 호킹 특유의 재밌는 비유나 말투로 재미있었고 예시들이 쏙쏙 이해가 잘 됬다.   책의 내용과 나의 생각   목차   1. 존재의 수수께끼 2. 법칙의 지배 3. 실재란 무엇인가 4. 대안역사들 5. 만물의 이론 6. 우리의 우주를 선택하기 7. 가시적인 기적 8. 위대한 설계   1. 존재의 수수께끼  우리는 존재한다. 누구나 우주가 어떻게 탄생되었는지, 나는 어디서 온건지, 왜 존재하는지 등의 궁금증을 가져보긴 하지만 우리 대부분은 이러한 궁금증들에 대해 많은 정력을 소비하지 않는다. 내 경험상 백년 남짓되는 이생동안 이런 질문들에 대해 고민해 본들 그 답을 찾을 수 없을것 같기 때문이고, 이미 이 사회는 우리가 이러한 질문들에 대해 충분히 생각하는 것을 허용하지 않는 것 같다. 경쟁에서 뒤쳐질 수 있기 때문이다. 따라서 이러한 질문들은 전통적으로 철학의 영역이었으나, 철학은 이제 죽었다고 한다. 과학의 발전 속도를 따라 잡지 못했다는 것이다. 이 말이 직관적으로 이해가 안됬지만 책을 읽는 동안 충분히 그럴 수 있다는 것에 놀라웠다. 즉, 과학자들이 존재의 수수께끼에 대해 내어 놓는 답변이 철학자들의 그것보다 더 그럴싸하다는 말이다. 이 책의 목적은 이렇듯 최근까지의 발견들과 이론적인 발전들이 시사하는 이러한 궁극적인 물음에 대해 대답을 제시하는 것이다. 플라톤의 모형에서 뉴턴의 고전이론을 거쳐 현대의 양자이론까지 왔는데 그보다 더 궁극적인 만물의 이론 후보인 M이론까지 모양새를 갖추어 가고 있다. 그리고 이 양자이론이나 M이론으로 이책의 상당부분의 논의가 의존한다. M이론이란 정말 만물의 모든걸 설명할 수 있는 단일한 이론일수도 있고 그물망 처럼 존재해 그물망의 각 부분은 여러 이론들이 차지하며 그 경계에선 두 이론이 모두 만족되는 그런 형태 일 수도 있다고 한다. 그물망 처럼 존재하다는 말의 예시를 들면 뉴턴의 법칙들은 느린 현실세계에선 대단히 잘 맞아 떨어지지만 빛의 속도에 가깝게 움직이는 물체나 원자정도의 매우 작은 세계에서는 그 의미를 상실하고 양자이론을 새로 도입해야 맞게 된다. 이럴때 그 중간지점(속도나 크기면에서)에선 두 법칙이 모두 맞는 형태일 수도 있다는 것이다. 내가 든 예시는 사실 아닐수도 있지만 대충 이런 개념인것 같다. 이러한 M이론에 따르면 우주는 유일한 것이 아니라 엄청나게 많은 우주들이 무(無)에서 창조되었다고 본다. 그러나 우리처럼 생명의 존재를 허용하는 우주들은 극소수 일것이라고 본다. 그리고 이러한 이론들을 바탕으로   왜 무(無)가 아니라 무엇인가 있을까 왜 우리가 있을까 왜 다른 법칙들이 아니라 이 특정한 법칙들이 있을까   와 같은 궁극적인 질문에 대답을 시도한다.   2. 법칙의 지배  예전에 사람들은 자연이 작동하는 방식에 대해 파악하기 어려웠다. 따라서 삶의 모든 면을 제멋대로 지배하는 신과같은 개념을 끌여들여 설명하려고 했다.   하지만 고대 이오니아 시대때부터 피타고라스와 같은 인물이 많이 등장하면서 자연법칙들을 조금씩 밝혀 나갔다. 여기서 자연법칙이란 모든사례에서 보편적으로 성립하지는 않더라도, 최소한 규정된 조건들에 맞는 사례들에서는 예외없이 성립하는 법칙을 말한다.   이는 후에 그리스인들에 의해서도 많이 발전하게 됬지만 이렇게 자연이 어떤 법칙들을 따라 움직인다는 생각은 기독교도들에 의해 배척당하게 된다. 우리가 아는 여러 위대한 사상가나 과학자들조차 신들이 세계의 운행에 개입하지 않는다는 생각에 불안감을 느끼고 반대한다. 하지만 실제로 자연법칙이 존재한다는 믿음이 되살아 나면서, 자연법칙과 신의 개념을 조화시키려는 노력들도 새로 등장했다. 예를 들면 데카르트는 신에의해 우주가 창조되었지만 그 후 신의 개입은 없다는 식으로 생각했다. 뉴턴도 이에 비슷한 입장을 취했다고 한다.   이들이 기독교 신자여서 신의 존재를 옹호했는지는 모르겠지만 우주의 창조까지 법칙으로서 설명할 수는 없을것이라 생각해서 그랬을것 같다. 이들이 우주의 창조까지 법칙으로 설명하려는 호킹의 생각을 접했을 때 어떠한 반응을 보일지 궁금해진다.  그리고 실제로 이러한 법칙들이 존재한다면 다음과 같은 질문이 제기 될 수 있다.    법칙들의 기원은 무엇일까  법칙의 예외, 이를 테면 기적은 존재할까  가능한 법칙들의 집합은 오직 하나인가   이 장에서 답을 바로 얻을 수 있는 것은 두번째 질문이다. 이책은 라플라스의 과학적 결정론을 택한다. 과학적 결정론이란 어떠한 시점에서 우주의 상태(초기조건)이 주어지면, 완전한 법칙들의 집합에 의해 미래와 거거가 철저히 결정된다는 입장이다. 따라서 어떠한 초자연적인 존재가 개입하지 않기로 결심할 때만 성립하는 자연법칙은 자연법칙이 아니라고 본다.   첫번째 질문과 세번째 질문은 이 책 뒤에서 답을 얻을 수 있다.   3. 실재란 무엇인가  이 장에서는 굉장히 재미있는 발상이 소개된다.  우리가 법칙을 만들고 하는 우주를 볼때 우리가 보는 대상들은 실재하는 것일까 객관적인 실재가 존재한다고 믿을수 있을까  어항에 들어있는 금붕어를 생각해보자. 우리가 보는 세상을 금붕어는 어항을 통해 휘어지게 보고 있을 것이다. 그렇다면 우리는 우리가 세계를 보는 방식이 실재적이라고 할 수 있을까 하는 것이다. 우리는 우주가 작동하는 방식을 여러 법칙들을 통해 기술한다. 하지만 그 법칙들은 어항속에 있는 금붕어에겐 엉터리일 것이다. 금붕어는 그 자신이 보는 세계를 자신들의 관찰에 부합하게 여러 식들로 정식화 하여 나타낼 수 있을것이다.  이를 좀 더 확장해 우리 인간에게 적용시켜 보면 굉장히 재밌다. 우리는 지구가 태양주위를 돈다고 확신한다. 하지만 태양이 지구 주위를 돌 수도있다! 프톨레마이오스가 천동설을 주장하고 설명할때 역행현상을 설명하기 위해 주전원을 도입하고 했듯이 그때 관측으로 발견하지 못했던 연주시차나 내행성의 위상변화 같은 것들도 천동설 모델을 수정하면 충분히 설명할 수 있을 것이다. 훨씬 복잡하겠지만 복잡함의 문제는 취향의 문제이다.   따라서 객관적인 실재의 개념은 없다고 할 수있으며 그림이나 이론에 의존하지 않는 실재의 개념은 없다. 따라서 모형 의존적 실재론이라는 개념을 채택할 수밖에 없다. 이는 이미 현대 과학을 해석하는데 기본골격의 구실을 할 만큼 중요한 개념이다. 이 이론에 따르게 되면 모형이 실재에 부합하느냐는 질문은 무의미하고, 오직 모형이 관찰에 부합하느냐는 질문만 유의미하다. 따라서 관찰에 부합하는 두 모형이 있다면, 한 모형이 다른 모형보다 더 실재에 가깝다는 말따위는 할 수 없으며 해당 상황에 더 편리한 모형을 사용하면 된다.  따라서 전자, 쿼크 등 우리가 절대 볼 수 없을 물질들이 '존재'하는지 여부는 크게 중요하지 않다. 다만 우리가 관찰하는 것에 부합하고 자연세계를 이해하는데 문제가 없다면 그만이다. 이런식으로 모형의존적 실재론은 존재의 문제를 해결하거나 최소한 우회할 수 있다.  하지만 좋은 모형이 갖춰야 할 조건이 있다.   -우아할것 -자의적이거나 조정 가능한 요소들을 거의 포함하지 않을 것 -기존의 모든 관찰들에 부합하고 그것들을 설명할 것 -만일 틀렸을 경우에 모형을 반증할 수 있는, 미래 관찰에 관한 상세한 예측들을 내어놓을 것    이렇게 모형을 한번 채택하게되면 만약 모형이 관찰에 부합하지 않게되면 모형을 포기하기보단 살리려고 노력하는 특성이 있다. 이는 어디선가 주워들었던 패러다임의 역할을 하는 것 같다.   4. 대안 역사들(alternative history)  이 장은 양자이론의 접근법인 대안 역사들에 대해 소개된다. 양자역학의 수수께끼가 모두 들어있다고 회자되는 이중 슬릿 실험에 대해 살펴보면 보통 크기의 물질에서는 나타나지 않는 현상이 버키볼(풀러렌)이나 전자로 실험하면 나타나게 된다. 어떤 현상이냐하면 한 슬릿을 통과하는 입자가 다른 슬릿의 개폐 여부에 영향을 받는다는 거다. 이 정말 말도안되는 현상을 설명하기 위해 과학자들은 소설을 쓴다. 바로 어떤위치에서 다른위치까지 갈 수 있는 모든 경로 예를 들면 버키볼이  A에서 B로 가는데 A에서 B로 직선코스로 갈 수 도 있지만, A에서 당신의 콧 속에 들어갔다가 B로 갈 수도 있는 것이다. 이런 경로들을 확률 진폭으로 나타내고 그 가능한 경로들을 역사라 하고 이런 역사들의 합을 통해 기술하는 것이다. 역사들의 합은 파인만의 역사 합 방법을 이용해 계산한다고 한다. 이러한 불확정성의 원리를 기반으로 해 플랑크의 양자원리를 더해 만든것이 양자이론이라고 한다. 정말 무슨 과학소설같다. 하지만 이 양자이론은 지금까지의 실험을 모두 통과했다고 한다.   이렇게 양자이론은 일상경험과 동떨어진 틀을 기초로 삼는다. 그렇다면 양자물리학 이론들도 고전물리학이 매우 정확하게 모형화 했던 일상적인 사건들을 설명할 수 있을까 대답은 설명할 수 있다는것이다. 단지 뉴턴이론과 같은 것들은 양자 요소들로 이루어진 거시적 물체의 행동을 기술하는 훌륭한 근사이론(approximation)일 뿐이다.  그리고 또한가지 의문은 양자이론은 불확정성의 원리를 기반으로 하기에 자연이 법칙들에 의해 지배된다는 생각을 위태롭게 할 수도 있다고 여겨질 수도 있다. 하지만 양자이론은 다만 새로운 형태의 결정론을 향한다는 것이다. 그 결정론은 어떤 시스템의 특정시점에서의 상태가 주어지면, 자연법칙들은 그 시스템의 미래와 과거를 정확하게 결정하는 것이 아니라, 다양한 미래들과 과거들의 확률을 결정한는 것이다.  위의 표현에서 다양한 미래라는 것은 잘 와 닿겠지만 다양한 과거들이란 말이 뭔지 선뜻 이해가 안될수도 있다. 이는 우리가 어떤 시스템이 어떠한 경로를 통해 이동했는지 '관찰'하게 되면 그 시스템의 진로가 바뀔수 밖에 없다는 것이다. 이는 이중슬릿 실험에서도 충분히 증명된다. 따라서 무엇인가를 '관찰하기만 하는 것'은 불가능하다. 관찰을 하려면 관찰자가 관찰대상과 상호작용을 해야한다.  따라서 과거는 미래와 마찬가지로 불확정적이며 다만 가능성들의 스펙트럼으로 존재한다. 여기서 시스템의 과거가 불확정적이라는 말은 당신의 현재 관찰이 시스템의 과거에 영향을 미친다는 의미이며 이는 입자뿐만이 아니라 우주에도 적용된다. 우주역시 과거, 혹은 역사는 단일하지 않고 가능한 모든 역사를 지녔다.   5. 만물의 이론  과학자들은 모든 현상을 설명할 수있는 만물의 이론을 원해왔다. 멕스웰도 그런 사람들 중에 하나였으며, 전기력과 자기력을 하나의 힘으로 통합시키고 전자기력이라는 개념을 창시했다.  또, 그 당시에 팽배해있던 에테르 모형의 실재를 판별하기 위해 여러 사람들이 증명을 하려고 노력했으며, 결국 이는 아인슈타인에 의해 에테르가 존재하지 않음이 증명되었다. 아인슈타인은 이를 절대적시간과 절대적 공간이라는 개념을 부정하는 특수상대성이론을 통해 증명했다. 주요 개념들을 살펴보면 광속은 모든 기준틀에서 동일하며 이를 통해 시간과 공간은 얽혀있다는 시공(spcae-time)의 개념을 주장했다. 후에 일반상대성이론을 통해 '중력은 질량이 시공을 휘어지게 한다는 사실의 결과물'이라고  주장하기도 했다. 이러한 멕스웰의 전자기이론이나 아인슈타인의 상대성이론은 물리학을 혁명적으로 변화시키기는 했지만 뉴턴의 물리학과 마찬가지로 고전이론들이다. 왜냐하면 그 이론들에 의해서 우주는 단일한 역사를 가지게 되기 때문이다. 즉 양자이론이 고려되지 않았다.  과학자들은 이러한 여러 법칙들과 자연에 존재하는 4가지 힘들(중력, 전자기력, 약한 핵력, 강한 핵력)의 양자버전이 필요했다. 그리고 양자버전을 개발하기 위해 노력했으며 자연법칙들을 양자적으로 기술하는 이론들을 일컬어 양자장이론이라고 한다.  이 4가지 힘들 중 가장 먼저 양자적으로 기술된 힘은 전자기력이고 파인만에 의해 양자전기역학(QED)가 개발되었다. 파인만이 QED를 기술한 방식 중 파인만도표나 재규격화 같은 기법들은 다른 세가지 힘들을 기술하는 양자이론을 개발하려는 노력을 부추켰으며 QED는 다른 양자이론들에 모범이 되기에 충분했다고 한다.  이렇게 사람들은 네 가지 힘을 양자이론과 조화를 이루는 단일한 법칙으로 통합하려는 만물의 이론을 추구하게 된다.   약한핵력에 관한 이론은 압두스 살람과 스티븐 와인버그라는 인물들에 의해 전자기력과 통합되었으며 그 통합된 힘을 '전기약력' 이라 부르며 w-, w+, z0 이라는 새로운 입자의 존재를 예측했으며, 후에 실제로 관찰되었다.   강한핵력에 관해서는 양자색역학(QCD)라는 이론이 등장했고 쿼크들로 양성자들과 중성자들의 행동을 아주 잘 설명했다.  과학자들은 전기약력에 강한핵력을 추가로 통합 할 길을 모색했다. 이를 대통일이론(GUTS)라 부르는데 여러가지가 존재한다. 이 GUTS들의 이론들의 거의 대부분이 양성자가 일년동안  붕괴할 확률이 1/(10^32)라고 예측한다고 한다. 하지만 전기약력의 경우와는 달리 관찰에 의해 뒷받침되지 못했다. 이렇듯 전기약력과 QCD를 통합하기는 쉽지 않았다. 더 우울한 예기는 중력과 이것들을 아우리는 것은 훨씬 더 어려운 일이라고 한다. 심지어 독자적인 양자중력이론을 개발하는 일도 대통일이론을 만드는 것보다 훨씬 어려운 일이라고 한다. 그러나 초중력이론이라는 양자중력이론을 기술하는데 해결책이 될 수 도 있는 가능성이 발견되었다고 한다. 계산이 너무 길고 난해해 아무도 손을 대지 못하고 있지만 말이다.  이러한 초중력이론은 끈이론(string theory)를 연구하는 과정에서 개발되었다. 끈이론에 따르면 입자는 점이아니라 진동의 패턴이며, 그 패턴은 마치 무한히 가는 끈처럼 길이만 있고 굵기는 없다. 이 이론들은 시공이 4차원이 아니라 10차원(후에 밝혀진 사실로는 1차원이 간과되 실제로는 11차원이라고 한다) 일때만 일관적이다. 우리가 인지할수있는 4차원 외의 나머지 차원들은 내면공간(internal spcae)에 감겨 있다고 하며 그 감겨있는 방식은 수백만개가 존재한다고 한다. 또, 그 끈이론 자체만도 서로다른 다섯가지가 존재하고, 오늘날 끈이론가들은 이 다섯가지 끈이론들과 초중력이론이 다른 이론들보다 더 근본적인 근사이론들이며 타당성이 있는 이론이라고 확신하고있다.   이런식의 생각으로, 이 끈이론들과 초중력이론들을 근사이론으로 거느렸다고 생각되는 더 근본적인 차원의 이론이 M이론이다.   이러한 M이론에 따르면 M이론은 다양한 우주를 허용한다. 이 이론의 해들이 허용하는 내면공간은 어쩌면 그 개수가 10^500에 달한다고 한다. 정말 상상할 수조차 없는 엄청난 수치다. 이는 M이론이 제각각 고유의 법칙을 가진 서로 다른 우주들을 저 개수 만큼 허용한다는 뜻이며 우리가 알고있는 우주는 그 무수한 우주들 중의 하나에 불과하다.   6. 우리의 우주를 선택하기  그렇다면 그 많은 우주들 중 우리가 사는 우주는 왜 하필 현재와 같은 모습인가 이 질문에 대해 대답하려는 노력은 옛날의 창조신화로 부터 해서 지금까지도 계속되고 있다. 그러나 과학자들은 앞 장들에서 얻은 지식들로 이제 이 질문에 그럴싸한 대답을 내어놓을 준비가 되어있다고 한다.   허블의 관찰로 정적인 우주 모형은 힘을 읽고 우주가 팽창하는 모형을 선택한다. 그러한 생각에서 우주가 팽창을 시작하는 상태인 지점이 있을 것이라고 자연스럽게 생각하게 되고 그 시점이 '빅뱅'이 되는 것이다. 그 후 마이크로파 우주배경복사(CMBR)의 존재가 밝혀지고 빅뱅이론이 예측한 우주의 구성물질들의 비율이 실제의 관찰과 일치하면서 빅뱅이론은 힘을 얻게된다. 하지만 이에도 역시 문제점이 있다. 이 빅뱅이론은 아인슈타인의 방정식들로부터 도출된 결과이지만 앞에서도 봤듯이 아인슈타인의 상대성이론은 양자세계에 적용되지 않는다. 충분히 거슬러 올라간 우주의 크기는 매우 작은데, 이 규모에서는 양자론을 감안해야 한다. 식적으로 살펴봐도 우주탄생시점에서는 우주의 온도, 밀도, 곡률이 모두 무한대가 되는 특이점이 되어 이 식에 결함이 있음을 보여준다. 따라서 아인슈타인의 방정식들로 나온 빅뱅이론은 아주 어린 우주에 대해서는 적용이 되지만 우주의 탄생까지 기술할 순 없다. 그 대신 인플레이션 모형이 등장했다. 이는 우주 팽창의 첫단계에서 이루어졌으며, 10^(-35)초 동안 10^30배의 팽창이 이루어 졌다고 예측한다. 이는 우주전체에 퍼져있는 CMBR의 미세한 변이와 우주의 온도의 균일함으로 인해 뒷받침 되고 있다. 이러한 인플레이션모형은 일반상대성이론과 양자이론을 같이 고려해 얻은 생각이라고 한다.   중력이 시간과 공간을 휘게 하는것을 이해하고 파인만의 방법을 우주에 적용시키면 우리 우주는 자발적으로 모든 가능한 초기조건 속에서 발생했다고 한다. 그 우주들의 일부는 우리 우주와 유사한 것도 있겠지만 대부분 전혀 다르다. 책의 표현을 빌리자면 '그 우주들은 엘비스가 요절했는지 혹은 순무가 사막의 식량인지 여부처럼 세부 사항들에서만 다른 것이 아니라 가시적인 자연법칙들에서도 다르다.'  이 장에서 기술한 결론은 우리 우주도 많은 우주들 중의 하나라는 것과, 우리 우주의 가시적인 법칙들이 유일한 법칙은 아니라는 것을 시시한다. 그리고 재밌는 것은 우리는 생명이 존재할 수 있는 우주에 살지만, 우리와 유사한 생명이 살고있을 우주는 드물것이라고 예측한다. 이 우주가 조금이라도 달랐다면, 우리와 같은 존재는 있을 수 없었을 것이다. 그렇다면 우리는 이 우주가 이토록 정밀하게 조정되어 있다는 사실을 어떻게 이해해야 할까   7. 가시적인 기적  조금만 주위를 둘러봐도 우리는 매우 행운적인 주위 환경 속에서 살고 있음을 느낄 수 있을것이다. 이를 약한 인본원리라고 한다. 이 외에도 우리가 얼마나 행운적인 물리법칙들, 물리상수들 속에서 살고있는지 알면 더욱 상황은 재미있어진다. 이를 강한 인본원리라고 한다.   예시를 들어보자. 약한인본원리의 예시로는 우리 지구가 이심률 2%의 거의 원에 가까운 궤도로 골디락스 존에서 태양주위를 공전하고 있다는 것이나, 태양의 질량이 매우 적절하다는 것 등을 들 수 있겠고, 강한 인본원리의 예시로는 강한 핵력의 강도가 실제값보다 0.5%정도 다르다거나 전기력이 4%정도만 다를 경우, 탄소, 산소가 생기기 힘들어 우리와 같은 생명체는 존재하기 힘들었을 것이다. 또, 만약 양성자의 질량이 0.2%만 더 컸어도 중성자로 붕괴했을 것이고, 공간이 3차원이여서 안정적인 타원궤도가 가능하며 태양이 산산조각나거나 블랙홀이 되지 않는다. 이 외에도 우주상수의 크기가 아주 적당해 지금의 안정적인 우주가 가능했다.  이렇듯 우리는 매우 기적적인 환경에서 존재한다는 것을 쉽게 알 수 있다. 우리는 이러한 절묘한 미세조정을 어떻게 받아들여야 할까 정말 위대한 설계자인 신이라는 존재가 있어 이러한 위대한 설계를 해 놓은 것일까  그러나 우리는 앞에서 보았듯이 현대 과학의 답변을 알고있다. 우리 우주는 각기 다른 법칙들을 지닌 수많은 우주들 중의 하나일 뿐이다. 이 발상은 신의 존재를 부정하기 위한 것이 아니라 현대우주론들의 많은 이론들과 무경계조건의 귀결이다. 따라서 만약 어떤 지적인 생명체가 우주에서 자신의 위치와 상태등을 파악해 본다면 그 생명체는 이런 기적적인 환경에 처해있음을 깨달을 수밖에 없게되는 것이다.   8. 위대한 설계  이렇게 우리는 발전해 왔다. 자연현상에서 법칙들을 발견하고 이를 통해 세상을 해석할 수 있다는 자신감에 차있다. 하지만 이런 자연법칙들은 우주가 '어떻게' 행동하는지 알려주지만 이 책의 첫 장에 제기됬던 더 근본적인 질문인 '왜'냐는 질문에는 대답하지 못한다. 이때문에 사람들은 신의 존재를 필요로 했었지만 호킹은 온전히 과학의 범위 안에서, 어떤 신적인 존재에도 호소하지않고, 위의 질문들에 대답할 수 있다고 한다.   모형에 의존하지 않고 실재 여부를 판단 할 수 없기에 실재와 창조에 대한 성찰에 도움이 되는 존 콘웨이가 발명한 생명게임에 대해 살펴보자.  이 게임은 정사각형들이 일정한 규칙에 의해서 세대를 거듭해 나가며 모양이 변하는 게임이다(자세한 게임방법은 책에 나온다). 이를 통해 자기와 같은 모양의 패턴을 만들어 내기 위한(복제) 최소의 정사각형 갯수는 10조 개 정도의 규모이다. 이는 세포 하나에 들어있는 분자의 개수와 대체로 일치한다고 한다. 즉, 세포 한개 정도의 규모면 법칙들에 의해 자기 복제가 가능하다.  자연의 모든 것들은 자연법칙을 따르지만 인간은 자유의지가 있어 자연법칙을 따르지 않는 것처럼 보일 수도 있다. 하지만 호킹은 만약 우리 몸을 구성하는 입자들 전부의 초기조건을 알고 있다면 인간도 자연법칙에 의해 다음 행동을 예측할 수 있을 것이라는 말이다. 다만 이것이 불가능하기에 자유의지를 지녔다는 말을 할 수는 있다.  이는 실제로 인간이 자유의지를 지녔다는것이 아니라 그 계산을 할 능력이 없음을 인정하는 것이다.  그리고 에너지 보존법칙을이용해 무(無)에서 무언가 창조될 수 있다고 주장한다. 그리고 우주가 무로 부터 창조될 수 있게 중력과 같은 법칙이 존재하는 이유를 들어 설명한다. 에너지 보존법칙에 의해 블랙홀이나 별과 같은 것들은 무로 부터 창조될 수 없지만 우주 전체는 그럴 수 있다. 즉 '자발적 창조'가 가능하고 실제로 창조 했다. 이것이 바로 무가 아니라 무언가 존재하는 이유이고, 우주가 존재하는 이유이다.  그리고 이러한 스스로 우주를 창조하는 모형이 될 수 있는 M이론은 3000년 넘게 이어져온 탐구의 성공적인 결과가 될 것이다. 즉, 위대한 설계를 발견하게 되는 것이다.   이책은 대단하다. 이렇게 정말 영원히 대답할 수 없을 것 같았던 첫장에서 소개되었던 질문들에 대답을 하고야 만다. 비록 첫번째 질문인 왜 무가 아니라 무엇인가 존재하느냐는 이유에 대한 대답이 자발적 창조라고 하지만 이는 결코 억지스러운 결론이 아니다. 우리가 존재하는 이유도 마찬가지로 우주의 자발적 창조로 가능했으며 물리적 미세조정인 위대한 설계를 통해 인간과 같은 지적인 존재까지 나타날 수 있었다.   또 우리 우주의 법칙들은 왜 지금과 같은 법칙들이여야만 하냐면 지금의 우주가 그러하기 때문이라고 답할 수 있을 것 같다. 중력이 존재해야 하는 이유나 초대칭성이 있어야 하는 이유들, 그리고 그것들의 미세조정으로 인해 기적속에 살고 있는 우리들. 앞에서도 말했듯이 어떤 지적인 생명체가 자신들의 위치를 파악해 본다면 그럴 수 밖에 없다. 그래야만 그들이 존재할 수 있다.  이러한 내용이 아무리 3000년 과학탐구의 결론이란 것이라지만 누군가에게는 분명히 받아들이기 껄끄러운 내용일 수 있다. 하지만 너무 충격을 받을 필요는 없을 것같다. 이 역시 이론에 불과하다. 이 이론이 나같이 아무것도 모르는 사람의 마음을 설레게 하기엔 충분 할 순 있지만 내 인생관이나 가치관과 이 모형이 부합하지 않게 되면 설사 난 이 모형이 정말 만물의 궁극적인 이론이라 할 지라도 나는 나의 상황에 맞게 바꿔서 인식할 자신이 있다. 모형의존적실재론을 택하면 단지 '관찰'에만 부합하면 되는 것이지 어떤게 더 실재적이냐 하는 논쟁은 의미가 없기 때문이다. 하지만 난 아직까지는 호킹이 설명한 만물의 모형이 아주 마음에 든다. 억지스럽지 않고 충분히 우아하며 지금까지의 관찰을 잘 반영한 것 같기 때문이다. 호킹은 이렇게 궁극적인 물음에 대답할 수 있기에 현대물리사에 이제 '전환점'이 필요한 잠정적으로는 매듭이 지어졌다고 생각하는 것 같다.   유명한 과학자 수학자들을 보면 과학자겸 철학자, 수학자겸 철학자 등 굉장히 많다. 당장 이 책의 역자인 전대호박사만 봐도 그렇다. 왜 그러한 과학자 수학자들이 철학자가 될까 생각해보면 과학과 수학이라는 것의 본질 상 깊게 파고 들어가면 그럴 수 밖에 없는 것 같다. 둘다 생각의 과정에 논리적인 오류가 침범하는 것을 용납하지 않는다. 그렇게 자연법칙들을 기술하다 보면 결국 저러한 나의존재, 우주의 존재등의 궁극적인 이유에 대해서 생각해 볼 수 밖에 없을테고, 이에 대한 대답은 그리 쉬운 문제가 아니었다.   그러다 현대에 와서야 비로소 이정도의 그럴싸한 답변을 내어 놓을 수 있게 되었고, 이렇게 과학자들에 의해 신은 죽어가고 철학은 죽었으며 과학자들의 손에 횃불이 쥐어져 있다고 한 것 같다.  이 책을 읽고나니 왠지모르게 어느정도 속이 후련하다.   \"],\n",
       " [19534,\n",
       "  '   [화폐인물]지폐 꿈꾸는 자들의 초상나는 꿈꾼다.늘 어디론가 떠나기로.세계 곳곳 구석구석 누비고 싶다.더 넓은 세상, 더 많은 사람들을 만나고 싶기 때문이다.그렇다면 지구상의 수 많은 나라를 각각 대표할 수 있는 것들은 무엇일까..?음식, 건축물, 축제, 언어, 등등등나는 해당 나라의 지폐라고 생각한다.그 나라를 상징하면서도 그 나라 국민들이 가장 자주 사용하게 될지도 모르는..그래서일까?지폐에 나타나는 인물은 국민들에게 존경받는 인물이고 영향력이 큰 인물이여야한다.그만큼 선정되기도 선정하기도 어렵다.이 책은 그 선정되기 까다롭다는 각국의 지폐의 인물들을 소개해준다.지폐를 알게되면 그 인물을 알게되고인물을 알게되면 그 역사을 알게되고역사를 알게되면 그 나라가 눈에 보인다.이 책 한권으로도 지구 한바퀴를 여행한 기분이다.   '],\n",
       " [8790,\n",
       "  '   2015313543 화학공학/고분자공학부 김지원 <화학의 시대를 읽고> 처음에 ‘화학의 시대’를 읽고 독후감을 써야한다는 말씀을 듣고 제일 먼저 생각난 것은 ‘같기도 하고 아니 같기도 하고’라는 책이었다. 고등학생 때 독서모임에서 그 책을 읽고 넋이 나갔던 기억이 났다. 그 때는 화학에 대한 막연한 관심과 흥미를 가지고 화학공학과로 진학하겠다는 목표만 있었을 뿐 화학에 관한 전문성은 없었던 시기였다. 처음에 ‘카이랄’이라는 단어를 보고 정신을 못 차렸던 기억이 난다. 그 책은 어린 나이의 나에게 그저 어렵기만하고 딱딱하기만 한 책이었다. 어느 덧 몇 년이 지나 다시 ‘화학의 시대’라는 책을 읽을 기회가 생겼다. 물론 지금도 전문성이라고는 찾기 힘들지만 고등학생 때보다는 내가 하고 싶은 일이 구체적으로 그려져서 조금 더 흥미롭게 책을 읽을 수 있었다. 많은 챕터들 중에서 제 5장 ‘분자 하나를 집을 수 있는 집게’를 제일 재밌게 읽었다. 특히 ‘이러한 각각의 분자 일꾼들은 자율적인 의식이 아니라 화학적 원리에 따라 움직인다.’라는 부분이 기억에 남는다. 분자들이 생각을 할 수 있는 것은 아닌데, 그리고 인간이 이런 분자가 이런 일을 했으면 좋겠다고 생각하는 것도 아닌데도 인간의 몸은 끊임없이 화학반응을 거치고 있다. 물론 우리의 몸이 존재할 수 있고 지탱되는 데에는 화학적 기작이 매우 중요한 역할을 한다. 우리가 매일 밥을 먹고 에너지를 얻는 과정에서도 화학적 분해가 일어난다. 심지어 유전정보를 담고 있는 DNA도 그 자체가 화학적 분자이며 DNA에 담겨있는 유전암호가 번역되어 생성되는 단백질도 화학분자이다. 우리는 우리 생활 속의 화학을 너무나도 당연하게 여긴다. 하지만 화학은 우리의 삶과 아주 많은 부분에 깊이 관련되어있고, 그만큼 중요하다는 것을 절감할 수 있다.  이 책에서는 고도의 분자 인식 과정 중의 하나로 분자 고리를 설명하고 있다. 어떤 분자들이 특정한 금속 이온에만 달라붙고 다른 이온에는 붙지 않는 선택성을 보인다는 것이다. 고리 안쪽의 산소와 같은 원자들이 많이 결합되어 있어서 이온은 아니지만 금속 이온을 끌어당길 수 있는 것이다. 여기서 무척이나 흥미로웠던 점은 지난주에 ‘약과 건강’이라는 수업에서 비슷한 내용을 들었다는 것이다. 찰스 페더슨이 석유화학 산업 분야와 관련해서 연구하던 왕관형 에테르는 초기의 목적에서 더 나아가 약으로도 쓰이게 되었다, 이는 세포막을 넘나드는 금속 이온에 관여하는 모넨신이라는 항생물질로 탄생하게 되었다. 페더슨이 왕관형 에테르로 노벨상을 수상하였으며 이온은 이온과만 결합한다고 생각했던 그 시대로써는 획기적인 발견이 아닐 수 없다고 말씀해주셨던 교수님의 말씀이 기억난다.  이렇듯 금속이온을 조절하는 화학물질이 생명체에게도 영향을 끼칠 수 있는 것은 실로 놀라운 일이 아닐 수 없다. 왕관형 에테르뿐만 아니라 다른 약물들이 미시적인 물질이 거시적인 효과를 내는 것이 신비롭고 어떻게 그런 효과를 내는 것인지 항상 궁금해왔다. 그래서 나는 생명체에 작용하는 화학적 기작을 연구하는 것을 진로로 생각하고 있다. 그래서인지 더 감명 깊은 챕터였고, 또한 ‘화학의 시대’라는 책이 오래 기억에 남을 것 같다.   '],\n",
       " [3116,\n",
       "  \"    평범한 시와 주석으로 이루어진 소설인 줄 알고 중후반까지 큰 흥미를 갖지 못한 채 느릿느릿 읽어나가다가, 같은 길을 달리는 듯 보이던 시와 주석이 점점 두 갈래로 나뉘더니 완전히 다른 갈림길로 뻗어나가는 모습에 눈 뜨고 코 베이는 기분으로 감상했다. 하나의 책으로 엮였지만 완전히 다른 두 글이 물과 기름처럼 분리되어 있었다. 그러나 그 두 작품을 함께 취급해야 비로소 완벽한 하나의 소설이 된다는 점에서 결국 분리할 수 없는 글이었다. 처음에는 시인 셰이드의 작품을 그의 '유일한' 벗인 킨보트가 주석자로서 충실하게 해석해주는 책에 불과하다고 여겼다. 그리고 실제로도 책은 초반부까지 그렇게 굴었다. 그러나 셰이드의 구절들이 점점 킨보트의 이야기 주제로만 다뤄지고, 시간이 흐를수록 아예 시 구절과 관련이 없는 내용으로 주석이 가득 채워지기도 한다. 셰이드가 바닥에 떨어진 낙엽에 대해 이야기하고 있었다면 킨보트는 그 낙엽에 대한 주석으로 어느 나라를 다스리던 국왕의 탈출기를 적어버린다. 또는 그가 셰이드에 대해 어떻게 생각하는지, 셰이드의 아내인 시빌에 대해서는 또 어떻게 생각하는지와 같은 자신의 생각을 적기 바쁘다. 주석의 탈을 쓰고 킨보트가 하고 싶은 말을 적는 일기에 가까운 글이 되어가는데, 이렇게 점진적으로 주석자의 위치가 실제 작품의 주인공과 바뀌며 주객전도되는 양상과 그가 스스로 정체를 드러내는 그 모든 방식들은 천에 물이 스며들듯이 빠르고 교묘하게 흐른다. 갑작스러운 반전의 장면을 넣기보다, 천천히 시간을 들여 한 문장씩 본모습을 드러낸다. 킨보트가 명시적으로 자신의 정체를 드러내는 구간은 꽤 후반부에 나오지만, 그러한 표현을 마주하기까지 독자는 이미 킨보트라는 주석자의 수상한 행태를 여러 번 목격해 왔으므로 반전 그 자체에 충격을 받기보다는 킨보트가 여태까지 저질러 온 행동들의 의도를 천천히 짜맞추며 그의 주석과 셰이드의 시, 킨보트의 진짜 의도를 마주하는 것에서 형용할 수 없는 놀라움을 느낀다. 그는 셰이드의 작품이 자신의 자전적인 작품이 되리라 생각했으나 그의 시를 보고 지금껏 자기가 그에게 준 영향들이 소용이 없었음을 깨달은 것이다. 때문에 주석자를 자처했고, 시의 내용은 그대로 둔 채 그 의도를 모조리 자기 입맛대로 서술한다. 그것이 사실인지 아닌지는 중요하지 않은 듯, 그는 살아남은 자로서 역사를 해설하는 막강하고 달콤한 권리를 휘두른다. 읽는 내내 소름이 끼치고 왠지 모를 불쾌한 감정히 은밀히, 끊임없이 들었다. 마지막 순간에는 그 감정이 극에 달했는데, 그 이유는 아마 킨보트가 자신의 목적을 더이상 숨길 생각도 없다는 모습이 보였으며 그가 온전히 셰이드의 '시'만을 원하고 있었음이 드러났기 때문일 것이다. 남의 시를 아예 제 것인양 챙기고, 코트 주머니에 챙겨 입고 다니며 '나의 젬블라'라고까지 말한다. 그의 완성된 시를 처음 보고서는 자신이 그렇게 젬블라에 대한 이야기를 열심히 전해 주었음에도 그 소재가 미미하여 셰이드를 배신자라고 말하기도 한다. 앞서 셰이드의 시와 킨보트의 주석이 마치 서로 다른 두 작품 같지만 하나의 작품으로 취급해야 재미있는 소설로 읽힐 수 있다고 했는데, 조금 더 추가하자면 이 책을 구성하는 모든 단락들이 하나의 소설인 것 같다는 생각이 든다. 일반적으로 책의 본문만 그 내용을 담고 있다면, <창백한 불꽃>은 머리말과 셰이드의 시, 킨보트의 주석, 뒤에 해설까지 모두 각각 퍼즐 한 조각씩을 맡고 있기 때문에 모두를 한꺼번에 아울러 봐야 그것이 진정한 하나의 본문으로서 기능하는 것 같다.    \"],\n",
       " [960,\n",
       "  '   \"즉 모든 자살자는 미친 사람이라는 것이다. 그러나 정말 자살이라는 정신병이 존재할까?\"(본문 36쪽) 성균관대학교 고유의 학과진입 시스템 아래, 공대에서 사회과학계열로 새롭게 진학한 나는 경제학과와 사회학과 사이의 진로를 고민하고 있다. 그러니 나는 <자살론>을 읽어야 했다. 그 명성에도 불구하고 대학교 입학 이후까지 이 책을 읽기를 미루게 된 것은 제목으로 인한 심리적 장벽 때문이었다. \\'자살\\'이라는 단어가 주는 거부감, 그 언급 자체에 대한 암묵적 터부. 깊이 없는 심리 공감 에세이가 판을 치고 많은 이의 조롱을 사는 상황에서 에밀 뒤르켐은 어떤 불편한 위로를 건네고자 노력했기에 명저로 불리는지 궁금했다. 그러나, 그러니 이번 책에 대한 독후감은 간략한 요약만을 거친 후 나의 감상에 집중하고자 한다. 자살의 원인을 크게 비사회적 요인, 그리고 사회적 요인으로 나누어 철저하고 치밀하게 이루어진 뒤르켐의 논의를 따라가는 과정은 흥미롭다. 자살은 정신질환인가? 주세(Jousset)와 모로(Moreau de Tours)에 따른 4가지 정신병적 자살의 종류를 보자. 상상적 충동을 동기삼은 광란증 자살, 주변과 유대하지 못하는 우울증 자살, 합리적 동기 없이 죽음의 욕구를 느끼는 강박증 자살, 혹은 그러한 지속적 동기조차 없는 충동적 자살. 마땅한 외부적 이유 없는 정신병 환자의 자살과 달리 많은 우리들의 죽음은 이유가 있으니  정신 질환과의 상관이론은 폐기. 월별 기온과 자살률에 대한 수치를 통해, 기후에 따른 온도와 뇌 흥분 사이 관계를 다룬 페리(Ferri)의 결론에 반박. 인종별 자살률 통계를 종교에 따라 재구분함으로써, 뒤르켐은 인종과 유전에 따른 이론을 뒤집어 끌어옴으로써 사회적 요인을 강조한 자신의 논리를 펼쳐 보인다. 그러므로 우리는 사회적인 탓에 이기적으로, 이타적으로, 아노미성으로, 혹은 숙명적으로 자살한다.내용 정리를 마치며, 앞서 적지 않은 가장 중요한 사항을 강조하고 싶다. 단 몇 자 안에 모두 넣기에는 지나치게 논리적인 이 논증 과정은 자살이라는 용어를 정의하는 일로부터 시작한다는 점이다. 자신이 서 있는 높이를 착각한 몽유병 환자의 추락사는 자살인가? 종교인의 희생적인 순교는 자살인가? 전쟁에서 목숨을 다해 싸운 군인의 죽음은 과연 자살인가?무수한 고민을 거친 뒤르켐은 자살을 \\'희생자 자신이 일어나게 될 결과를 알고 행하는 적극적 혹은 소극적 행위에서 비롯되는 직접적 혹은 간접적 결과로 일어나는 모든 인간의 죽음 사례\\'로 정의내린다. 그러니 에밀 뒤르켐의 <자살론>은 책이라고 하기보다는 논문 출판본에 가깝다고 보아야겠다. 이번 학년도에 수강한 <사회과학입문> 강의를 통한 배움은 이 책을 바탕으로 완성되었다. 한 사람의 학문적 고민을 따라가며 결론을 향해 다가가는 논박의 과정은 어느 추리소설보다도 긴박하고 아름다웠다. 너무나도 복잡한 인간의 삶을 완벽에 가까운 근거를 바탕으로 분석해나가는 사회과학은 이 시대에 위상을 잃어가는 인문학이 공학에 못지 않게 과학적이라는 사실을, 그것이 우리 사회를 멋지게 위로하기에 무엇보다도 의미깊은 학문이라는 것을 온몸으로 증명한다.스스로의 부족한 문장력과 요약 능력이 원망스러울 정도로 흥미진진한 에밀 뒤르켐의 <자살론>을 직접 한 줄 한 줄 읽어내려가기를 바라며, 나는 경제학과와 사회학과 사이의 고민을 끝맺을 수 있을 듯하다.   '],\n",
       " [16848,\n",
       "  \"   사실 나는 글을 잘 쓰지 못한다. 그래도 좋은 책을 알리고 싶어서 부족하지만 독서노트를 쓰기로 했다.  나는 책을 선택하는 것에 있어서 조금 제한적이다. 주로 소설, 그것도 추리소설같은 반전있는 내용을 좋아한다. 책의 출신도 신경쓰는 편이다. 일본 소설에 두 번이나 실망한 이후에는 보지 않고 있다. 그러다 문득 너무 편향된 취향과 관점이 좋지 않다는 것을 깨달았고 다른 분야에 관심이 있었던 만큼, 깊이 있는 지식이 쌓고 싶어졌다. 그래서 선택한 책이 심리학 책이었다. 평소에 관심이 있던 분야였기 때문이다.  '가끔은 제정신'은 일단 제목부터가 마음에 들었다. '우리는 늘 착각 속에 산다' 라는 문구가 공감이 됐다.보통 심리학과 관련된 책은 어렵고 심오해서 접근하기가 어렵다. 물론 부담스럽게 두껍기도하고..하지만 이책은 누구라도 쉽고 재미있게 읽을 수 있는 책이다. 작가는 모든 사람들이 착각을 하고 살고 있으며, 착각 속에 살고 있는 사람들의 생각과 행동을 사실적으로 콕집어서 말하고 있다. 착각을 하고 있다는 진실이 불편하게 다가 올 수도 있겠지만 나는 너무 재미있게, 공감하면서 읽었다. 나도 착각을 하며 살고 있다는 사실을 인정하면서...(물론 너무나 뜨끔했지만..) 내용을 간단히 설명하자면...책은 크게 5가지의 주제로 나누어있다. 1. 착각의 진실, 내게만 그럴듯하다.2. 착각의 효용, 나를 지키려면 반드시 필요하다3. 착각의 속도, 깨달음보다 언제나 빠르다.4. 착각의 활용, 콩깍지를 씌워라.5. 착각의 예방, 방법은 하나뿐이다.책은 먼저, 착각이 무엇이고 우리가 무슨 착각을 하고 있는 설명한다. 그 착각은 의식적으로 자신을 보호하기 위해 행해지기도 하며 무의식적으로 행해지기도 한다.또한 그 착각을 잘 활용해야 하며 피할 수 없다면 착각이 사라질 것을 대비하라고 말한다. 과연 우리가 맞다고 믿고 있는 사실들중 100%진실인 것이 몇이나 될까? 맞다는 것을 당연하다고 착각하고 있는건 아닐까?내 생각이 정답인데 왜 저 사람은 틀린 답을 말하고 있다고 착각하지는 않는가?나는 착각을 하고 있지 않다고 착각하고 있진 않은가?작가은 글을 읽는 독자에게 계속해서 질문을 던진다. 동시에 착각을 하고있음을 인정하라고 말한다. 착각을 하지 않는 것을 불가능하다고.. 하지만 착각이 나쁜 것은 아니라고.. 착각을 해야 행복할 수 있다고..다만 그 착각을 잘 활용해야된다고 말한다. 나는 마음만 먹으면 다 할 수 있다는 착각, 우리 가족이 최고라는 착각, 언젠가는 복권에 당첨될거라는 착각...마지막으로 작가는 말한다. 착각에서 깨어나기 위해 노력하기보다는 현실을 착각과 비슷하게 만들어보려고 노력하라고... 착각이 현실에 되는 그 순간을 위해 우리 모두 노력하자고...  자신을 착각을 하고 있다고 느끼고 그 것을 쿨하게 인정할 자신이 있으며 착각을 활용하고 싶다면 이 책을 읽기를 추천하고 싶다. 책의 진가를 설명하기엔 이 글이 너무 부족하니 꼭 읽어보시기를 바란다.     \"]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a584c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"doc_list.pkl\",\"wb\") as f:\n",
    "    pickle.dump(doc_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b8e0f1a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"doc_list.pkl\",\"rb\") as f:\n",
    "    doc_list_load = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "000b88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2912.3"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listLen = 0\n",
    "for i in doc_list_load:\n",
    "    listLen += len(i[1])\n",
    "listLen / len(doc_list_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e962077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_all_mpnet_base_v2 = joblib.load('./kw_model_all-mpnet-base-v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d4aeaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_base = joblib.load('./kw_model_base.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "89fc1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_distiluse_base_multilingual_cased_v1 = joblib.load('./kw_model_distiluse-base-multilingual-cased-v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7879c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_klue_bert_base = joblib.load('./kw_model_klue_bert-base.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5c6d7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_klue_roberta_base = joblib.load('./kw_model_klue_roberta-base.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fe001a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_klue_roberta_small = joblib.load('./kw_model_klue_roberta-small.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "563f8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_klue_roberta_large = joblib.load('./kw_model_klue_roberta-large.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c54eab0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12145"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_list_load[4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "491bab24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_list_load[5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0c8a908d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('생활환경', 0.4338), ('재구성한다', 0.4202), ('매력적이다', 0.4059), ('객관적으로', 0.3983), ('인간의', 0.3976)]\n",
      "keywords_1: 0.41116\n",
      "[('관점에서 재구성한다', 0.4717), ('역사의 내용이다', 0.465), ('불과함을 적나라하게', 0.462), ('생활환경 변화의', 0.4619), ('수백만 전의', 0.4603)]\n",
      "keywords_2: 0.46418\n",
      "[('독자의 상상력을 자극한다', 0.5061), ('역사는 수백만 전의', 0.5048), ('독특한 관점에서 재구성한다', 0.5038), ('종들과는 구별되는 특성을', 0.4951), ('육식을 하는 동물의', 0.4937)]\n",
      "keywords_3: 0.5006999999999999\n",
      "13.1042 sec\n",
      "[('성균관대학교에서', 0.5298), ('천재과학자의', 0.5279), ('성균관대학교', 0.5189), ('일상생활의', 0.5139), ('문과학생들을', 0.5131)]\n",
      "keywords_1: 0.5207200000000001\n",
      "[('천재과학자의 현학적인', 0.6098), ('작동하는 방식과', 0.5667), ('성균관대학교에서 일어날', 0.5592), ('면모와 과학자로서의', 0.5578), ('과학자의 이미지와는', 0.5488)]\n",
      "keywords_2: 0.56846\n",
      "[('천재과학자의 현학적인 대화인', 0.6638), ('인간적인 면모와 과학자로서의', 0.6315), ('과학의 역할과 의미를', 0.6241), ('속에서 과학의 역할과', 0.6101), ('정치가 작동하는 방식과', 0.6092)]\n",
      "keywords_3: 0.62774\n",
      "15.2764 sec\n",
      "[('국어국문학과', 0.489), ('형이상학과', 0.4846), ('공리주의의', 0.4559), ('공리주의적', 0.4548), ('의도성을', 0.4432)]\n",
      "keywords_1: 0.4655\n",
      "[('국어국문학과 장재영', 0.6396), ('공리주의의 간학문적', 0.6133), ('존재론이나 형이상학과', 0.6062), ('공리주의적 관점에서', 0.6024), ('입법의 가능성과', 0.5848)]\n",
      "keywords_2: 0.60926\n",
      "[('의해서 인간의 행동', 0.6577), ('국어국문학과 장재영 도덕과', 0.6495), ('공리주의적 관점에서 과학적으로', 0.648), ('우선 존재론이나 형이상학과', 0.6479), ('공리주의 2014310297 국어국문학과', 0.6337)]\n",
      "keywords_3: 0.64736\n",
      "15.2196 sec\n",
      "[('의식과', 0.4573), ('성의가', 0.4375), ('조상과', 0.4235), ('선악과', 0.4194), ('생명의', 0.4031)]\n",
      "keywords_1: 0.42816\n",
      "[('의리란 선악과', 0.5033), ('의식과 사상을', 0.4786), ('생명관 도덕적', 0.4752), ('인간은 조상과', 0.4729), ('사대 의식을', 0.4656)]\n",
      "keywords_2: 0.47912\n",
      "[('도덕적으로 인간은 조상과', 0.4984), ('중의 하나인 긍정을', 0.4884), ('책에서는 제사에 대해서', 0.4865), ('순정성이다 의리란 선악과', 0.4849), ('사상이다 우리 한국의', 0.4845)]\n",
      "keywords_3: 0.4885400000000001\n",
      "12.4897 sec\n",
      "[('불확정성의', 0.5494), ('일반상대성이론과', 0.5255), ('절대적시간과', 0.5142), ('상대성이론과', 0.5079), ('중성자들의', 0.4992)]\n",
      "keywords_1: 0.51924\n",
      "[('자연법칙과 신의', 0.6078), ('객관적인 실재의', 0.5966), ('완전한 법칙들의', 0.5932), ('인생관이나 가치관과', 0.5804), ('의해 전자기력과', 0.5795)]\n",
      "keywords_2: 0.5915\n",
      "[('인물들에 의해 전자기력과', 0.6368), ('행동하는지 알려주지만 책의', 0.6352), ('불확정적이라는 말은 당신의', 0.6298), ('인생관이나 가치관과 모형이', 0.6186), ('움직이는 물체나 원자정도의', 0.6148)]\n",
      "keywords_3: 0.62704\n",
      "64.5773 sec\n",
      "[('지구상의', 0.4913), ('등등등나는', 0.442), ('생각한다', 0.4339), ('자들의', 0.4181), ('각국의', 0.4129)]\n",
      "keywords_1: 0.43964\n",
      "[('자들의 초상나는', 0.5326), ('등등등나는 해당', 0.5196), ('그렇다면 지구상의', 0.5098), ('인물들을 소개해준다', 0.499), ('지구상의 많은', 0.4886)]\n",
      "keywords_2: 0.5099199999999999\n",
      "[('등등등나는 해당 나라의', 0.5896), ('꿈꾸는 자들의 초상나는', 0.5505), ('자들의 초상나는 꿈꾼다', 0.5464), ('언어 등등등나는 해당', 0.53), ('나라의 지폐라고 생각한다', 0.5198)]\n",
      "keywords_3: 0.54726\n",
      "3.1398 sec\n",
      "[('화학공학과로', 0.5601), ('이온과만', 0.5144), ('화학분자이다', 0.4911), ('화학물질이', 0.4906), ('왕관형', 0.4897)]\n",
      "keywords_1: 0.50918\n",
      "[('작용하는 화학적', 0.6209), ('조절하는 화학물질이', 0.5922), ('막연한 관심과', 0.5895), ('화학공학과로 진학하겠다는', 0.5804), ('단백질도 화학분자이다', 0.5623)]\n",
      "keywords_2: 0.58906\n",
      "[('화학공학과로 진학하겠다는 목표만', 0.6499), ('의식이 아니라 화학적', 0.6435), ('처음에 화학의 시대', 0.638), ('속의 화학을 너무나도', 0.6363), ('생활 속의 화학을', 0.6107)]\n",
      "keywords_3: 0.63568\n",
      "9.8057 sec\n",
      "[('생각하는지와', 0.4707), ('주인공과', 0.4291), ('반전의', 0.4011), ('완전히', 0.3927), ('생각하는지', 0.3898)]\n",
      "keywords_1: 0.41668000000000005\n",
      "[('작품의 주인공과', 0.5069), ('다스리던 국왕의', 0.5014), ('국왕의 탈출기를', 0.4744), ('명시적으로 자신의', 0.4713), ('점진적으로 주석자의', 0.4676)]\n",
      "keywords_2: 0.48432\n",
      "[('국왕의 탈출기를 적어버린다', 0.5344), ('다스리던 국왕의 탈출기를', 0.5334), ('진정한 하나의 본문으로서', 0.5236), ('해석해주는 책에 불과하다고', 0.5218), ('생각하는지와 같은 자신의', 0.5193)]\n",
      "keywords_3: 0.5265\n",
      "10.5732 sec\n",
      "[('성균관대학교', 0.5884), ('정의내린다', 0.5471), ('정신질환인가', 0.5412), ('문장력과', 0.5387), ('상관이론은', 0.5384)]\n",
      "keywords_1: 0.55076\n",
      "[('질환과의 상관이론은', 0.6048), ('정신 질환과의', 0.5952), ('36쪽 성균관대학교', 0.5907), ('부족한 문장력과', 0.5899), ('나는 경제학과와', 0.582)]\n",
      "keywords_2: 0.5925199999999999\n",
      "[('경제학과와 사회학과 사이의', 0.637), ('추락사는 자살인가 종교인의', 0.6277), ('착각한 몽유병 환자의', 0.6167), ('질환과의 상관이론은 폐기', 0.6131), ('몽유병 환자의 추락사는', 0.609)]\n",
      "keywords_3: 0.6207\n",
      "10.3283 sec\n",
      "[('착각하지는', 0.4893), ('노력하기보다는', 0.4812), ('불가능하다고', 0.4782), ('무의식적으로', 0.4709), ('의식적으로', 0.4707)]\n",
      "keywords_1: 0.47806\n",
      "[('착각은 의식적으로', 0.587), ('착각의 진실', 0.567), ('책의 출신도', 0.5664), ('당연하다고 착각하고', 0.5627), ('착각을 활용하고', 0.5606)]\n",
      "keywords_2: 0.56874\n",
      "[('노력하기보다는 현실을 착각과', 0.6455), ('불가능하다고 하지만 착각이', 0.5932), ('착각은 의식적으로 자신을', 0.5918), ('착각의 진실 내게만', 0.5917), ('심리학과 관련된 책은', 0.5848)]\n",
      "keywords_3: 0.6013999999999999\n",
      "8.3244 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_whole(loaded_model_base, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4c401a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('역사부문에서', 0.6974), ('우선적으로', 0.692), ('재구성한다', 0.6831), ('문명들에', 0.6775), ('중요하지만', 0.6696)]\n",
      "keywords_1: 0.68392\n",
      "[('내용은 우리가', 0.7386), ('동시에 주제가', 0.7366), ('하나하나에 숨겨져', 0.7323), ('우선적으로 하는', 0.7306), ('우리의 기원에', 0.7279)]\n",
      "keywords_2: 0.7332\n",
      "[('내용이 우리가 자주', 0.7529), ('이유는 우리가 얼마나', 0.7495), ('동시에 주제가 주제인', 0.7489), ('우리가 다른 영장류와', 0.7473), ('우리는 우리 자신에', 0.7459)]\n",
      "keywords_3: 0.7489000000000001\n",
      "68.9312 sec\n",
      "[('문과학생들을', 0.655), ('전문지식을', 0.6534), ('수식만큼이나', 0.6502), ('인간적인', 0.6269), ('비추어본다면', 0.6138)]\n",
      "keywords_1: 0.63986\n",
      "[('조국의 재건을', 0.7039), ('숙고와 고심하는', 0.6789), ('본인의 연구', 0.677), ('중심으로 움직인다', 0.677), ('무기화에는 적극', 0.6746)]\n",
      "keywords_2: 0.68228\n",
      "[('조국의 재건을 위해', 0.7097), ('이후 조국의 재건을', 0.7029), ('후에는 무기화에는 적극', 0.6945), ('수식과 실험에만 몰두하는', 0.6942), ('아니고 그의 수식과', 0.6909)]\n",
      "keywords_3: 0.69844\n",
      "76.2360 sec\n",
      "[('운동에는', 0.6628), ('연구들에서', 0.6476), ('대한민국의', 0.6434), ('분석하는데', 0.6409), ('인문학적', 0.6389)]\n",
      "keywords_1: 0.64672\n",
      "[('수학의 흔적은', 0.6828), ('밴담은 운동에는', 0.6791), ('연구들에서 과학이나', 0.6788), ('영국의 경험주의라는', 0.6784), ('경우에는 중학교', 0.6743)]\n",
      "keywords_2: 0.67868\n",
      "[('공리주의 2014310297 국어국문학과', 0.7395), ('넘나드는 공리주의 2014310297', 0.736), ('2014310297 국어국문학과 장재영', 0.7111), ('수학의 흔적은 거의', 0.6914), ('연구들에서 과학이나 수학의', 0.6899)]\n",
      "keywords_3: 0.71358\n",
      "79.0678 sec\n",
      "[('제사에', 0.5938), ('사진이나', 0.5873), ('제사가', 0.5836), ('글자에', 0.5827), ('제사', 0.5807)]\n",
      "keywords_1: 0.5856199999999999\n",
      "[('기사는 제사', 0.6103), ('한다 제사가', 0.601), ('존재와 제사', 0.595), ('제사 제목에', 0.5808), ('중에 하나가', 0.5805)]\n",
      "keywords_2: 0.59352\n",
      "[('찾아보아야 한다 제사가', 0.6006), ('귀신 존재와 제사', 0.5921), ('나는 귀신과 제사', 0.5839), ('귀신과 제사 제목에', 0.5811), ('존재와 제사 의례의', 0.5809)]\n",
      "keywords_3: 0.5877199999999998\n",
      "82.2918 sec\n",
      "[('움직인다는', 0.7288), ('누군가에게는', 0.7282), ('불가능하기에', 0.7277), ('현대물리사에', 0.7213), ('현대우주론들의', 0.7199)]\n",
      "keywords_1: 0.7251799999999999\n",
      "[('질문이다 이책은', 0.7496), ('따라 움직인다는', 0.748), ('죽어가고 철학은', 0.7473), ('아니라 현대우주론들의', 0.7453), ('우리가 존재하는지에', 0.7446)]\n",
      "keywords_2: 0.74696\n",
      "[('연구하는 과정에서 개발되었다', 0.7691), ('아니라 현대우주론들의 많은', 0.762), ('발견하지 못했던 연주시차나', 0.761), ('죽어가고 철학은 죽었으며', 0.7582), ('일때만 일관적이다 우리가', 0.7567)]\n",
      "keywords_3: 0.7614\n",
      "294.3551 sec\n",
      "[('국민들에게', 0.7174), ('인물이고', 0.6898), ('인물들을', 0.6875), ('인물은', 0.6822), ('국민들이', 0.6779)]\n",
      "keywords_1: 0.6909599999999999\n",
      "[('나타나는 인물은', 0.7378), ('국민들에게 존경받는', 0.7322), ('존경받는 인물이고', 0.7246), ('나라 국민들이', 0.722), ('인물들을 소개해준다', 0.7216)]\n",
      "keywords_2: 0.72764\n",
      "[('지구상의 많은 나라를', 0.7429), ('지폐에 나타나는 인물은', 0.7409), ('인물들을 소개해준다 지폐를', 0.7408), ('존경받는 인물이고 영향력이', 0.7398), ('지폐의 인물들을 소개해준다', 0.7314)]\n",
      "keywords_3: 0.73916\n",
      "15.1818 sec\n",
      "[('화학분자이다', 0.6669), ('중요하다는', 0.6665), ('연구하는', 0.655), ('전문성은', 0.6524), ('화학물질이', 0.6512)]\n",
      "keywords_1: 0.6584\n",
      "[('기작을 연구하는', 0.7034), ('이라는 수업에서', 0.6934), ('분해가 일어난다', 0.6909), ('움직인다 라는', 0.6902), ('화학은 우리의', 0.6857)]\n",
      "keywords_2: 0.6927199999999999\n",
      "[('기작을 연구하는 것을', 0.7133), ('분해가 일어난다 심지어', 0.6981), ('분자가 이런 일을', 0.6897), ('실로 놀라운 일이', 0.6881), ('역할을 한다 우리가', 0.688)]\n",
      "keywords_3: 0.69544\n",
      "38.2051 sec\n",
      "[('순간에는', 0.7031), ('구성하는', 0.688), ('주인공과', 0.6838), ('해석해주는', 0.6766), ('주석자의', 0.6751)]\n",
      "keywords_1: 0.6853199999999999\n",
      "[('주석자의 수상한', 0.7433), ('주석으로 이루어진', 0.7407), ('구성하는 모든', 0.7351), ('점에서 결국', 0.735), ('자체에 충격을', 0.7349)]\n",
      "keywords_2: 0.7378\n",
      "[('구간은 후반부에 나오지만', 0.7674), ('해석해주는 책에 불과하다고', 0.7628), ('후반부에 나오지만 그러한', 0.7554), ('작품의 주인공과 바뀌며', 0.7479), ('낙엽에 대한 주석으로', 0.7464)]\n",
      "keywords_3: 0.75598\n",
      "43.9198 sec\n",
      "[('자살을', 0.6946), ('자살은', 0.6878), ('자살인가', 0.6743), ('자살', 0.6699), ('자살이라는', 0.66)]\n",
      "keywords_1: 0.6773200000000001\n",
      "[('우울증 자살', 0.7043), ('자살인가 무수한', 0.7042), ('죽음은 이유가', 0.7), ('그러나 정말', 0.6966), ('추락사는 자살인가', 0.6916)]\n",
      "keywords_2: 0.6993400000000001\n",
      "[('죽음은 이유가 있으니', 0.7014), ('이라는 단어가 주는', 0.6893), ('죽음은 과연 자살인가', 0.6892), ('못하는 우울증 자살', 0.6881), ('때문이었다 자살 이라는', 0.6833)]\n",
      "keywords_3: 0.6902600000000001\n",
      "45.5317 sec\n",
      "[('언젠가는', 0.6839), ('불가능하다고', 0.6832), ('착각하지는', 0.6745), ('부족하지만', 0.669), ('설명하자면', 0.6653)]\n",
      "keywords_1: 0.6751799999999999\n",
      "[('불가능하다고 하지만', 0.7104), ('무슨 착각을', 0.707), ('실망한 이후에는', 0.7022), ('자신을 착각을', 0.7008), ('나는 착각을', 0.6976)]\n",
      "keywords_2: 0.7036\n",
      "[('나는 글을 쓰지', 0.7303), ('우리는 착각 속에', 0.7257), ('산다 라는 문구가', 0.7174), ('무슨 착각을 하고', 0.7124), ('우리가 무슨 착각을', 0.7113)]\n",
      "keywords_3: 0.7194200000000001\n",
      "43.2255 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_whole(loaded_model_all_mpnet_base_v2, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6788296c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('역사는', 0.3598), ('역사적', 0.3527), ('역사이다', 0.3518), ('역사의', 0.349), ('역사를', 0.3423)]\n",
      "keywords_1: 0.35112\n",
      "[('역사적 과학적', 0.3876), ('흔히 역사를', 0.3512), ('역사부문에서 두드러지게', 0.3426), ('역사를 통해', 0.3415), ('역사이다 기나긴', 0.3409)]\n",
      "keywords_2: 0.35275999999999996\n",
      "[('역사를 통해 배운다', 0.3836), ('역사이다 기나긴 역사', 0.3783), ('단순한 암기보다는 전후', 0.3751), ('암기보다는 전후 관계를', 0.3651), ('이해하고 미래까지 엿볼', 0.3541)]\n",
      "keywords_3: 0.37124\n",
      "8.8144 sec\n",
      "[('성균관대학교에서', 0.4947), ('성균관대학교', 0.4564), ('성균관대에서', 0.3717), ('캠퍼스가', 0.2829), ('이과학생들이', 0.2375)]\n",
      "keywords_1: 0.36863999999999997\n",
      "[('성균관대학교에서 일어날', 0.5167), ('있는 성균관대학교에서', 0.4899), ('비단 성균관대학교', 0.442), ('성균관대학교 뿐만', 0.4398), ('성균관대에서 개최된', 0.3887)]\n",
      "keywords_2: 0.45542\n",
      "[('성균관대학교에서 일어날 법한', 0.5311), ('있는 성균관대학교에서 일어날', 0.5127), ('되어 있는 성균관대학교에서', 0.4717), ('이는 비단 성균관대학교', 0.4475), ('비단 성균관대학교 뿐만', 0.4355)]\n",
      "keywords_3: 0.47970000000000007\n",
      "9.6658 sec\n",
      "[('도덕과', 0.4239), ('철학적으로', 0.3802), ('철학적', 0.3768), ('철학', 0.3579), ('원칙을', 0.3537)]\n",
      "keywords_1: 0.3785\n",
      "[('도덕과 입법의', 0.5471), ('장재영 도덕과', 0.4462), ('입법의 원칙에', 0.4399), ('입법 원칙이', 0.4356), ('공리주의를 철학', 0.4279)]\n",
      "keywords_2: 0.45933999999999997\n",
      "[('도덕과 입법의 원칙에', 0.6155), ('장재영 도덕과 입법의', 0.5438), ('공리주의가 입법 원칙이', 0.5173), ('국어국문학과 장재영 도덕과', 0.4772), ('나에게 도덕과 입법의', 0.4573)]\n",
      "keywords_3: 0.52222\n",
      "10.7683 sec\n",
      "[('제사라고', 0.3308), ('종교성을', 0.2937), ('제사에', 0.288), ('제사', 0.2863), ('조상님을', 0.286)]\n",
      "keywords_1: 0.29696\n",
      "[('조상님을 숭배하기', 0.391), ('제사 의례의', 0.3769), ('귀신과 제사', 0.3581), ('조상 숭배의', 0.3558), ('조상 숭배에', 0.352)]\n",
      "keywords_2: 0.3667599999999999\n",
      "[('제사를 지내는 집안이', 0.4126), ('제사를 조상을 숭배하기', 0.4118), ('제사 조상 숭배', 0.4105), ('귀신과 제사 라는', 0.3993), ('의례의 유교적 종교성을', 0.3901)]\n",
      "keywords_3: 0.40486000000000005\n",
      "12.3576 sec\n",
      "[('양자물리학', 0.5034), ('양자중력이론을', 0.4991), ('현대물리학이', 0.4862), ('물리학이', 0.4522), ('물리학을', 0.4402)]\n",
      "keywords_1: 0.47622\n",
      "[('책은 현대물리학이', 0.6039), ('책이 철학적이라는', 0.5418), ('양자물리학 이론들도', 0.534), ('초중력이론이라는 양자중력이론을', 0.5299), ('이론들도 고전물리학이', 0.5201)]\n",
      "keywords_2: 0.5459400000000001\n",
      "[('책은 현대물리학이 지금까지', 0.6209), ('설계 책이 철학적이라는', 0.5917), ('그러나 책은 현대물리학이', 0.5579), ('이론들도 고전물리학이 매우', 0.5489), ('아인슈타인의 상대성이론은 물리학을', 0.5426)]\n",
      "keywords_3: 0.5724\n",
      "62.8246 sec\n",
      "[('화폐인물', 0.4227), ('지폐의', 0.421), ('지폐를', 0.407), ('지폐', 0.4005), ('지폐에', 0.3941)]\n",
      "keywords_1: 0.40906000000000003\n",
      "[('지폐 꿈꾸는', 0.6075), ('각국의 지폐의', 0.4737), ('나라의 지폐라고', 0.4725), ('지폐의 인물들을', 0.4433), ('화폐인물 지폐', 0.4429)]\n",
      "keywords_2: 0.48797999999999997\n",
      "[('화폐인물 지폐 꿈꾸는', 0.6264), ('지폐 꿈꾸는 자들의', 0.6066), ('각국의 지폐의 인물들을', 0.4946), ('지폐라고 생각한다 나라를', 0.4811), ('나라의 지폐라고 생각한다', 0.4574)]\n",
      "keywords_3: 0.5332199999999999\n",
      "3.1121 sec\n",
      "[('화학공학과로', 0.4806), ('화학공학', 0.4662), ('화학의', 0.4473), ('화학을', 0.4381), ('화학은', 0.4352)]\n",
      "keywords_1: 0.45348\n",
      "[('화학의 시대', 0.5402), ('화학의 시대를', 0.5366), ('2015313543 화학공학', 0.5017), ('처음에 화학의', 0.4833), ('화학공학과로 진학하겠다는', 0.483)]\n",
      "keywords_2: 0.50896\n",
      "[('화학의 시대 읽고', 0.5614), ('처음에 화학의 시대', 0.5518), ('화학의 시대를 읽고', 0.551), ('화학의 시대 라는', 0.5339), ('김지원 화학의 시대를', 0.521)]\n",
      "keywords_3: 0.54382\n",
      "9.9181 sec\n",
      "[('소설이', 0.357), ('소설로', 0.3507), ('소설인', 0.3218), ('책으로', 0.2438), ('책의', 0.2387)]\n",
      "keywords_1: 0.3024\n",
      "[('소설로 읽힐', 0.4012), ('하나의 소설이', 0.3936), ('재미있는 소설로', 0.3827), ('이루어진 소설인', 0.3766), ('하나의 소설인', 0.3746)]\n",
      "keywords_2: 0.38574\n",
      "[('완벽한 하나의 소설이', 0.4569), ('책으로 엮였지만 완전히', 0.4211), ('주석으로 이루어진 소설인', 0.4175), ('재미있는 소설로 읽힐', 0.3964), ('감상했다 하나의 책으로', 0.3879)]\n",
      "keywords_3: 0.41596\n",
      "10.6508 sec\n",
      "[('자살이라는', 0.4496), ('자살론', 0.4329), ('자살인가', 0.4293), ('자살자는', 0.4242), ('자살률에', 0.4181)]\n",
      "keywords_1: 0.43082000000000004\n",
      "[('자살자는 미친', 0.6307), ('자살이라는 정신병이', 0.5869), ('자살은 정신질환인가', 0.5751), ('정신병적 자살의', 0.5449), ('자살론 책이라고', 0.532)]\n",
      "keywords_2: 0.57392\n",
      "[('자살자는 미친 사람이라는', 0.6888), ('모든 자살자는 미친', 0.6556), ('자살이라는 정신병이 존재할까', 0.6075), ('정말 자살이라는 정신병이', 0.5968), ('자살은 정신질환인가 주세', 0.5695)]\n",
      "keywords_3: 0.62364\n",
      "10.1465 sec\n",
      "[('소설', 0.4759), ('소설에', 0.4642), ('추리소설같은', 0.3746), ('독서노트를', 0.3718), ('책을', 0.309)]\n",
      "keywords_1: 0.3991\n",
      "[('일본 소설에', 0.5102), ('주로 소설', 0.5097), ('좋은 책을', 0.4934), ('소설 그것도', 0.4648), ('좋아한다 책의', 0.4572)]\n",
      "keywords_2: 0.48705999999999994\n",
      "[('편이다 일본 소설에', 0.5366), ('소설에 번이나 실망한', 0.5129), ('일본 소설에 번이나', 0.5121), ('그래도 좋은 책을', 0.5096), ('주로 소설 그것도', 0.5033)]\n",
      "keywords_3: 0.5149\n",
      "8.8539 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_whole(loaded_model_distiluse_base_multilingual_cased_v1, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "12dd9c42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('숲속에', 0.9617), ('숲에', 0.9605), ('있다', 0.9597), ('생각했던', 0.9596), ('싶은', 0.9596)]\n",
      "keywords_1: 0.96022\n",
      "[('재미있었다 저자는', 0.9662), ('때문이다 인간은', 0.9637), ('매력적이다 곤충을', 0.9635), ('것이다 그러나', 0.9628), ('영장류 숲속에', 0.9627)]\n",
      "keywords_2: 0.9637800000000001\n",
      "[('동시에 재미있었다 저자는', 0.9685), ('재미있었다 저자는 자신이', 0.9672), ('되기 때문이다 인간은', 0.9667), ('나타나는 특성이다 우리는', 0.9663), ('하는지를 있다 서론에서', 0.966)]\n",
      "keywords_3: 0.9669399999999999\n",
      "271.3007 sec\n",
      "[('철학이라는', 0.9679), ('철학이었음을', 0.9675), ('철학에', 0.9674), ('철학적인', 0.9671), ('것이었다', 0.9669)]\n",
      "keywords_1: 0.96736\n",
      "[('철학적인 내용이', 0.9701), ('철학이라는 틀에', 0.9693), ('속에서 과학의', 0.969), ('철학이 현대사회와', 0.969), ('학문이라고 생각하는', 0.969)]\n",
      "keywords_2: 0.96928\n",
      "[('인식되고 있는 철학이', 0.971), ('호기심을 철학이라는 틀에', 0.9703), ('것이기도 하였다 실험실에', 0.9703), ('철학이라는 틀에 맞춰', 0.9699), ('일이다 역시 생활속의', 0.9699)]\n",
      "keywords_3: 0.97028\n",
      "307.4745 sec\n",
      "[('미시적이고', 0.9682), ('것이었지만', 0.9679), ('있었으나', 0.9675), ('철학적', 0.9675), ('공리주의적', 0.9675)]\n",
      "keywords_1: 0.9677200000000001\n",
      "[('사상이었다는 또한', 0.9698), ('이유이다 나에게', 0.9697), ('책이다 제러미', 0.9696), ('사상을 참조하는', 0.9694), ('이론이 참조되는', 0.9693)]\n",
      "keywords_2: 0.9695599999999999\n",
      "[('과학 것이다 철학적', 0.9713), ('이유이다 나에게 공리주의란', 0.9708), ('체계적인 사상으로 만들고자', 0.9707), ('공리주의는 사고의 대상이자', 0.9706), ('이론을 철학적으로 설명하고자', 0.9704)]\n",
      "keywords_3: 0.97076\n",
      "314.3624 sec\n",
      "[('절충적이고', 0.9673), ('생각되었다', 0.967), ('호전적이고', 0.967), ('확립되었을', 0.9669), ('생활에', 0.9667)]\n",
      "keywords_1: 0.9669800000000001\n",
      "[('있다고 생각되었다', 0.9689), ('생활에 스며들게', 0.9688), ('관심이 있고', 0.9687), ('책에서도 관심이', 0.9686), ('특징으로는 융화이다', 0.9685)]\n",
      "keywords_2: 0.9686999999999999\n",
      "[('책에서도 관심이 있고', 0.9706), ('특징으로는 융화이다 융화는', 0.9702), ('유교의 특징으로는 융화이다', 0.9702), ('관심이 있고 흥미롭게', 0.9699), ('생활에 스며들게 있을', 0.9698)]\n",
      "keywords_3: 0.97014\n",
      "338.2945 sec\n",
      "[('m이론까지', 0.9666), ('m이론이다', 0.9662), ('철학적이라는', 0.9661), ('m이론에', 0.9659), ('생각했다', 0.9656)]\n",
      "keywords_1: 0.96608\n",
      "[('질문이다 이책은', 0.9704), ('게임이다 자세한', 0.9703), ('뿐이다 발상은', 0.9699), ('이유이다 그리고', 0.9698), ('증명되었다 아인슈타인은', 0.9696)]\n",
      "keywords_2: 0.97\n",
      "[('중요한 개념이다 이론에', 0.9729), ('확신하고있다 이런식의 생각으로', 0.9726), ('이론이라고 확신하고있다 이런식의', 0.9723), ('있다는것이다 단지 뉴턴이론과', 0.9719), ('m이론이다 이러한 m이론에', 0.9718)]\n",
      "keywords_3: 0.9723\n",
      "1445.9893 sec\n",
      "[('생각한다', 0.9629), ('사람들을', 0.9614), ('기분이다', 0.9614), ('인물이여야한다', 0.961), ('때문이다', 0.961)]\n",
      "keywords_1: 0.96154\n",
      "[('어렵다 책은', 0.9713), ('때문이다 그렇다면', 0.9697), ('싶다 넓은', 0.9688), ('싶기 때문이다', 0.9648), ('알게되고인물을 알게되면', 0.9641)]\n",
      "keywords_2: 0.96774\n",
      "[('선정하기도 어렵다 책은', 0.9728), ('싶기 때문이다 그렇다면', 0.9727), ('때문이다 그렇다면 지구상의', 0.9702), ('어렵다 책은 선정되기', 0.9689), ('싶다 넓은 세상', 0.9669)]\n",
      "keywords_3: 0.9703000000000002\n",
      "63.8344 sec\n",
      "[('책이었다', 0.9714), ('생각했던', 0.9706), ('생각하는', 0.9702), ('화학물질이', 0.9701), ('생명체에게도', 0.9699)]\n",
      "keywords_1: 0.97044\n",
      "[('딱딱하기만 책이었다', 0.973), ('있어서 이온은', 0.9724), ('조절하는 화학물질이', 0.9721), ('읽을 있었다', 0.9718), ('속의 화학을', 0.9717)]\n",
      "keywords_2: 0.9722\n",
      "[('어렵기만하고 딱딱하기만 책이었다', 0.9739), ('속의 화학을 너무나도', 0.9738), ('기억이 난다 책은', 0.9737), ('결합되어 있어서 이온은', 0.9735), ('분자이며 dna에 담겨있는', 0.9732)]\n",
      "keywords_3: 0.97362\n",
      "267.2572 sec\n",
      "[('글이었다', 0.9525), ('생각했으나', 0.9521), ('주석자로서', 0.952), ('읽어나가다가', 0.9515), ('바뀌며', 0.9515)]\n",
      "keywords_1: 0.95192\n",
      "[('글이었다 처음에는', 0.9656), ('것이다 때문에', 0.9627), ('여겼다 그리고', 0.9622), ('것이다 남의', 0.9602), ('감상했다 하나의', 0.9598)]\n",
      "keywords_2: 0.9621000000000001\n",
      "[('것이다 때문에 주석자를', 0.9674), ('깨달은 것이다 때문에', 0.9658), ('기분으로 감상했다 하나의', 0.965), ('것이다 남의 시를', 0.9644), ('여겼다 그리고 실제로도', 0.9634)]\n",
      "keywords_3: 0.9652000000000001\n",
      "261.2885 sec\n",
      "[('읽어내려가기를', 0.9745), ('읽기를', 0.9744), ('감상에', 0.9743), ('과학적이라는', 0.9743), ('때문이었다', 0.9743)]\n",
      "keywords_1: 0.9743600000000001\n",
      "[('바탕으로 완성되었다', 0.9761), ('이후까지 책을', 0.9758), ('고민을 따라가며', 0.9756), ('않게 과학적이라는', 0.9756), ('장벽 때문이었다', 0.9756)]\n",
      "keywords_2: 0.97574\n",
      "[('책을 바탕으로 완성되었다', 0.9774), ('학문적 고민을 따라가며', 0.9772), ('나의 감상에 집중하고자', 0.9767), ('이후까지 책을 읽기를', 0.9766), ('않게 과학적이라는 사실을', 0.9766)]\n",
      "keywords_3: 0.9769\n",
      "254.4920 sec\n",
      "[('책이었다', 0.9601), ('책이다', 0.957), ('사람은', 0.957), ('읽었다', 0.9569), ('깨달음보다', 0.9568)]\n",
      "keywords_1: 0.95756\n",
      "[('하나뿐이다 책은', 0.9644), ('책이었다 평소에', 0.964), ('책이다 작가는', 0.9619), ('읽었다 나도', 0.9607), ('심리학 책이었다', 0.96)]\n",
      "keywords_2: 0.9621999999999999\n",
      "[('있는 책이다 작가는', 0.9648), ('심리학 책이었다 평소에', 0.9648), ('하나뿐이다 책은 먼저', 0.964), ('책이다 작가는 모든', 0.9636), ('방법은 하나뿐이다 책은', 0.9635)]\n",
      "keywords_3: 0.9641400000000001\n",
      "211.8546 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_whole(loaded_model_klue_bert_base, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e03c3d3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('암기보다는', 0.9742), ('매력적이다', 0.9739), ('라는', 0.9731), ('보여주며', 0.973), ('것이다', 0.973)]\n",
      "keywords_1: 0.9734399999999999\n",
      "[('것이다 그러나', 0.9771), ('잡은 우리의', 0.9752), ('있다 나아가면', 0.975), ('것이다 오늘날', 0.975), ('합리적인 생활환경', 0.9749)]\n",
      "keywords_2: 0.9754400000000001\n",
      "[('것이다 그러나 충분히', 0.9784), ('대상이었다 그러나 우리는', 0.9778), ('것이다 오늘날 우리가', 0.9775), ('통해 배운다 라는', 0.9765), ('통해 바라볼 있다', 0.9764)]\n",
      "keywords_3: 0.9773200000000001\n",
      "81.0641 sec\n",
      "[('철학이라는', 0.9648), ('일상생활', 0.9645), ('양자역학', 0.9645), ('수식만큼이나', 0.9644), ('양자역학을', 0.9644)]\n",
      "keywords_1: 0.96452\n",
      "[('것이었다 과학자는', 0.9684), ('것이었다 생활속의', 0.9683), ('것이다 하지만', 0.9673), ('성균관대학교 뿐만', 0.9671), ('통해 양자역학', 0.967)]\n",
      "keywords_2: 0.9676199999999999\n",
      "[('것이었다 생활속의 양자', 0.9708), ('생각했다 하지만 수업과', 0.9701), ('것이었다 과학자는 일상생활에서', 0.9697), ('인식시켜 것이었다 과학자는', 0.9695), ('어렵다는 것이다 하지만', 0.9691)]\n",
      "keywords_3: 0.9698399999999999\n",
      "90.9583 sec\n",
      "[('공리주의란', 0.9662), ('공리주의로', 0.966), ('8장', 0.9657), ('공리주의라는', 0.9653), ('것은', 0.9648)]\n",
      "keywords_1: 0.9656\n",
      "[('과학 이라는', 0.9674), ('것이다 그는', 0.9671), ('것이다 철학적', 0.9669), ('나에게 도덕과', 0.9666), ('공리주의의 최대', 0.9666)]\n",
      "keywords_2: 0.96692\n",
      "[('철학 사상이 아니다', 0.9687), ('또한 작용했다 나는', 0.9687), ('아니다 입법과 과학이라는', 0.9683), ('공리주의라는 개념을 어디서', 0.9683), ('공리주의를 철학 사상으로', 0.9683)]\n",
      "keywords_3: 0.96846\n",
      "98.0181 sec\n",
      "[('찾아보아야', 0.9643), ('것은', 0.9642), ('절충적이고', 0.9641), ('유교라는', 0.9638), ('중심으로', 0.9638)]\n",
      "keywords_1: 0.96404\n",
      "[('유교를 이해함으로', 0.9675), ('것이다 하지만', 0.9672), ('것이다 또한', 0.9671), ('있다 귀신이라는', 0.9663), ('것이었다 이렇게', 0.9662)]\n",
      "keywords_2: 0.9668599999999999\n",
      "[('것이다 또한 제사를', 0.9701), ('생각되었다 한국 유교와', 0.9697), ('읽었다 한국 유교의', 0.9695), ('있다 또한 우리는', 0.969), ('생각하였다 하지만 제사를', 0.9689)]\n",
      "keywords_3: 0.96944\n",
      "89.3236 sec\n",
      "[('양자이론은', 0.9764), ('노력들도', 0.9757), ('m이론은', 0.9757), ('고전이론들이다', 0.9757), ('것이고', 0.9755)]\n",
      "keywords_1: 0.9758000000000001\n",
      "[('있을것이다 이를', 0.9791), ('입장이다 따라서', 0.979), ('고전이론들이다 왜냐하면', 0.9784), ('때문이다 따라서', 0.9783), ('있다 그러나', 0.978)]\n",
      "keywords_2: 0.9785600000000001\n",
      "[('없기 때문이다 하지만', 0.9809), ('마찬가지로 고전이론들이다 왜냐하면', 0.9805), ('설명할 있다는것이다 단지', 0.98), ('생각을 위태롭게 수도', 0.9796), ('문제이다 따라서 객관적인', 0.9795)]\n",
      "keywords_3: 0.9801\n",
      "423.6690 sec\n",
      "[('선정되기도', 0.9684), ('때문이다', 0.9684), ('지폐의', 0.9679), ('선정하기도', 0.9679), ('선정되기', 0.9679)]\n",
      "keywords_1: 0.9681000000000001\n",
      "[('때문이다 그렇다면', 0.9719), ('선정하기도 어렵다', 0.9711), ('인물은 국민들에게', 0.9708), ('화폐인물 지폐', 0.9705), ('지폐를 알게되면', 0.9703)]\n",
      "keywords_2: 0.9709200000000001\n",
      "[('싶기 때문이다 그렇다면', 0.9734), ('선정되기도 선정하기도 어렵다', 0.9725), ('어렵다 책은 선정되기', 0.972), ('때문이다 그렇다면 지구상의', 0.9719), ('지폐의 인물들을 소개해준다', 0.9718)]\n",
      "keywords_3: 0.9723200000000001\n",
      "16.4418 sec\n",
      "[('화학공학과로', 0.9719), ('dna도', 0.9712), ('분자이며', 0.971), ('화학공학', 0.9708), ('항생물질로', 0.9707)]\n",
      "keywords_1: 0.97112\n",
      "[('분자이며 dna에', 0.9749), ('화학은 우리의', 0.9744), ('가지고 화학공학과로', 0.9729), ('단백질도 화학분자이다', 0.9726), ('dna도 자체가', 0.9724)]\n",
      "keywords_2: 0.9734400000000001\n",
      "[('하지만 화학은 우리의', 0.9754), ('화학적 분자이며 dna에', 0.975), ('화학에 관한 전문성은', 0.9742), ('노벨상을 수상하였으며 이온은', 0.974), ('어렵기만하고 딱딱하기만 책이었다', 0.974)]\n",
      "keywords_3: 0.97452\n",
      "59.7816 sec\n",
      "[('같다', 0.968), ('적어버린다', 0.9677), ('셰이드의', 0.9675), ('말한다', 0.9675), ('배신자라고', 0.9675)]\n",
      "keywords_1: 0.9676400000000001\n",
      "[('있었다 그러나', 0.9709), ('것이다 남의', 0.9698), ('바쁘다 주석의', 0.9698), ('감상했다 하나의', 0.9696), ('글이었다 처음에는', 0.9696)]\n",
      "keywords_2: 0.9699399999999999\n",
      "[('굴었다 그러나 셰이드의', 0.9746), ('분리되어 있었다 그러나', 0.973), ('것이다 남의 시를', 0.972), ('있었다 그러나 작품을', 0.9717), ('감상했다 하나의 책으로', 0.9716)]\n",
      "keywords_3: 0.97258\n",
      "63.2987 sec\n",
      "[('때문이었다', 0.973), ('점이다', 0.9728), ('과학적이라는', 0.9723), ('것은', 0.9723), ('추리소설보다도', 0.9722)]\n",
      "keywords_1: 0.97252\n",
      "[('사례 정의내린다', 0.9752), ('자살 이라는', 0.9752), ('것이다 그러나', 0.9748), ('점이다 자신이', 0.9741), ('질환과의 상관이론은', 0.974)]\n",
      "keywords_2: 0.9746599999999999\n",
      "[('때문이었다 자살 이라는', 0.9769), ('흥미롭다 자살은 정신질환인가', 0.9767), ('것이다 그러나 정말', 0.9757), ('강박증 자살 혹은', 0.9754), ('광란증 자살 주변과', 0.9753)]\n",
      "keywords_3: 0.976\n",
      "60.3174 sec\n",
      "[('맞다는', 0.9668), ('것은', 0.9667), ('그럴듯하다', 0.9661), ('편이다', 0.9658), ('깨달음보다', 0.9658)]\n",
      "keywords_1: 0.96624\n",
      "[('하나뿐이다 책은', 0.9696), ('책은 어렵고', 0.9687), ('책이었다 평소에', 0.9686), ('때문이다 가끔은', 0.9685), ('읽었다 나도', 0.9684)]\n",
      "keywords_2: 0.96876\n",
      "[('심리학 책이었다 평소에', 0.9716), ('하나뿐이다 책은 먼저', 0.9705), ('방법은 하나뿐이다 책은', 0.9703), ('했다 나는 책을', 0.9701), ('주제로 나누어있다 착각의', 0.9701)]\n",
      "keywords_3: 0.9705199999999999\n",
      "55.0050 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_whole(loaded_model_klue_roberta_base, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1feafb6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2챕터', 0.812), ('2챕터일', 0.812), ('1챕터', 0.8091), ('1챕터와', 0.8091), ('에서는', 0.8059)]\n",
      "keywords_1: 0.80962\n",
      "[('기대감이 깃들어있다', 0.8446), ('말해주고 있다', 0.8411), ('간과되어서는 것이다', 0.8393), ('이야기한다 인간을', 0.8382), ('관점에서 재구성한다', 0.8352)]\n",
      "keywords_2: 0.8396800000000001\n",
      "[('인간을 바라보고자 한다', 0.8745), ('이야기한다 인간을 지칭하는', 0.8647), ('현생인류의 등장에 대해', 0.8597), ('나타나는 특성이다 우리는', 0.8573), ('역사부문에서 두드러지게 나타나는', 0.8564)]\n",
      "keywords_3: 0.86252\n",
      "41.3753 sec\n",
      "[('양자역학은', 0.7861), ('느끼곤한다', 0.7847), ('상대성이론을', 0.7829), ('사유한다는', 0.7818), ('정치인에게서도', 0.7801)]\n",
      "keywords_1: 0.78312\n",
      "[('개념을 활용한다는', 0.8382), ('비하하는 내용이라는', 0.8332), ('다루는 양자역학은', 0.832), ('천재과학자의 현학적인', 0.8304), ('숙고하였다 하이젠베르크는', 0.8258)]\n",
      "keywords_2: 0.83192\n",
      "[('문과학생들을 비하하는 내용이라는', 0.8619), ('개념을 바탕으로 사유한다는', 0.8615), ('철학 개념을 활용한다는', 0.856), ('세계를 다루는 양자역학은', 0.8534), ('개념을 활용한다는 것과', 0.8466)]\n",
      "keywords_3: 0.8558800000000002\n",
      "43.5313 sec\n",
      "[('항목화하고자', 0.7877), ('비실증적인', 0.7835), ('경험주의라는', 0.7827), ('222p에서부터는', 0.7778), ('실현하고자', 0.7774)]\n",
      "keywords_1: 0.78182\n",
      "[('입법과 과학이라는', 0.8425), ('밴담과 공리주의는', 0.8358), ('공리주의로 실현하고자', 0.8339), ('국민이라면 공리주의라는', 0.8296), ('공리주의를 통한', 0.8286)]\n",
      "keywords_2: 0.8340799999999999\n",
      "[('철학적 사상이 과학적인', 0.86), ('공리주의를 통한 입법의', 0.8598), ('공리주의적 관점에서 과학적으로', 0.8581), ('관점에서 밴담과 공리주의는', 0.8579), ('공리주의로 실현하고자 했다', 0.8573)]\n",
      "keywords_3: 0.8586199999999999\n",
      "45.7825 sec\n",
      "[('생각되었다', 0.815), ('연관되어있다', 0.8115), ('생각하였다', 0.7937), ('순정성이다', 0.7897), ('유교에서는', 0.7884)]\n",
      "keywords_1: 0.7996599999999999\n",
      "[('추구하는 사상이다', 0.8483), ('생각하게 되었다', 0.842), ('역사와 연관되어있다', 0.836), ('있다고 생각되었다', 0.8325), ('의미이지만 절충적이고', 0.831)]\n",
      "keywords_2: 0.83796\n",
      "[('통합을 추구하는 사상이다', 0.8703), ('생각되었다 한국 유교와', 0.8578), ('종교성을 조명하는 글이다', 0.8564), ('글자에 관심이 많아졌고', 0.8526), ('의미를 무엇일까 책에서는', 0.8522)]\n",
      "keywords_3: 0.85786\n",
      "47.9167 sec\n",
      "[('실재론이라는', 0.849), ('양자이론이라고', 0.8436), ('양자장이론이라고', 0.8404), ('m이론이란', 0.8377), ('초중력이론이라는', 0.8356)]\n",
      "keywords_1: 0.8412600000000001\n",
      "[('이론이라고 확신하고있다', 0.8723), ('만든것이 양자이론이라고', 0.8636), ('책이 철학적이라는', 0.8601), ('있는 이론이라고', 0.8561), ('근본적인 근사이론들이며', 0.8546)]\n",
      "keywords_2: 0.86134\n",
      "[('있는 이론이라고 확신하고있다', 0.8813), ('이론들보다 근본적인 근사이론들이며', 0.8783), ('과학소설같다 하지만 양자이론은', 0.8746), ('근사이론들이며 타당성이 있는', 0.8746), ('상대성이론은 물리학을 혁명적으로', 0.8736)]\n",
      "keywords_3: 0.8764799999999999\n",
      "200.7180 sec\n",
      "[('인물이여야한다', 0.8127), ('싶다', 0.7669), ('국민들에게', 0.7598), ('소개해준다', 0.7581), ('한권으로도', 0.7567)]\n",
      "keywords_1: 0.77084\n",
      "[('영향력이 인물이여야한다', 0.8324), ('누비고 싶다', 0.8235), ('인물이여야한다 그만큼', 0.8221), ('인물들을 소개해준다', 0.8164), ('자들의 초상나는', 0.8099)]\n",
      "keywords_2: 0.8208599999999999\n",
      "[('지폐의 인물들을 소개해준다', 0.8479), ('꿈꾸는 자들의 초상나는', 0.8479), ('나라의 지폐라고 생각한다', 0.8432), ('그래서일까 지폐에 나타나는', 0.8398), ('인물이고 영향력이 인물이여야한다', 0.8393)]\n",
      "keywords_3: 0.8436199999999999\n",
      "8.1960 sec\n",
      "[('궁금해왔다', 0.8198), ('독서모임에서', 0.814), ('에테르는', 0.8128), ('화학공학과로', 0.8102), ('책이었다', 0.805)]\n",
      "keywords_1: 0.81236\n",
      "[('화학공학과로 진학하겠다는', 0.8474), ('전문성이라고는 찾기', 0.8392), ('라는 책이었다', 0.8389), ('가지고 화학공학과로', 0.8383), ('책이었다 고등학생', 0.8371)]\n",
      "keywords_2: 0.8401800000000001\n",
      "[('생성되는 단백질도 화학분자이다', 0.8613), ('가지고 화학공학과로 진학하겠다는', 0.861), ('고분자공학부 김지원 화학의', 0.8605), ('책이었다 고등학생 독서모임에서', 0.8588), ('라는 책이었다 고등학생', 0.8558)]\n",
      "keywords_3: 0.8594799999999999\n",
      "34.6441 sec\n",
      "[('글이었다', 0.7875), ('엮였지만', 0.7839), ('감상했다', 0.7823), ('주객전도되는', 0.7815), ('행동들의', 0.7815)]\n",
      "keywords_1: 0.7833399999999999\n",
      "[('적는 일기에', 0.8272), ('해석해주는 책에', 0.8265), ('셰이드의 구절들이', 0.8244), ('셰이드를 배신자라고', 0.8243), ('책으로 엮였지만', 0.8234)]\n",
      "keywords_2: 0.8251600000000001\n",
      "[('셰이드의 킨보트의 주석', 0.8466), ('소설인 같다는 생각이', 0.8463), ('말을 적는 일기에', 0.8444), ('글이 되어가는데 이렇게', 0.84), ('책으로 엮였지만 완전히', 0.8392)]\n",
      "keywords_3: 0.8432999999999999\n",
      "31.9828 sec\n",
      "[('과학적이라는', 0.8225), ('상관이론은', 0.8155), ('정신질환인가', 0.8102), ('책이라고', 0.8095), ('자살이라는', 0.808)]\n",
      "keywords_1: 0.81314\n",
      "[('자살론 책이라고', 0.869), ('자살은 정신질환인가', 0.8495), ('질환과의 상관이론은', 0.8491), ('분석해나가는 사회과학은', 0.8484), ('과정은 자살이라는', 0.8468)]\n",
      "keywords_2: 0.8525600000000001\n",
      "[('뒤르켐의 자살론 책이라고', 0.8761), ('흥미롭다 자살은 정신질환인가', 0.869), ('논증 과정은 자살이라는', 0.8674), ('나의 감상에 집중하고자', 0.8664), ('때문이었다 자살 이라는', 0.864)]\n",
      "keywords_3: 0.86858\n",
      "31.7017 sec\n",
      "[('싶어졌다', 0.8169), ('나누어있다', 0.8095), ('책이었다', 0.8057), ('않은가', 0.8051), ('뜨끔했지만', 0.8042)]\n",
      "keywords_1: 0.8082799999999999\n",
      "[('활용해야된다고 말한다', 0.8563), ('착각하지는 않는가', 0.8448), ('말하고 있다고', 0.8444), ('말하고 있다', 0.8444), ('하나뿐이다 책은', 0.8438)]\n",
      "keywords_2: 0.8467399999999999\n",
      "[('착각을 활용해야된다고 말한다', 0.8781), ('지식이 쌓고 싶어졌다', 0.8742), ('착각을 하고 있다고', 0.8711), ('책을 읽기를 추천하고', 0.8709), ('책을 알리고 싶어서', 0.8704)]\n",
      "keywords_3: 0.87294\n",
      "27.9524 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_whole(loaded_model_klue_roberta_small, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9a6410c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('숲속에', 0.9617), ('숲에', 0.9605), ('있다', 0.9597), ('생각했던', 0.9596), ('싶은', 0.9596)]\n",
      "keywords_1: 0.96022\n",
      "[('재미있었다 저자는', 0.9662), ('때문이다 인간은', 0.9637), ('매력적이다 곤충을', 0.9635), ('것이다 그러나', 0.9628), ('영장류 숲속에', 0.9627)]\n",
      "keywords_2: 0.9637800000000001\n",
      "[('동시에 재미있었다 저자는', 0.9685), ('재미있었다 저자는 자신이', 0.9672), ('되기 때문이다 인간은', 0.9667), ('나타나는 특성이다 우리는', 0.9663), ('하는지를 있다 서론에서', 0.966)]\n",
      "keywords_3: 0.9669399999999999\n",
      "295.7973 sec\n",
      "[('철학이라는', 0.9679), ('철학이었음을', 0.9675), ('철학에', 0.9674), ('철학적인', 0.9671), ('것이었다', 0.9669)]\n",
      "keywords_1: 0.96736\n",
      "[('철학적인 내용이', 0.9701), ('철학이라는 틀에', 0.9693), ('속에서 과학의', 0.969), ('철학이 현대사회와', 0.969), ('학문이라고 생각하는', 0.969)]\n",
      "keywords_2: 0.96928\n",
      "[('인식되고 있는 철학이', 0.971), ('호기심을 철학이라는 틀에', 0.9703), ('것이기도 하였다 실험실에', 0.9703), ('철학이라는 틀에 맞춰', 0.9699), ('일이다 역시 생활속의', 0.9699)]\n",
      "keywords_3: 0.97028\n",
      "319.2193 sec\n",
      "[('미시적이고', 0.9682), ('것이었지만', 0.9679), ('있었으나', 0.9675), ('철학적', 0.9675), ('공리주의적', 0.9675)]\n",
      "keywords_1: 0.9677200000000001\n",
      "[('사상이었다는 또한', 0.9698), ('이유이다 나에게', 0.9697), ('책이다 제러미', 0.9696), ('사상을 참조하는', 0.9694), ('이론이 참조되는', 0.9693)]\n",
      "keywords_2: 0.9695599999999999\n",
      "[('과학 것이다 철학적', 0.9713), ('이유이다 나에게 공리주의란', 0.9708), ('체계적인 사상으로 만들고자', 0.9707), ('공리주의는 사고의 대상이자', 0.9706), ('이론을 철학적으로 설명하고자', 0.9704)]\n",
      "keywords_3: 0.97076\n",
      "360.8521 sec\n",
      "[('절충적이고', 0.9673), ('생각되었다', 0.967), ('호전적이고', 0.967), ('확립되었을', 0.9669), ('생활에', 0.9667)]\n",
      "keywords_1: 0.9669800000000001\n",
      "[('있다고 생각되었다', 0.9689), ('생활에 스며들게', 0.9688), ('관심이 있고', 0.9687), ('책에서도 관심이', 0.9686), ('특징으로는 융화이다', 0.9685)]\n",
      "keywords_2: 0.9686999999999999\n",
      "[('책에서도 관심이 있고', 0.9706), ('특징으로는 융화이다 융화는', 0.9702), ('유교의 특징으로는 융화이다', 0.9702), ('관심이 있고 흥미롭게', 0.9699), ('생활에 스며들게 있을', 0.9698)]\n",
      "keywords_3: 0.97014\n",
      "381.2225 sec\n",
      "[('m이론까지', 0.9666), ('m이론이다', 0.9662), ('철학적이라는', 0.9661), ('m이론에', 0.9659), ('생각했다', 0.9656)]\n",
      "keywords_1: 0.96608\n",
      "[('질문이다 이책은', 0.9704), ('게임이다 자세한', 0.9703), ('뿐이다 발상은', 0.9699), ('이유이다 그리고', 0.9698), ('증명되었다 아인슈타인은', 0.9696)]\n",
      "keywords_2: 0.97\n",
      "[('중요한 개념이다 이론에', 0.9729), ('확신하고있다 이런식의 생각으로', 0.9726), ('이론이라고 확신하고있다 이런식의', 0.9723), ('있다는것이다 단지 뉴턴이론과', 0.9719), ('m이론이다 이러한 m이론에', 0.9718)]\n",
      "keywords_3: 0.9723\n",
      "1435.9773 sec\n",
      "[('생각한다', 0.9629), ('사람들을', 0.9614), ('기분이다', 0.9614), ('인물이여야한다', 0.961), ('때문이다', 0.961)]\n",
      "keywords_1: 0.96154\n",
      "[('어렵다 책은', 0.9713), ('때문이다 그렇다면', 0.9697), ('싶다 넓은', 0.9688), ('싶기 때문이다', 0.9648), ('알게되고인물을 알게되면', 0.9641)]\n",
      "keywords_2: 0.96774\n",
      "[('선정하기도 어렵다 책은', 0.9728), ('싶기 때문이다 그렇다면', 0.9727), ('때문이다 그렇다면 지구상의', 0.9702), ('어렵다 책은 선정되기', 0.9689), ('싶다 넓은 세상', 0.9669)]\n",
      "keywords_3: 0.9703000000000002\n",
      "57.1171 sec\n",
      "[('책이었다', 0.9714), ('생각했던', 0.9706), ('생각하는', 0.9702), ('화학물질이', 0.9701), ('생명체에게도', 0.9699)]\n",
      "keywords_1: 0.97044\n",
      "[('딱딱하기만 책이었다', 0.973), ('있어서 이온은', 0.9724), ('조절하는 화학물질이', 0.9721), ('읽을 있었다', 0.9718), ('속의 화학을', 0.9717)]\n",
      "keywords_2: 0.9722\n",
      "[('어렵기만하고 딱딱하기만 책이었다', 0.9739), ('속의 화학을 너무나도', 0.9738), ('기억이 난다 책은', 0.9737), ('결합되어 있어서 이온은', 0.9735), ('분자이며 dna에 담겨있는', 0.9732)]\n",
      "keywords_3: 0.97362\n",
      "221.1788 sec\n",
      "[('글이었다', 0.9525), ('생각했으나', 0.9521), ('주석자로서', 0.952), ('읽어나가다가', 0.9515), ('바뀌며', 0.9515)]\n",
      "keywords_1: 0.95192\n",
      "[('글이었다 처음에는', 0.9656), ('것이다 때문에', 0.9627), ('여겼다 그리고', 0.9622), ('것이다 남의', 0.9602), ('감상했다 하나의', 0.9598)]\n",
      "keywords_2: 0.9621000000000001\n",
      "[('것이다 때문에 주석자를', 0.9674), ('깨달은 것이다 때문에', 0.9658), ('기분으로 감상했다 하나의', 0.965), ('것이다 남의 시를', 0.9644), ('여겼다 그리고 실제로도', 0.9634)]\n",
      "keywords_3: 0.9652000000000001\n",
      "240.0260 sec\n",
      "[('읽어내려가기를', 0.9745), ('읽기를', 0.9744), ('감상에', 0.9743), ('과학적이라는', 0.9743), ('때문이었다', 0.9743)]\n",
      "keywords_1: 0.9743600000000001\n",
      "[('바탕으로 완성되었다', 0.9761), ('이후까지 책을', 0.9758), ('고민을 따라가며', 0.9756), ('않게 과학적이라는', 0.9756), ('장벽 때문이었다', 0.9756)]\n",
      "keywords_2: 0.97574\n",
      "[('책을 바탕으로 완성되었다', 0.9774), ('학문적 고민을 따라가며', 0.9772), ('나의 감상에 집중하고자', 0.9767), ('이후까지 책을 읽기를', 0.9766), ('않게 과학적이라는 사실을', 0.9766)]\n",
      "keywords_3: 0.9769\n",
      "227.9893 sec\n",
      "[('책이었다', 0.9601), ('책이다', 0.957), ('사람은', 0.957), ('읽었다', 0.9569), ('깨달음보다', 0.9568)]\n",
      "keywords_1: 0.95756\n",
      "[('하나뿐이다 책은', 0.9644), ('책이었다 평소에', 0.964), ('책이다 작가는', 0.9619), ('읽었다 나도', 0.9607), ('심리학 책이었다', 0.96)]\n",
      "keywords_2: 0.9621999999999999\n",
      "[('있는 책이다 작가는', 0.9648), ('심리학 책이었다 평소에', 0.9648), ('하나뿐이다 책은 먼저', 0.964), ('책이다 작가는 모든', 0.9636), ('방법은 하나뿐이다 책은', 0.9635)]\n",
      "keywords_3: 0.9641400000000001\n",
      "191.8588 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_whole(loaded_model_klue_roberta_large, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a259925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4698f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296da01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afccb3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d62cdbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바르톨로메는 개가 아니다 (라헐 판 코에이 장편소설)\n",
      "[('양철', 0.9687), ('것은', 0.9685), ('와타나베에게서', 0.9684), ('숨쉬었다는', 0.9682), ('나오코란', 0.9682)]\n",
      "[('앉아있었다 1982년에', 0.9721), ('떠나보냈다 와타나베의', 0.9709), ('그것을 찾았다', 0.9702), ('허무하지 않은가', 0.9701), ('죽음은 그것의', 0.9699)]\n",
      "[('앉아있었다 1982년에 자신을', 0.9729), ('그것을 찾았다 삶은', 0.9727), ('좌석에 앉아있었다 1982년에', 0.9721), ('관계에서 표류하는 와타나베에게', 0.9718), ('나오코의 남자친구였다 나오코는', 0.9718)]\n",
      "104.4026 sec\n",
      "글로벌 거지 부부 (국적 초월, 나이 초월, 상식 초월, 9살 연상연하 커플의 무일푼 여행기)\n",
      "[('이었습니다제가', 0.9748), ('것은', 0.9736), ('같았습니다', 0.9732), ('흥분되었습니다', 0.9731), ('문제라는', 0.973)]\n",
      "[('충격 이었습니다제가', 0.9771), ('같습니다 저자는', 0.9768), ('않습니다 저자는', 0.9767), ('되었습니다 한마디로', 0.9754), ('것입니다 인간의', 0.9753)]\n",
      "[('같습니다 저자는 인생이', 0.9783), ('느낌은 충격 이었습니다제가', 0.9782), ('그렇습니다 역행자로서 살아가며', 0.9777), ('충격 이었습니다제가 책을', 0.9777), ('책인 같습니다 저자는', 0.9776)]\n",
      "53.2123 sec\n",
      "미스 플라이트 (박민정 장편소설)\n",
      "[('같다', 0.9641), ('문장들만으로도', 0.964), ('주옥같은', 0.9637), ('아니다', 0.9637), ('이야기다', 0.9636)]\n",
      "[('정세랑이었다 시선으로부터', 0.9676), ('감동했다 주옥같은', 0.9673), ('듯하다 지난', 0.9663), ('나에게 학기는', 0.9659), ('편이었다 가늘고', 0.9658)]\n",
      "[('같았다 나에게 학기는', 0.9697), ('감동했다 주옥같은 구절들이', 0.9685), ('나는 감동했다 주옥같은', 0.9681), ('듯하다 지난 3주는', 0.968), ('바로 정세랑이었다 시선으로부터', 0.9676)]\n",
      "102.2403 sec\n",
      "보험 속의 경제학 (보험, 경제를 살리다)\n",
      "[('폐결핵으로', 0.9696), ('비롯된다', 0.9692), ('살아가야', 0.9692), ('모자수의', 0.9686), ('파친코라는', 0.9685)]\n",
      "[('곳으로 상징된다', 0.9711), ('죽었다 그는', 0.9709), ('비롯된다 바로', 0.9706), ('대중오락이다 파친코라는', 0.9705), ('조선이 아닌', 0.9705)]\n",
      "[('있다 또한 아픈', 0.9728), ('재외동포들의 심볼이 되었다', 0.9725), ('고한수를 받아들이며 양진과', 0.9722), ('전에 죽었다 그는', 0.9721), ('도박성 대중오락이다 파친코라는', 0.9719)]\n",
      "107.8393 sec\n",
      "브람스를 좋아하세요\n",
      "[('점이다', 0.9655), ('일기뿐만', 0.9653), ('작품이라', 0.9649), ('것은', 0.9646), ('것이다', 0.9644)]\n",
      "[('것이다 결론적으로', 0.9715), ('때문이다 이런', 0.9686), ('살아가기에 니나의', 0.967), ('있다 이들', 0.9669), ('슈타인의 일기뿐만', 0.9667)]\n",
      "[('것이다 결론적으로 작가는', 0.9708), ('때문이다 이런 태도가', 0.9699), ('행각이었을 것이다 결론적으로', 0.9695), ('것이다 소설은 니나라는', 0.9689), ('때문이다 허나 니나의', 0.9687)]\n",
      "120.5747 sec\n",
      "베네치아에서의 죽음\n",
      "[('때문이었다', 0.9683), ('조이스의', 0.9682), ('분투하는가', 0.9682), ('매력적인', 0.9681), ('신부의', 0.9681)]\n",
      "[('때문이었다 하지만', 0.9717), ('읽었다 에블린', 0.9707), ('소설들 가운데', 0.9701), ('은총 에서의', 0.9701), ('율리시스에 이르러', 0.9701)]\n",
      "[('빛났기 때문이었다 하지만', 0.9721), ('작가들이 있기 때문이다', 0.9716), ('있기 때문이다 문체의', 0.9716), ('조이스는 율리시스에 이르러', 0.9715), ('에서의 스산하고 기괴한', 0.9715)]\n",
      "76.7523 sec\n",
      "인어가 잠든 집 (人魚の眠る家)\n",
      "[('돈키호테의', 0.9702), ('추락하고만다', 0.9702), ('1605년과', 0.9701), ('구닥다리라', 0.9694), ('마땅하다는', 0.9694)]\n",
      "[('있다 돈키호테의', 0.9734), ('때문이다 돈키호테의', 0.9733), ('돈키호테는 고릿적의', 0.9729), ('뿐이고 돈키호테의', 0.9725), ('있다 돈키호테가', 0.9722)]\n",
      "[('놓여 있다 돈키호테의', 0.9753), ('때문이다 돈키호테의 문체는', 0.9748), ('수두룩하기 때문이다 돈키호테의', 0.9746), ('있다 돈키호테의 사유력은', 0.9746), ('것이다 돈키호테는 읽을만한', 0.9737)]\n",
      "95.3903 sec\n",
      "노자 (자연과 더불어 세계와 소통하다)\n",
      "[('2등', 0.9666), ('1등', 0.9666), ('같다', 0.9665), ('중요하다', 0.9664), ('전달한다', 0.9663)]\n",
      "[('같다 1등과', 0.9701), ('때문이다 특히나', 0.9698), ('전달한다 하지만', 0.9692), ('한다 2등', 0.9688), ('컨셉 때문이', 0.9686)]\n",
      "[('것이다 대부분 창업가들은', 0.972), ('있다 특히 배민은', 0.9711), ('말인 같다 1등과', 0.9706), ('것이다 이런 배민을', 0.9702), ('판단하기 때문이다 특히나', 0.9702)]\n",
      "97.7080 sec\n",
      "혼자가 좋은데 혼자라서 싫다 (혼자라는그고독과처절함속에서도누구보다기꺼이멋지게살아가고있는당신에게)\n",
      "[('포기하면', 0.9745), ('머물렀다', 0.9743), ('상황이었다', 0.9742), ('읽어', 0.9742), ('살아가게', 0.9742)]\n",
      "[('상황이었다 최근', 0.9769), ('살아가게 된다', 0.9766), ('상곤의 대화였다', 0.9766), ('실패하게 된다', 0.9765), ('대화였다 단순히', 0.976)]\n",
      "[('상황이었다 최근 후루룩', 0.9789), ('있다 책은 우리가', 0.9783), ('요즘이었다 워커 홀릭의', 0.9783), ('사람을 보게 된다', 0.978), ('있다 최근에 나의', 0.9772)]\n",
      "110.1819 sec\n",
      "루쉰전집 2: 외침 방황 (외침, 방황)\n",
      "[('것들로', 0.968), ('그들로', 0.9678), ('말이다', 0.9673), ('것은', 0.9672), ('아니다', 0.9672)]\n",
      "[('것이다 2차', 0.9703), ('했다 나를', 0.9692), ('것이다 명이', 0.9692), ('파반느 수많은', 0.9691), ('정답은 아니다', 0.969)]\n",
      "[('같았다 그렇게 나의', 0.9708), ('것만이 정답은 아니다', 0.9707), ('보였을 것이다 2차', 0.9707), ('공부를 잘했다 사교성도', 0.9706), ('했다 나를 좋아한다는', 0.9705)]\n",
      "94.3979 sec\n",
      "962.7046 sec\n"
     ]
    }
   ],
   "source": [
    "bert_b = TransformerDocumentEmbeddings('klue/roberta-base')\n",
    "total_start = time.time()\n",
    "for i in doc_list:\n",
    "    print(data['title'][i[0]])\n",
    "    keyBERT_model(bert_b, i[1])\n",
    "print(f\"{time.time()-total_start:.4f} sec\") # 수행시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8f823e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kiwipiepy in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: kiwipiepy-model~=0.16 in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from kiwipiepy) (0.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from kiwipiepy) (1.24.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from kiwipiepy) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\liber\\anaconda3\\envs\\fivecart\\lib\\site-packages (from tqdm->kiwipiepy) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kiwipiepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "956ba82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "kiwi = Kiwi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4509ef18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그때 보잉 기기 좌석 년 자신 회고 와타나베 독백 자신 속마음 고백 듯 어조 이야기 시작 과거 초원 와타나베 곁 나오코 여자 나오코 자신 그림자 고백 도로시 오즈 마법사 양철 인간 공허감 와타나베 희망 말 한마디 희망 고문 수 자신 갈구 이 자신 기억 부탁 자신 세상 숨 사실 세상 일부 존재 것 것 기억 시간 나오코 죽음 이후 와타나베 시작 단순 사랑 주제 이야기 요약 것 소설 핵심 생 사 연속 때문 소설 전반 주인공 결여 삶 와타나베 기숙사 선배 나가 사 도덕 결여 삶 점 눈 점 와타나베 지옥 삶 생각 나오코 정신 문제 요양소 레이코 음모 남편 딸 결별 자신 아이 주인공 와타나베 나오코 살 기즈키 아이 와타나베 절친 나오코 남자 친구 나오코 이후 말 때 자신 느낌 말 것 정신 문제 결국 생 마감 와타나베 기즈키 나오코 소설 무결 사람 세상 사람 극복 사람 존재 뿐 소설 사람 미도리 미도리 와타나베 대학교 학우 날 와타나베 음식점 미도리 와타나베 말투 호감 감정 발전 인상 모습 미도리 그림자 어머니 나이 세상 아버지 딸 관심 미도리 앞 나오코 관계 표류 와타나베 닻 사랑 나오코 수 용기 복 작가 말 와타나베 나오코 미도리 사람 채 어찌저찌 세상 것 진심 사랑 이 존재 소멸 과정 절망 죽음 확정 사실 삶 속 죽음 대극 일부 존재 곁 도움 기즈키 와타나베 나오코 레이코 요양소 사람 도우 것 미도리 와타나베 삶 죽음 존재 죽음 매몰 그림자 곳 결국 자신 블랙홀 잠식 것 허무 필자 이야기 처음 것 재수 학원 자습 실 허리 고개 주위 모두 석상 책상 책 공부 수 숨 책 학원 너머 나오코 초원 상상 산들바람 억새풀 몸 나오코 머릿결 책장 나오코 소설 속 죽음 등장인물 결과 것 활자 존재 책 때 말 자신 행간 숨 자신 이야기 때 번 책장 수 행복 경험 것 터 격변 현대 사회 정적 텍스트 역할 잠 고요 새벽 시간 하루키 노르웨이 숲 나오코 브람스 교향곡 번 우울 인생 서로 의지 앞 것 서로 서로 존재 것 기억'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc = kiwi.analyze(doc_list[0][1])\n",
    "#명사 뽑기\n",
    "tokenized_nouns = ' '.join([i[0] for word in tokenized_doc for i in word[0] if i[1].startswith('NN')])\n",
    "tokenized_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca9273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noun_tokenize(doc):\n",
    "    tokenized_doc = kiwi.analyze(doc)\n",
    "    tokenized_nouns = ' '.join([i[0] for word in tokenized_doc for i in word[0] if i[1].startswith('NN')])\n",
    "    return tokenized_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b21fe1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyBERT_model_noun(modelname, doc):\n",
    "    start = time.time()\n",
    "    kw_model = KeyBERT(model=modelname)\n",
    "    tokenized_doc = kiwi.analyze(doc)\n",
    "    tokenized_nouns = ' '.join([i[0] for word in tokenized_doc for i in word[0] if i[1].startswith('NN')])\n",
    "    keywords_1 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "    keywords_2 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(2, 2), stop_words=None)\n",
    "    keywords_3 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(3, 3), stop_words=None)\n",
    "    print(keywords_1)\n",
    "    print(keywords_2)\n",
    "    print(keywords_3)\n",
    "    print(f\"{time.time()-start:.4f} sec\") # 수행시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aa4653c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('와타나베', 0.7425), ('나오코', 0.7285), ('무결', 0.7222), ('허무', 0.7128), ('레이코', 0.712)]\n",
      "[('와타나베 사랑', 0.7863), ('와타나베 음식점', 0.7822), ('와타나베 나오코', 0.7762), ('와타나베 죽음', 0.7725), ('와타나베 희망', 0.7724)]\n",
      "[('표류 와타나베 사랑', 0.7977), ('회고 와타나베 독백', 0.796), ('미도리 와타나베 죽음', 0.7917), ('공허감 와타나베 희망', 0.7908), ('와타나베 사랑 나오코', 0.7878)]\n",
      "22.7872 sec\n"
     ]
    }
   ],
   "source": [
    "keyBERT_model(roberta_s, tokenized_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be82c7d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "복덕방\n",
      "[('와타나베', 0.7425), ('나오코', 0.7285), ('무결', 0.7222), ('허무', 0.7128), ('레이코', 0.712)]\n",
      "[('와타나베 사랑', 0.7863), ('와타나베 음식점', 0.7822), ('와타나베 나오코', 0.7762), ('와타나베 죽음', 0.7725), ('와타나베 희망', 0.7724)]\n",
      "[('표류 와타나베 사랑', 0.7977), ('회고 와타나베 독백', 0.796), ('미도리 와타나베 죽음', 0.7917), ('공허감 와타나베 희망', 0.7908), ('와타나베 사랑 나오코', 0.7878)]\n",
      "22.7102 sec\n",
      "\n",
      "한국의 능력주의 (한국인이 기꺼이 참거나 죽어도 못 참는 것에 대하여)\n",
      "[('솓구', 0.7486), ('순리자', 0.7363), ('안정감', 0.7237), ('이것저것', 0.7192), ('작정', 0.7187)]\n",
      "[('마음 솓구', 0.777), ('창피 순리자', 0.7636), ('솓구 모습', 0.7555), ('순리자 모습', 0.7529), ('설명 얘기', 0.7527)]\n",
      "[('인정 마음 솓구', 0.7894), ('순리자 모습 이야기', 0.7884), ('얘기 창피 순리자', 0.7857), ('순리 세상 설명', 0.7805), ('자신 일시 안정감', 0.7799)]\n",
      "9.5780 sec\n",
      "\n",
      "모든 관계는 말투에서 시작된다(10만 부 기념 스페셜 에디션) (기분 좋은 사람으로 기억되는 사소한 습관)\n",
      "[('상태', 0.7265), ('해파리', 0.7212), ('박서련', 0.7137), ('기대', 0.7095), ('실질', 0.7083)]\n",
      "[('텔레파시 생각', 0.7503), ('주옥 구절', 0.7458), ('정말 상태', 0.7386), ('시간 이번', 0.7349), ('기대 실망', 0.7328)]\n",
      "[('박서련 박상영 백수', 0.7687), ('불안 마음 진통제', 0.7677), ('하늘 텔레파시 생각', 0.7594), ('마음 진통제 영양제', 0.7579), ('감동 주옥 구절', 0.7573)]\n",
      "22.6829 sec\n",
      "\n",
      "장자 (낙천적 허무주의자의 길)\n",
      "[('선자', 0.7486), ('양진', 0.74), ('파친코', 0.7336), ('생활력', 0.7323), ('삼대', 0.7304)]\n",
      "[('파친코 선자', 0.781), ('선자 모순', 0.7751), ('선자 위치', 0.774), ('일대기 소설', 0.7681), ('파친코 일제', 0.765)]\n",
      "[('선자 이삭 관계', 0.8009), ('양진 선자 운명', 0.7978), ('파친코 배우자 서사', 0.7977), ('파친코 사업 이후', 0.7951), ('가장 건강 선자', 0.7913)]\n",
      "29.7927 sec\n",
      "\n",
      "닫힌 방 악마와 선한 신 (Huis Clos)\n",
      "[('고유', 0.7017), ('효과', 0.7016), ('일종', 0.6998), ('로맹', 0.6994), ('종국', 0.6988)]\n",
      "[('의미 문학', 0.7334), ('변칙 아인', 0.7306), ('줄거리 전개', 0.7303), ('파운틴헤드 의미', 0.7242), ('파운틴헤드 싯다르타', 0.7223)]\n",
      "[('파운틴헤드 의미 문학', 0.7682), ('가리의 변칙 아인', 0.7627), ('시점 줄거리 전개', 0.7574), ('로맹 가리의 변칙', 0.7568), ('자전 소설 삽입', 0.7554)]\n",
      "31.9402 sec\n",
      "\n",
      "돈은 좋지만 재테크는 겁나는 너에게 (혼자서는 막막한 20대에게 뿅글이가 알려주는 돈을 다루고 불리는 비밀)\n",
      "[('에블린', 0.7876), ('에블', 0.7729), ('더블린', 0.7668), ('정취', 0.756), ('만큼', 0.743)]\n",
      "[('인상 에블린', 0.8216), ('더블린 정취', 0.8121), ('에블린 마지막', 0.8111), ('더블린 이야기', 0.8021), ('유희 더블린', 0.7956)]\n",
      "[('에블린 마지막 장면', 0.8424), ('하숙집 인상 에블린', 0.8314), ('인상 에블린 마지막', 0.8268), ('장면 에블 직전', 0.8245), ('에블린 하숙집 인상', 0.8235)]\n",
      "19.2507 sec\n",
      "\n",
      "왜 일하는가 (지금 당신이 가장 뜨겁게 물어야 할 첫 번째 질문)\n",
      "[('어물렁대', 0.739), ('도스토옙스키', 0.7389), ('세르반테스', 0.7379), ('대목', 0.7242), ('고골', 0.7219)]\n",
      "[('고골 도스토옙스키', 0.7856), ('세르반테스 자신', 0.7855), ('키하노 세르반테스', 0.7726), ('비판 세르반테스', 0.771), ('세르반테스 인물', 0.7703)]\n",
      "[('키하노 세르반테스 자신', 0.8009), ('플로베르 고골 도스토옙스키', 0.8007), ('사상 키하노 세르반테스', 0.796), ('세르반테스 열중 모습', 0.7935), ('사상 세르반테스 돈키호테', 0.7933)]\n",
      "21.3605 sec\n",
      "\n",
      "우리가 빛의 속도로 갈 수 없다면 (김초엽 소설)\n",
      "[('획기적', 0.732), ('중요', 0.7235), ('이번', 0.7213), ('브랜딩', 0.721), ('페르소나', 0.7191)]\n",
      "[('수치 중요', 0.7655), ('성과 중요', 0.7652), ('강조 부분', 0.7552), ('민족 브랜딩', 0.7532), ('창업가 진짜', 0.753)]\n",
      "[('이벤트 소비 중심', 0.8053), ('창업 수업 강조', 0.7925), ('소비자 사업 중요', 0.7923), ('생각 대부분 창업가', 0.7854), ('창업가 진짜 소비자', 0.7843)]\n",
      "22.6640 sec\n",
      "\n",
      "미디어 알고리즘의 욕망 (자동화된 미디어는 우리의 일상을 어떻게 바꾸는가)\n",
      "[('챕터', 0.794), ('오랜만', 0.7772), ('중요', 0.7636), ('느낌', 0.7631), ('회의감', 0.7611)]\n",
      "[('경험 챕터', 0.8185), ('대부분 챕터', 0.8153), ('사람 챕터', 0.8121), ('챕터 챕터', 0.8058), ('지푸라기 태도', 0.8016)]\n",
      "[('경우 대부분 챕터', 0.8261), ('대부분 챕터 챕터', 0.8225), ('지푸라기 프로젝트 진행', 0.8195), ('용기 경험 챕터', 0.8195), ('이해 사람 챕터', 0.8146)]\n",
      "21.3977 sec\n",
      "\n",
      "파과 (구병모 장편소설)\n",
      "[('왈가닥', 0.7584), ('만큼', 0.7403), ('때문', 0.739), ('화장', 0.7383), ('애초', 0.7346)]\n",
      "[('왈가닥 성격', 0.7793), ('아이 왈가닥', 0.7764), ('가치 세상', 0.7717), ('가치 자신', 0.7658), ('화장 외출', 0.7613)]\n",
      "[('파반느 물음표 이야기', 0.8075), ('허구 세계 때문', 0.8012), ('의미 가치 자신', 0.793), ('기준 가치 세상', 0.7912), ('사람 이야기 자신', 0.7903)]\n",
      "15.0323 sec\n",
      "\n",
      "216.4142 sec\n"
     ]
    }
   ],
   "source": [
    "roberta_s = TransformerDocumentEmbeddings('klue/roberta-small')\n",
    "total_start = time.time()\n",
    "for i in doc_list:\n",
    "    print(data['title'][i[0]])\n",
    "    keyBERT_model_noun(roberta_s, i[1])\n",
    "    print()\n",
    "print(f\"{time.time()-total_start:.4f} sec\") # 수행시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ce0892a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyBERT_model_noun_maxsum(modelname, doc):\n",
    "    start = time.time()\n",
    "    tokenized_doc = kiwi.analyze(doc)\n",
    "    kw_model = KeyBERT(model=modelname)\n",
    "    tokenized_nouns = ' '.join([i[0] for word in tokenized_doc for i in word[0] if i[1].startswith('NN')])\n",
    "    keywords_1 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(1, 1),use_maxsum=True, nr_candidates=20, stop_words=None)\n",
    "    keywords_2 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(2, 2),use_maxsum=True, nr_candidates=20, stop_words=None)\n",
    "    keywords_3 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(3, 3),use_maxsum=True, nr_candidates=20, stop_words=None)\n",
    "    print(keywords_1)\n",
    "    print(keywords_2)\n",
    "    print(keywords_3)\n",
    "    print(f\"{time.time()-start:.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c9968c9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "바르톨로메는 개가 아니다 (라헐 판 코에이 장편소설)\n",
      "[('회고', 0.7038), ('처음', 0.7073), ('어찌저찌', 0.7101), ('공허감', 0.7116), ('와타나베', 0.7425)]\n",
      "[('학원 자습', 0.7495), ('작가 와타나베', 0.7507), ('공허감 와타나베', 0.7626), ('와타나베 기즈키', 0.7628), ('와타나베 나오코', 0.7762)]\n",
      "[('산들바람 억새풀 나오코', 0.7761), ('인간 공허감 와타나베', 0.7766), ('작가 와타나베 나오코', 0.7785), ('와타나베 음식점 미도리', 0.7842), ('공허감 와타나베 희망', 0.7908)]\n",
      "24.0272 sec\n",
      "\n",
      "글로벌 거지 부부 (국적 초월, 나이 초월, 상식 초월, 9살 연상연하 커플의 무일푼 여행기)\n",
      "[('내용', 0.7009), ('소개', 0.7025), ('안정감', 0.7237), ('순리자', 0.7363), ('솓구', 0.7486)]\n",
      "[('내용 내용', 0.7399), ('이상 순리자', 0.7406), ('순리자 자신', 0.7408), ('세상 설명', 0.7418), ('시간 투자', 0.7517)]\n",
      "[('처음 한마디 느낌', 0.7673), ('안정감 자위 합리', 0.7695), ('발전 시간 투자', 0.7703), ('창피 순리자 모습', 0.7738), ('방법 설명 얘기', 0.7775)]\n",
      "10.5168 sec\n",
      "\n",
      "미스 플라이트 (박민정 장편소설)\n",
      "[('공허', 0.6997), ('주말', 0.7), ('시점', 0.7006), ('박상영', 0.7037), ('덧니', 0.7079)]\n",
      "[('공허 불안', 0.7229), ('결말 덧니', 0.7242), ('이야기 전개', 0.7245), ('일과 모멸감', 0.7292), ('주옥 구절', 0.7458)]\n",
      "[('주말 일과 모멸감', 0.7528), ('정세랑 덧니 구절', 0.7544), ('공허 불안 마음', 0.7554), ('본가 혼자 현실', 0.7566), ('단편집 출간 제안', 0.7569)]\n",
      "24.0374 sec\n",
      "\n",
      "보험 속의 경제학 (보험, 경제를 살리다)\n",
      "[('가능', 0.7199), ('폐결핵', 0.7199), ('일대기', 0.7219), ('여유', 0.7264), ('파친코', 0.7336)]\n",
      "[('선자 세상', 0.7537), ('이삭 폐결핵', 0.755), ('심볼 파친코', 0.7552), ('이야기 이전', 0.7552), ('생활 선자', 0.756)]\n",
      "[('일대기 소설 양진', 0.7852), ('집안 삼대 파친코', 0.787), ('파친코 이름 게임', 0.7876), ('욕망 선자 모순', 0.7884), ('가장 건강 선자', 0.7913)]\n",
      "30.6676 sec\n",
      "\n",
      "브람스를 좋아하세요\n",
      "[('가리의', 0.6902), ('파운틴헤드', 0.6918), ('이성', 0.6943), ('싯다르타', 0.6946), ('안온', 0.6976)]\n",
      "[('유일 방법', 0.7171), ('긍정 효과', 0.7183), ('파운틴헤드 싯다르타', 0.7223), ('파운틴헤드 의미', 0.7242), ('줄거리 전개', 0.7303)]\n",
      "[('인위 인간 이성', 0.7416), ('의미 문학 작품', 0.7459), ('니나 자전 소설', 0.7493), ('파운틴헤드 싯다르타 이반', 0.7543), ('로맹 가리의 변칙', 0.7568)]\n",
      "32.4803 sec\n",
      "\n",
      "베네치아에서의 죽음\n",
      "[('피네', 0.7375), ('만큼', 0.743), ('정취', 0.756), ('더블린', 0.7668), ('에블린', 0.7876)]\n",
      "[('배치 강세', 0.7744), ('문학 갈래', 0.7764), ('예술 더블린', 0.7793), ('율리시스 피네', 0.7845), ('에블린 하숙집', 0.7943)]\n",
      "[('경야 초반부 데뷔작', 0.8099), ('초상 율리시스 피네', 0.8112), ('조이스 문학 자리', 0.8155), ('조이스 아일랜드 더블린', 0.8206), ('에블린 하숙집 인상', 0.8235)]\n",
      "20.5102 sec\n",
      "\n",
      "인어가 잠든 집 (人魚の眠る家)\n",
      "[('놀음', 0.7003), ('만큼', 0.7033), ('대목', 0.7242), ('세르반테스', 0.7379), ('어물렁대', 0.739)]\n",
      "[('내용 전개', 0.7396), ('가치 대목', 0.7398), ('산초 대화', 0.7448), ('돈키호테 어물렁대', 0.7473), ('키하노 세르반테스', 0.7726)]\n",
      "[('역동 측면 세르반테스', 0.7663), ('산초 대화 서술', 0.7711), ('의미 이야기 소설', 0.7756), ('어물렁대 가치 의심', 0.7806), ('세르반테스 돈키호테 어물렁대', 0.7872)]\n",
      "22.5880 sec\n",
      "\n",
      "노자 (자연과 더불어 세계와 소통하다)\n",
      "[('퍼스널', 0.7086), ('부채', 0.7089), ('강조', 0.7118), ('쿠팡이츠', 0.7164), ('페르소나', 0.7191)]\n",
      "[('기업 마케팅', 0.7415), ('배미 창업가', 0.7434), ('필요 획기적', 0.7438), ('대부분 창업가', 0.7464), ('자랑 이벤트', 0.7481)]\n",
      "[('배달 민족 브랜딩', 0.7735), ('기업 이미지 팝업', 0.777), ('막내 자랑 이벤트', 0.779), ('배미 창업가 진짜', 0.7812), ('생각 대부분 창업가', 0.7854)]\n",
      "23.9449 sec\n",
      "\n",
      "혼자가 좋은데 혼자라서 싫다 (혼자라는그고독과처절함속에서도누구보다기꺼이멋지게살아가고있는당신에게)\n",
      "[('가지', 0.7514), ('일반', 0.7518), ('지푸라기', 0.7569), ('글렌', 0.7586), ('회의감', 0.7611)]\n",
      "[('회의감 스탠스', 0.7758), ('줄거리 도서관', 0.7764), ('성곤 대화', 0.7796), ('지푸라기 프로젝트', 0.7911), ('챕터 챕터', 0.8058)]\n",
      "[('예전 모습 내용', 0.8002), ('성곤 대화 의문', 0.8034), ('방법 지푸라기 태도', 0.8054), ('단편 소설 독서', 0.8087), ('대부분 챕터 챕터', 0.8225)]\n",
      "22.3090 sec\n",
      "\n",
      "루쉰전집 2: 외침 방황 (외침, 방황)\n",
      "[('비교', 0.7225), ('따위', 0.7239), ('파반느', 0.7246), ('의미', 0.7299), ('왈가닥', 0.7584)]\n",
      "[('허구 세계', 0.7527), ('파반느 물음표', 0.7579), ('의미 가치', 0.7595), ('외출 거울', 0.7607), ('왈가닥 성격', 0.7793)]\n",
      "[('느낌 얼굴 변화', 0.7819), ('자신 사랑 각자', 0.7846), ('나이 이상 의미', 0.7861), ('아이 왈가닥 성격', 0.7878), ('파반느 물음표 이야기', 0.8075)]\n",
      "16.0918 sec\n",
      "227.1767 sec\n"
     ]
    }
   ],
   "source": [
    "roberta_s = TransformerDocumentEmbeddings('klue/roberta-small')\n",
    "total_start = time.time()\n",
    "for i in doc_list:\n",
    "    print(data['title'][i[0]])\n",
    "    keyBERT_model_noun_maxsum(roberta_s, i[1])\n",
    "    print()\n",
    "print(f\"{time.time()-total_start:.4f} sec\") # 수행시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "54e9bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyBERT_model_noun_mmr(modelname, doc):\n",
    "    start = time.time()\n",
    "    tokenized_doc = kiwi.analyze(doc)\n",
    "    kw_model = KeyBERT(model=modelname)\n",
    "    tokenized_nouns = ' '.join([i[0] for word in tokenized_doc for i in word[0] if i[1].startswith('NN')])\n",
    "    keywords_1 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(1, 1),use_mmr=True,diversity=0.7, stop_words=None)\n",
    "    keywords_2 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(2, 2),use_mmr=True,diversity=0.7, stop_words=None)\n",
    "    keywords_3 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(3, 3),use_mmr=True,diversity=0.7, stop_words=None)\n",
    "    print(keywords_1)\n",
    "    print(keywords_2)\n",
    "    print(keywords_3)\n",
    "    print(f\"{time.time()-start:.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "938d0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyBERT_model_noun_mmr_whole(model, doc):\n",
    "    start = time.time()\n",
    "    tokenized_doc = kiwi.analyze(doc)\n",
    "    kw_model = model\n",
    "    tokenized_nouns = ' '.join([i[0] for word in tokenized_doc for i in word[0] if i[1].startswith('NN')])\n",
    "    keywords_1 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(1, 1),use_mmr=True,diversity=0.3, stop_words=None)\n",
    "    keywords_2 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(2, 2),use_mmr=True,diversity=0.3, stop_words=None)\n",
    "    keywords_3 = kw_model.extract_keywords(tokenized_nouns, keyphrase_ngram_range=(3, 3),use_mmr=True,diversity=0.3, stop_words=None)\n",
    "    print(keywords_1)\n",
    "    print(keywords_2)\n",
    "    print(keywords_3)\n",
    "    print(f\"{time.time()-start:.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2beeffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "86c2bdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('챕터', 0.7513), ('이성', 0.7202), ('만큼', 0.719), ('사피엔스', 0.7134), ('문명사회', 0.7024)]\n",
      "[('자극 챕터', 0.7801), ('인상 챕터', 0.7796), ('짝짓기 챕터', 0.7749), ('사피엔스 등장', 0.7574), ('육지 영장류', 0.7454)]\n",
      "[('상상력 자극 챕터', 0.7951), ('이해 관심 중요', 0.7813), ('인류 역사 관심', 0.7782), ('농업 혁명 과학', 0.7723), ('영장류 적응 동물', 0.768)]\n",
      "20.2993 sec\n",
      "[('하이젠베르크', 0.7203), ('중요', 0.7153), ('괴팅겐', 0.7127), ('패망', 0.7064), ('사유', 0.7022)]\n",
      "[('하이젠베르크 양자', 0.7594), ('파급력 고려', 0.7444), ('인과율 개념', 0.7422), ('과학자 토론', 0.7395), ('일상생활 과학', 0.727)]\n",
      "[('파급력 숙고 하이젠베르크', 0.7841), ('학문 유리 현상', 0.7831), ('원리 탐구 과학', 0.7825), ('하이젠베르크 철학 일상생활', 0.7778), ('하이젠베르크 양자 역학', 0.7697)]\n",
      "25.9606 sec\n",
      "[('국어국문학과', 0.7309), ('년대', 0.7284), ('경험주의', 0.727), ('이리가레이', 0.7257), ('공리주의', 0.7182)]\n",
      "[('공리주의 공부', 0.78), ('공리주의 국어국문학과', 0.7749), ('국어국문학과 장재영', 0.7714), ('경험주의 주제', 0.7642), ('접근법 사용', 0.74)]\n",
      "[('공리주의 국어국문학과 장재영', 0.8016), ('공리주의 개념 경우', 0.7979), ('경험주의 주제 아래', 0.797), ('공리주의 공부 사상', 0.7935), ('라캉 가타리 사상가', 0.7835)]\n",
      "27.2213 sec\n",
      "[('도리', 0.7032), ('중요', 0.7019), ('순수', 0.6965), ('사유', 0.6908), ('나라', 0.6846)]\n",
      "[('조상 숭배', 0.7357), ('근원 때문', 0.729), ('추구 사유', 0.7277), ('융화 언급', 0.7251), ('유교 생명관', 0.7193)]\n",
      "[('조상 숭배 한국', 0.7696), ('한국 유교 관심', 0.7653), ('보존 추구 사유', 0.7624), ('융화 융화 언급', 0.7543), ('유교 생명관 도덕', 0.7514)]\n",
      "22.4606 sec\n",
      "[('횃불', 0.7198), ('라플라스', 0.7193), ('에테르', 0.716), ('자연현상', 0.6923), ('프톨레마이오스', 0.6902)]\n",
      "[('프톨레마이오스 천동설', 0.7655), ('라플라스 과학', 0.756), ('과학자 횃불', 0.7427), ('재규격화 기법', 0.736), ('양자중력 이론', 0.734)]\n",
      "[('프톨레마이오스 천동설 주장', 0.7806), ('양자 이론 설명', 0.7589), ('모형 실재 따위', 0.7588), ('자연현상 법칙 발견', 0.7584), ('라플라스 과학 결정', 0.7488)]\n",
      "95.5301 sec\n",
      "[('등등', 0.7698), ('지구', 0.762), ('때문', 0.751), ('화폐', 0.7503), ('나라', 0.7421)]\n",
      "[('지구 나라', 0.7964), ('나라 대표', 0.7948), ('인물 여야', 0.7856), ('언어 등등', 0.7855), ('지구 바퀴', 0.7832)]\n",
      "[('지구 나라 대표', 0.8345), ('축제 언어 등등', 0.8316), ('지구 바퀴 여행', 0.8262), ('역사 나라 지구', 0.8201), ('인물 여야 선정', 0.8144)]\n",
      "3.9472 sec\n",
      "[('에테르', 0.765), ('챕터', 0.7594), ('획기적', 0.7481), ('효과', 0.7318), ('페더슨이', 0.7303)]\n",
      "[('흥미 챕터', 0.7882), ('감명 챕터', 0.7812), ('왕관 에테르', 0.764), ('생명체 영향', 0.7639), ('획기적 발견', 0.761)]\n",
      "[('생각 감명 챕터', 0.803), ('왕관 에테르 초기', 0.7951), ('화학 공학과 진학', 0.7832), ('부분 관련 중요', 0.7809), ('생활 화학 화학', 0.7668)]\n",
      "12.8480 sec\n",
      "[('젬블라', 0.7322), ('주객', 0.7212), ('중요', 0.7172), ('셰이드', 0.7168), ('내용', 0.6974)]\n",
      "[('셰이드 구절', 0.7744), ('구절 관련', 0.764), ('자신 젬블라', 0.7622), ('셰이드 킨보트', 0.7612), ('셰이드 신자', 0.7581)]\n",
      "[('시인 셰이드 작품', 0.7835), ('시간 구절 관련', 0.7834), ('처음 자신 젬블라', 0.7829), ('초반부 셰이드 구절', 0.7815), ('주객 전도 양상', 0.7814)]\n",
      "13.5122 sec\n",
      "[('뒤르켐', 0.768), ('뒤르켐은', 0.768), ('터부', 0.7474), ('강조', 0.7419), ('광란', 0.7341)]\n",
      "[('에밀 뒤르켐', 0.7926), ('철저 뒤르켐', 0.7907), ('뒤르켐 자살론', 0.7883), ('사항 강조', 0.782), ('상관 이론', 0.7653)]\n",
      "[('에밀 뒤르켐 자살론', 0.8151), ('뒤르켐 자살론 논문', 0.8138), ('논문 출판 이번', 0.8035), ('사회 요인 강조', 0.7983), ('단어 거부감 언급', 0.7899)]\n",
      "18.9477 sec\n",
      "[('진가', 0.7217), ('착각', 0.717), ('분야', 0.7102), ('만큼', 0.7098), ('내용', 0.6974)]\n",
      "[('콩깍지 착각', 0.7604), ('착각 가능', 0.7543), ('주제 착각', 0.7529), ('현실 착각', 0.7485), ('내용 설명', 0.7347)]\n",
      "[('착각 가능 착각', 0.7857), ('착각 진실 착각', 0.7829), ('사람 착각 착각', 0.782), ('작가 사람 착각', 0.778), ('가족 최고 착각', 0.7768)]\n",
      "10.1968 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_noun_mmr_whole(loaded_model_klue_roberta_small, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8bcbc853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('때문', 0.9498), ('문명사회', 0.9497), ('사피엔스', 0.9475), ('과학', 0.9452), ('이상', 0.942)]\n",
      "[('생활 환경', 0.9537), ('육지 영장류', 0.9525), ('상상력 자극', 0.9518), ('문명 인간', 0.9463), ('만큼 동물', 0.9385)]\n",
      "[('반응 파악 중요', 0.9583), ('인간 부정 충동', 0.9546), ('경향 농업 혁명', 0.9545), ('영장류 적응 동물', 0.9539), ('동물 특성 육식', 0.9489)]\n",
      "37.9475 sec\n",
      "[('일상생활', 0.9523), ('이후', 0.9496), ('성균관대학교', 0.9493), ('과학', 0.9484), ('마흐', 0.9427)]\n",
      "[('지식 과학', 0.9565), ('철학 현대', 0.9541), ('현대 사회', 0.9513), ('작동 방식', 0.9508), ('철학 일상생활', 0.9437)]\n",
      "[('개최 체육 대회', 0.9615), ('정치 작동 방식', 0.9566), ('고민 고민 과학자', 0.9563), ('세계 구성 원리', 0.9548), ('시민 대량 살상', 0.9462)]\n",
      "47.7340 sec\n",
      "[('공리주의', 0.9495), ('국어국문학과', 0.947), ('접근법', 0.9444), ('장재영', 0.943), ('감수성', 0.9351)]\n",
      "[('밴담 공리주의', 0.9517), ('기준 공리주의', 0.9505), ('참조 경우', 0.9501), ('현대 사회', 0.9473), ('이래 이리가레이', 0.9272)]\n",
      "[('공리주의 입법 원칙', 0.956), ('경우 중학교 학년', 0.9555), ('기준 공리주의 관점', 0.954), ('행동 의도 방법', 0.9518), ('본인 사상 과학', 0.9388)]\n",
      "50.1740 sec\n",
      "[('번째', 0.9524), ('융화', 0.9512), ('때문', 0.9504), ('생명관', 0.9461), ('혁명', 0.9454)]\n",
      "[('생각 생각', 0.9579), ('유교 생명관', 0.9564), ('융화 융화', 0.9535), ('한국 유교', 0.9526), ('개혁 혁명', 0.9491)]\n",
      "[('사상 한국 유교', 0.9604), ('의식 개혁 혁명', 0.9523), ('한국 유교 특성', 0.9516), ('숭배 생명 존중', 0.9445), ('귀신 제사 제사', 0.9401)]\n",
      "41.9948 sec\n",
      "[('양성자', 0.9221), ('접근법', 0.917), ('골디락스', 0.9166), ('과학', 0.9157), ('정말', 0.9118)]\n",
      "[('형태 결정론', 0.9256), ('자연 자연', 0.9222), ('발전 자연', 0.9214), ('금붕어 생각', 0.9193), ('법칙 인간', 0.9029)]\n",
      "[('m이론 이론 m이론', 0.9307), ('자연 작동 방식', 0.926), ('단일 가능 역사', 0.9243), ('문제 취향 문제', 0.9201), ('법칙 어항 금붕어', 0.9112)]\n",
      "181.1091 sec\n",
      "[('때문', 0.9773), ('대표', 0.9766), ('지구', 0.9744), ('등등', 0.9712), ('기분', 0.9708)]\n",
      "[('인물 여야', 0.9813), ('역사 나라', 0.9789), ('인물 국민', 0.9787), ('대표 음식', 0.9734), ('때문 지구', 0.9728)]\n",
      "[('인물 인물 역사', 0.983), ('생각 나라 상징', 0.9813), ('국민 사용 지폐', 0.9798), ('인물 국민 존경', 0.9758), ('초상 세계 곳곳', 0.9747)]\n",
      "7.6144 sec\n",
      "[('세포막', 0.9677), ('공학과', 0.9662), ('페더슨이', 0.9626), ('시기', 0.9546), ('카이랄', 0.951)]\n",
      "[('목적 세포막', 0.9701), ('시대 획기적', 0.9664), ('에테르 노벨상', 0.9645), ('화학 시대', 0.9626), ('처음 카이랄', 0.9569)]\n",
      "[('화학 기작 연구', 0.9723), ('분자 인식 과정', 0.9682), ('왕관 에테르 약물', 0.9639), ('지금 전문 고등학생', 0.9586), ('시기 처음 카이랄', 0.9562)]\n",
      "25.2393 sec\n",
      "[('초반부', 0.9696), ('시빌', 0.9666), ('진짜', 0.9656), ('행태', 0.9623), ('이상', 0.9606)]\n",
      "[('생각 자신', 0.9725), ('소설 후반', 0.9703), ('완성 처음', 0.9669), ('나라 국왕', 0.9656), ('모습 보트', 0.9651)]\n",
      "[('셰이드 작품 자신', 0.9742), ('시간 문장 모습', 0.9718), ('충격 보트 행동', 0.971), ('반전 자체 충격', 0.9679), ('표현 독자 보트', 0.9677)]\n",
      "25.1508 sec\n",
      "[('자살론', 0.9702), ('입학', 0.9695), ('성균관대학교', 0.967), ('과학', 0.9656), ('강박증', 0.9625)]\n",
      "[('충동 자살', 0.9752), ('진로 고민', 0.9689), ('인종 자살', 0.9641), ('기후 온도', 0.9605), ('아래 공대', 0.9562)]\n",
      "[('동기 충동 자살', 0.9753), ('사이 진로 고민', 0.9687), ('결과 인간 죽음', 0.9658), ('자살 단어 거부감', 0.9594), ('시대 위상 인문학', 0.9537)]\n",
      "35.4996 sec\n",
      "[('콩깍지', 0.9629), ('때문', 0.9626), ('이후', 0.9621), ('사실', 0.9618), ('인정', 0.9576)]\n",
      "[('생각 행동', 0.9683), ('착각 인정', 0.9604), ('정답 사람', 0.9603), ('행동 사실', 0.9586), ('출신 신경', 0.9555)]\n",
      "[('착각 착각 설명', 0.9696), ('일본 소설 실망', 0.9651), ('생각 행동 사실', 0.9649), ('지식 선택 심리학', 0.964), ('심리학 평소 관심', 0.9585)]\n",
      "19.2460 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_noun_mmr_whole(loaded_model_klue_roberta_base, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8811a03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('문명사회', 0.9535), ('식충류', 0.9529), ('영장류', 0.9525), ('관심', 0.9519), ('사실', 0.9503)]\n",
      "[('내용 반면', 0.957), ('챕터 짝짓기', 0.9553), ('문명 반응', 0.9553), ('인간 인간', 0.9527), ('곤충 식충류', 0.9527)]\n",
      "[('성공 동물 생각', 0.9609), ('문명 인간 자체', 0.9598), ('매력 곤충 식충류', 0.9563), ('바다 유선 직립', 0.9556), ('챕터 챕터 챕터', 0.9468)]\n",
      "122.8800 sec\n",
      "[('과학', 0.9431), ('성균관대학교', 0.9403), ('성균관대', 0.9388), ('괴팅겐', 0.9383), ('당시', 0.9381)]\n",
      "[('기술 방식', 0.9473), ('철학 일상생활', 0.9456), ('이원 성균관대학교', 0.944), ('고민 고민', 0.9398), ('얼마 성균관대', 0.9307)]\n",
      "[('천재 과학자 현학', 0.9508), ('개념 활용 개념', 0.9476), ('모습 모습 인간', 0.9469), ('규합 연구소 개발', 0.944), ('성균관대학교 해프닝 성균관대학교', 0.9431)]\n",
      "156.0866 sec\n",
      "[('경험주의', 0.9431), ('이리가레이', 0.9392), ('단어', 0.9379), ('년대', 0.9376), ('당시', 0.9353)]\n",
      "[('가능 공리주의', 0.9486), ('공리주의 체계', 0.948), ('분야 분야', 0.946), ('논의 운동', 0.9449), ('철학 사상', 0.9425)]\n",
      "[('체계 사상 노력', 0.95), ('사용 학문 과학', 0.9497), ('원칙 서론 공리주의', 0.9493), ('대상 철학 사상', 0.9472), ('입법 해당 분야', 0.9446)]\n",
      "164.7137 sec\n",
      "[('번째', 0.9425), ('생명관', 0.942), ('문화', 0.9418), ('이유', 0.9398), ('단점', 0.9397)]\n",
      "[('관심 생각', 0.9483), ('제사 대상', 0.9474), ('근원 혈통', 0.9457), ('글자 관심', 0.945), ('가지 특징', 0.9446)]\n",
      "[('방법 세계 이해', 0.9511), ('존재 제사 조상', 0.9509), ('생각 생각 귀신', 0.9465), ('귀신 제사 귀신', 0.9463), ('번째 의리 순정', 0.9439)]\n",
      "137.3899 sec\n",
      "[('프톨레마이오스', 0.9319), ('속도', 0.9309), ('m이론', 0.9298), ('무한대', 0.9295), ('양성자', 0.9264)]\n",
      "[('m이론 이론', 0.9378), ('법칙 다음', 0.9366), ('생각 목차', 0.9361), ('위치 위치', 0.9311), ('질량 중성자', 0.9271)]\n",
      "[('생각 우주 팽창', 0.9405), ('변화 뉴턴 물리학', 0.9405), ('가능 자연 자연', 0.9401), ('조건 완전 법칙', 0.9324), ('양성자 질량 중성자', 0.9312)]\n",
      "587.4316 sec\n",
      "[('세계', 0.9695), ('역사', 0.9687), ('소개', 0.9683), ('존경', 0.9683), ('등등', 0.9681)]\n",
      "[('초상 세계', 0.9748), ('상징 나라', 0.974), ('인물 역사', 0.9739), ('역사 역사', 0.9716), ('구석구석 세상', 0.9631)]\n",
      "[('지폐 인물 인물', 0.9781), ('인물 인물 역사', 0.9773), ('지구 나라 대표', 0.9727), ('선정 선정 각국', 0.9718), ('곳곳 구석구석 세상', 0.9613)]\n",
      "24.6804 sec\n",
      "[('세포막', 0.9535), ('단어', 0.9504), ('페더슨이', 0.9483), ('독후감', 0.9475), ('모넨신', 0.9459)]\n",
      "[('화학 반응', 0.9576), ('결합 생각', 0.9554), ('시대 획기적', 0.9545), ('관여 모넨신', 0.9494), ('탄생 페더슨이', 0.9494)]\n",
      "[('생각 시대 획기적', 0.9596), ('인간 화학 반응', 0.959), ('정신 기억 나이', 0.9587), ('말씀 교수 말씀', 0.9575), ('물질 탄생 페더슨이', 0.9539)]\n",
      "82.8461 sec\n",
      "[('탈출기', 0.9514), ('시빌', 0.9502), ('목적', 0.9485), ('위치', 0.948), ('진짜', 0.9443)]\n",
      "[('주석 킨보트', 0.9547), ('구절 관련', 0.9546), ('작품 주인공', 0.953), ('이야기 주제', 0.9509), ('킨보트 진짜', 0.95)]\n",
      "[('주석 작품 작품', 0.9577), ('입맛 서술 사실', 0.9573), ('작품 주인공 주객', 0.9546), ('나라 국왕 탈출기', 0.9539), ('취급 소설 추가', 0.9523)]\n",
      "81.6272 sec\n",
      "[('자살론', 0.9519), ('단어', 0.9459), ('성균관대학교', 0.9444), ('터부', 0.9443), ('독후감', 0.9434)]\n",
      "[('자살자 사람', 0.9556), ('명성 학교', 0.9522), ('사이 관계', 0.9519), ('부족 문장력', 0.9505), ('논리 사회', 0.946)]\n",
      "[('에밀 뒤르켐 자살론', 0.9559), ('숙명 자살 내용', 0.9551), ('사람 학문 고민', 0.9546), ('온도 흥분 사이', 0.9538), ('수치 기후 온도', 0.9513)]\n",
      "115.3469 sec\n",
      "[('속도', 0.9495), ('설명', 0.9483), ('사실', 0.9469), ('관심', 0.9469), ('콩깍지', 0.9456)]\n",
      "[('착각 속도', 0.9534), ('분야 관심', 0.9526), ('사람 생각', 0.9507), ('일본 소설', 0.9495), ('활용 콩깍지', 0.9456)]\n",
      "[('소설 실망 이후', 0.9545), ('착각 사람 생각', 0.9538), ('인정 착각 가능', 0.953), ('분야 관심 만큼', 0.9516), ('착각 활용 콩깍지', 0.9482)]\n",
      "62.6028 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_noun_mmr_whole(loaded_model_klue_roberta_large, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ebfe34bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('문명사회', 0.9535), ('식충류', 0.9529), ('영장류', 0.9525), ('관심', 0.9519), ('사실', 0.9503)]\n",
      "[('내용 반면', 0.957), ('챕터 짝짓기', 0.9553), ('문명 반응', 0.9553), ('인간 인간', 0.9527), ('곤충 식충류', 0.9527)]\n",
      "[('성공 동물 생각', 0.9609), ('문명 인간 자체', 0.9598), ('매력 곤충 식충류', 0.9563), ('바다 유선 직립', 0.9556), ('챕터 챕터 챕터', 0.9468)]\n",
      "123.6592 sec\n",
      "[('과학', 0.9431), ('성균관대학교', 0.9403), ('성균관대', 0.9388), ('괴팅겐', 0.9383), ('당시', 0.9381)]\n",
      "[('기술 방식', 0.9473), ('철학 일상생활', 0.9456), ('이원 성균관대학교', 0.944), ('고민 고민', 0.9398), ('얼마 성균관대', 0.9307)]\n",
      "[('천재 과학자 현학', 0.9508), ('개념 활용 개념', 0.9476), ('모습 모습 인간', 0.9469), ('규합 연구소 개발', 0.944), ('성균관대학교 해프닝 성균관대학교', 0.9431)]\n",
      "155.3813 sec\n",
      "[('경험주의', 0.9431), ('이리가레이', 0.9392), ('단어', 0.9379), ('년대', 0.9376), ('당시', 0.9353)]\n",
      "[('가능 공리주의', 0.9486), ('공리주의 체계', 0.948), ('분야 분야', 0.946), ('논의 운동', 0.9449), ('철학 사상', 0.9425)]\n",
      "[('체계 사상 노력', 0.95), ('사용 학문 과학', 0.9497), ('원칙 서론 공리주의', 0.9493), ('대상 철학 사상', 0.9472), ('입법 해당 분야', 0.9446)]\n",
      "164.7793 sec\n",
      "[('번째', 0.9425), ('생명관', 0.942), ('문화', 0.9418), ('이유', 0.9398), ('단점', 0.9397)]\n",
      "[('관심 생각', 0.9483), ('제사 대상', 0.9474), ('근원 혈통', 0.9457), ('글자 관심', 0.945), ('가지 특징', 0.9446)]\n",
      "[('방법 세계 이해', 0.9511), ('존재 제사 조상', 0.9509), ('생각 생각 귀신', 0.9465), ('귀신 제사 귀신', 0.9463), ('번째 의리 순정', 0.9439)]\n",
      "137.8651 sec\n",
      "[('프톨레마이오스', 0.9319), ('속도', 0.9309), ('m이론', 0.9298), ('무한대', 0.9295), ('양성자', 0.9264)]\n",
      "[('m이론 이론', 0.9378), ('법칙 다음', 0.9366), ('생각 목차', 0.9361), ('위치 위치', 0.9311), ('질량 중성자', 0.9271)]\n",
      "[('생각 우주 팽창', 0.9405), ('변화 뉴턴 물리학', 0.9405), ('가능 자연 자연', 0.9401), ('조건 완전 법칙', 0.9324), ('양성자 질량 중성자', 0.9312)]\n",
      "588.2293 sec\n",
      "[('세계', 0.9695), ('역사', 0.9687), ('소개', 0.9683), ('존경', 0.9683), ('등등', 0.9681)]\n",
      "[('초상 세계', 0.9748), ('상징 나라', 0.974), ('인물 역사', 0.9739), ('역사 역사', 0.9716), ('구석구석 세상', 0.9631)]\n",
      "[('지폐 인물 인물', 0.9781), ('인물 인물 역사', 0.9773), ('지구 나라 대표', 0.9727), ('선정 선정 각국', 0.9718), ('곳곳 구석구석 세상', 0.9613)]\n",
      "24.6987 sec\n",
      "[('세포막', 0.9535), ('단어', 0.9504), ('페더슨이', 0.9483), ('독후감', 0.9475), ('모넨신', 0.9459)]\n",
      "[('화학 반응', 0.9576), ('결합 생각', 0.9554), ('시대 획기적', 0.9545), ('관여 모넨신', 0.9494), ('탄생 페더슨이', 0.9494)]\n",
      "[('생각 시대 획기적', 0.9596), ('인간 화학 반응', 0.959), ('정신 기억 나이', 0.9587), ('말씀 교수 말씀', 0.9575), ('물질 탄생 페더슨이', 0.9539)]\n",
      "82.5053 sec\n",
      "[('탈출기', 0.9514), ('시빌', 0.9502), ('목적', 0.9485), ('위치', 0.948), ('진짜', 0.9443)]\n",
      "[('주석 킨보트', 0.9547), ('구절 관련', 0.9546), ('작품 주인공', 0.953), ('이야기 주제', 0.9509), ('킨보트 진짜', 0.95)]\n",
      "[('주석 작품 작품', 0.9577), ('입맛 서술 사실', 0.9573), ('작품 주인공 주객', 0.9546), ('나라 국왕 탈출기', 0.9539), ('취급 소설 추가', 0.9523)]\n",
      "81.5600 sec\n",
      "[('자살론', 0.9519), ('단어', 0.9459), ('성균관대학교', 0.9444), ('터부', 0.9443), ('독후감', 0.9434)]\n",
      "[('자살자 사람', 0.9556), ('명성 학교', 0.9522), ('사이 관계', 0.9519), ('부족 문장력', 0.9505), ('논리 사회', 0.946)]\n",
      "[('에밀 뒤르켐 자살론', 0.9559), ('숙명 자살 내용', 0.9551), ('사람 학문 고민', 0.9546), ('온도 흥분 사이', 0.9538), ('수치 기후 온도', 0.9513)]\n",
      "114.9761 sec\n",
      "[('속도', 0.9495), ('설명', 0.9483), ('사실', 0.9469), ('관심', 0.9469), ('콩깍지', 0.9456)]\n",
      "[('착각 속도', 0.9534), ('분야 관심', 0.9526), ('사람 생각', 0.9507), ('일본 소설', 0.9495), ('활용 콩깍지', 0.9456)]\n",
      "[('소설 실망 이후', 0.9545), ('착각 사람 생각', 0.9538), ('인정 착각 가능', 0.953), ('분야 관심 만큼', 0.9516), ('착각 활용 콩깍지', 0.9482)]\n",
      "62.6505 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_noun_mmr_whole(loaded_model_klue_bert_base, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a18f8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('역사', 0.313), ('원숭이', 0.168), ('논리', 0.1628), ('산업', 0.1112), ('기대감', 0.0323)]\n",
      "[('혁명 과학', 0.4204), ('전후 관계', 0.2921), ('모리스 원숭이', 0.2265), ('내용 오늘날', 0.2066), ('도구 사용', -0.0457)]\n",
      "[('혁명 과학 혁명', 0.4292), ('관계 파악 논리', 0.2971), ('기억 부분 예측', 0.266), ('데드먼드 모리스 원숭이', 0.2236), ('오늘날 발자취 현재', 0.2232)]\n",
      "3.5899 sec\n",
      "[('성균관대학교', 0.3703), ('공학', 0.1622), ('플래카드', 0.1122), ('변화', 0.0742), ('하이젠베르크', -0.0296)]\n",
      "[('성균관대학교 해프닝', 0.3792), ('변화 기술', 0.2199), ('체육 대회', 0.1911), ('플래카드 문과', 0.1207), ('세계 두려움', 0.0401)]\n",
      "[('성균관대학교 해프닝 성균관대학교', 0.4585), ('개최 체육 대회', 0.2174), ('학생 플래카드 문과', 0.2075), ('기술 방식 변화', 0.2064), ('대부분 천재 과학자', 0.1749)]\n",
      "4.6012 sec\n",
      "[('도덕', 0.4098), ('과학', 0.2224), ('국어국문학과', 0.1756), ('오늘날', 0.0113), ('움직임', -0.117)]\n",
      "[('도덕 입법', 0.5195), ('국어국문학과 장재영', 0.1764), ('밴담 스튜어트', 0.0961), ('이름 아래', -0.0252), ('고립 분야', -0.1069)]\n",
      "[('도덕 입법 원칙', 0.5817), ('단어 때문 저자', 0.13), ('목록 대응 동기', 0.0123), ('최대 다수 최대', 0.0113), ('학문 고립 분야', -0.0236)]\n",
      "4.6379 sec\n",
      "[('숭배', 0.2534), ('한국', 0.1857), ('조명', 0.088), ('특징', 0.0037), ('마지막', -0.0101)]\n",
      "[('숭배 한국', 0.421), ('조명 제사', 0.2053), ('귀신 존재', 0.1684), ('제목 선택', 0.1358), ('특징 균형', 0.0148)]\n",
      "[('숭배 한국 유교', 0.5147), ('조명 제사 집안', 0.2725), ('귀신 제목 선택', 0.2003), ('특징 균형 작용', 0.0192), ('음식 사진 휴대폰', -0.0464)]\n",
      "3.8276 sec\n",
      "[('물리학', 0.3888), ('현대', 0.1575), ('확률', 0.0625), ('아무것', 0.0565), ('금붕어', -0.0005)]\n",
      "[('물리학 이론', 0.475), ('설계 현대', 0.3134), ('존재 답변', 0.1358), ('산산조각 블랙홀', 0.1162), ('준비 허블', -0.005)]\n",
      "[('양자 물리학 이론', 0.5082), ('존재 설계 현대', 0.3566), ('자신 세계 자신', 0.0996), ('세부 사항 가시', 0.0423), ('금붕어 엉터리 금붕어', 0.0191)]\n",
      "17.1429 sec\n",
      "[('화폐', 0.4536), ('지구', 0.1793), ('역사', 0.1588), ('축제', 0.101), ('영향력', 0.0883)]\n",
      "[('나라 지폐', 0.5196), ('구석구석 세상', 0.2798), ('인물 영향력', 0.2252), ('음식 건축물', 0.1605), ('여행 기분', 0.0464)]\n",
      "[('화폐 인물 지폐', 0.5622), ('때문 지구 나라', 0.2768), ('음식 건축물 축제', 0.2249), ('선정 선정 선정', 0.1372), ('바퀴 여행 기분', 0.0405)]\n",
      "1.1311 sec\n",
      "[('화학공학', 0.484), ('고등학생', 0.2099), ('독서', 0.1761), ('세포막', 0.0096), ('페더슨이', 0.0036)]\n",
      "[('화학공학 분자', 0.5163), ('고등학생 독서', 0.3512), ('시대 기회', 0.1619), ('원리 부분', 0.1085), ('찰스 페더슨이', 0.028)]\n",
      "[('화학 시대 기억', 0.5326), ('고등학생 독서 모임', 0.3366), ('기회 지금 전문', 0.0787), ('역할 에너지 과정', 0.0552), ('암호 번역 생성', 0.0306)]\n",
      "2.6950 sec\n",
      "[('소설', 0.324), ('기름', 0.1829), ('보트', 0.1064), ('처음', 0.0115), ('기능', -0.0158)]\n",
      "[('주석 소설', 0.4076), ('기름 분리', 0.2453), ('이유 보트', 0.1274), ('아내 시빌', 0.091), ('완성 처음', 0.0555)]\n",
      "[('주석 소설 후반', 0.4349), ('감상 기름 분리', 0.2714), ('아내 시빌 생각', 0.1222), ('보트 행동 의도', 0.1049), ('조각 때문 모두', 0.0165)]\n",
      "2.6634 sec\n",
      "[('자살론', 0.5158), ('성균관대학교', 0.1115), ('출판', 0.1021), ('시스템', 0.0643), ('아래', 0.0578)]\n",
      "[('정신병 자살', 0.5996), ('본문 성균관대학교', 0.1319), ('논문 출판', 0.127), ('시스템 아래', 0.0889), ('용어 정의', 0.0084)]\n",
      "[('자살 정신병 존재', 0.6242), ('성균관대학교 고유 학과', 0.1795), ('논문 출판 이번', 0.1436), ('진입 시스템 아래', 0.0881), ('용어 정의 시작', 0.0187)]\n",
      "3.5763 sec\n",
      "[('심리학', 0.3968), ('독서', 0.2597), ('일본', 0.0799), ('관련', 0.061), ('제한', 0.0162)]\n",
      "[('선택 심리학', 0.4812), ('부족 독서', 0.3265), ('현실 순간', 0.0504), ('복권 당첨', 0.0272), ('예방 방법', -0.0194)]\n",
      "[('신경 일본 소설', 0.54), ('지식 선택 심리학', 0.4815), ('노트 선택 제한', 0.1765), ('관심 분야 때문', 0.163), ('사실 진실 착각', 0.1608)]\n",
      "2.1039 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_noun_mmr_whole(loaded_model_distiluse_base_multilingual_cased_v1, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0e5174af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('문명', 0.2903), ('절대', 0.2103), ('하나하나', 0.1493), ('경향', 0.0654), ('표현', 0.0373)]\n",
      "[('인간 문명', 0.3805), ('육지 영장류', 0.2175), ('부분 예측', 0.1561), ('챕터 챕터', 0.1273), ('제시 다양', 0.1038)]\n",
      "[('생활 환경 변화', 0.4562), ('특성 역사 오늘날', 0.3328), ('미래 기대감 미래', 0.2928), ('인류 역사 인류', 0.2024), ('챕터 짝짓기 챕터', 0.1436)]\n",
      "3.0783 sec\n",
      "[('성균관대학교', 0.5062), ('심리', 0.1239), ('부분', 0.1174), ('칸트', 0.1111), ('영향력', 0.0657)]\n",
      "[('성균관대학교 해프닝', 0.6194), ('대화 대화', 0.2793), ('모습 모습', 0.2127), ('진리 추구', 0.1758), ('영향력 발휘', 0.0767)]\n",
      "[('성균관대학교 해프닝 성균관대학교', 0.6406), ('기반 아인슈타인 하이젠베르크', 0.367), ('종합 지적 양자', 0.2512), ('사람 세계 두려움', 0.1866), ('사회 영향력 발휘', 0.0817)]\n",
      "3.9982 sec\n",
      "[('국어국문학과', 0.3434), ('정립', 0.1464), ('물체', 0.1201), ('오늘날', 0.044), ('뒷받침', 0.0188)]\n",
      "[('공리주의 국어국문학과', 0.5493), ('유지 입법', 0.2009), ('쾌락 표현', 0.0775), ('이름 아래', 0.0579), ('분야 분야', 0.0306)]\n",
      "[('공리주의 국어국문학과 장재영', 0.6262), ('행동 양식 정리', 0.2051), ('학문 도움 년대', 0.177), ('데카르트 홉스 칸트', 0.1527), ('다양 분야 분야', 0.0311)]\n",
      "4.0529 sec\n",
      "[('생명관', 0.4124), ('시비', 0.1286), ('하나', 0.0703), ('표출', 0.0568), ('은혜', 0.0509)]\n",
      "[('유교 생명관', 0.494), ('작용 한국', 0.3014), ('부모 부모', 0.1532), ('우리나라 사대', 0.1522), ('표지 귀신', 0.1414)]\n",
      "[('숭배 유교 생명관', 0.5519), ('도덕 가치 규범', 0.2928), ('한국 역사 근원', 0.2327), ('귀신 제사 귀신', 0.183), ('부모 부모 하늘', 0.1724)]\n",
      "3.2620 sec\n",
      "[('인생관', 0.378), ('도표', 0.151), ('물음', 0.1436), ('개폐', 0.0397), ('쿼크', -0.0272)]\n",
      "[('인생관 가치관', 0.5012), ('설계 현대', 0.228), ('사람 마음', 0.188), ('등장 쿼크', 0.1284), ('귀결 만약', 0.0537)]\n",
      "[('인생관 가치관 모형', 0.5647), ('고대 이오니아 시대', 0.2469), ('붕괴 확률 예측', 0.1662), ('이론 등장 쿼크', 0.1156), ('수수께끼 회자 슬릿', 0.0576)]\n",
      "13.8274 sec\n",
      "[('상징', 0.3451), ('대표', 0.1879), ('축제', 0.183), ('사람', 0.1725), ('곳곳', 0.0651)]\n",
      "[('구석구석 세상', 0.4058), ('인물 인물', 0.287), ('지구 바퀴', 0.2115), ('나라 대표', 0.19), ('세계 곳곳', 0.0773)]\n",
      "[('인물 국민 존경', 0.4653), ('구석구석 세상 사람', 0.3625), ('세계 곳곳 구석구석', 0.3358), ('영향력 인물 여야', 0.2664), ('해당 나라 지폐', 0.2251)]\n",
      "0.9467 sec\n",
      "[('화학공학', 0.3842), ('생명체', 0.2728), ('말씀', 0.2669), ('신비', 0.1762), ('약물', 0.0499)]\n",
      "[('말씀 고등학생', 0.5098), ('페더슨이 왕관', 0.5049), ('화학 화학', 0.339), ('카이랄 단어', 0.2093), ('시대 기회', 0.1938)]\n",
      "[('공학과 진학 목표', 0.5434), ('화학 화학 부분', 0.3957), ('말씀 교수 말씀', 0.3782), ('카이랄 단어 정신', 0.2768), ('기회 지금 전문', 0.2205)]\n",
      "2.1623 sec\n",
      "[('완성', 0.2702), ('후반부', 0.1261), ('기름', 0.0882), ('영향', 0.0651), ('표현', 0.047)]\n",
      "[('국왕 탈출기', 0.3804), ('의도 입맛', 0.1855), ('작품 작품', 0.1673), ('셰이드 킨보트', 0.1458), ('셰이드 때문', 0.076)]\n",
      "[('주머니 젬블라 완성', 0.4229), ('때문 모두 본문', 0.2334), ('셰이드 신자 셰이드', 0.1993), ('셰이드 바닥 낙엽', 0.1867), ('셰이드 때문 코트', 0.1269)]\n",
      "2.0772 sec\n",
      "[('성균관대학교', 0.4721), ('존재', 0.2432), ('구분', 0.1147), ('심리', 0.1099), ('뒤르켐', 0.0496)]\n",
      "[('본문 성균관대학교', 0.5314), ('뒤르켐 논의', 0.2593), ('자살 합리', 0.1816), ('뒤르켐 불편', 0.1756), ('사회 위로', 0.0652)]\n",
      "[('본문 성균관대학교 고유', 0.5568), ('행위 직접 간접', 0.2798), ('자살자 사람 자살', 0.2125), ('요인 사회 요인', 0.211), ('뒤르켐 불편 위로', 0.1829)]\n",
      "3.0108 sec\n",
      "[('인정', 0.2954), ('착각', 0.1974), ('부담', 0.1401), ('필요', 0.1105), ('깨달음', 0.0444)]\n",
      "[('의식 착각', 0.3751), ('관점 분야', 0.2584), ('진실 불편', 0.2332), ('효용 필요', 0.1922), ('분야 때문', 0.0684)]\n",
      "[('의식 착각 활용', 0.4944), ('인정 내용 설명', 0.3336), ('분야 관심 만큼', 0.2924), ('분야 때문 정신', 0.261), ('부담 작가 사람', 0.2295)]\n",
      "1.7378 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_noun_mmr_whole(loaded_model_base, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "db3692f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('원숭이', 0.5654), ('독특', 0.4707), ('미래', 0.3872), ('바다', 0.2782), ('다람쥐', 0.1441)]\n",
      "[('분석 원숭이', 0.7523), ('통제 생각', 0.5901), ('반면 데드먼드', 0.5586), ('예측 수준', 0.5055), ('이해 미래', 0.4577)]\n",
      "[('구분 원숭이 객관', 0.7767), ('만큼 스스로 시각', 0.6507), ('신비 동시 재미', 0.6126), ('챕터 챕터 챕터', 0.4821), ('이유 다양 이유', 0.4539)]\n",
      "18.5794 sec\n",
      "[('성균관대학교', 0.6776), ('적극', 0.499), ('플래카드', 0.4336), ('추구', 0.4048), ('영향력', 0.1576)]\n",
      "[('숙고 하이젠베르크', 0.7588), ('성균관대학교 해프닝', 0.7268), ('체육 대회', 0.4587), ('대화 대화', 0.3934), ('붕괴 연쇄', 0.1354)]\n",
      "[('성균관대학교 사회 학문', 0.8038), ('무기 직감 조국', 0.6212), ('개최 체육 대회', 0.5069), ('토로 모습 모습', 0.4743), ('사회 영향력 발휘', 0.1378)]\n",
      "29.4096 sec\n",
      "[('국어국문학과', 0.6542), ('포스트모더니즘', 0.5807), ('스튜어트', 0.4375), ('라캉', 0.3407), ('경계', 0.148)]\n",
      "[('공리주의 국어국문학과', 0.7929), ('당시 데카르트', 0.5292), ('목록 미각', 0.453), ('체계 사상', 0.4356), ('분야 분야', 0.1196)]\n",
      "[('공리주의 국어국문학과 장재영', 0.8133), ('이래 이리가레이 크리스테바', 0.5259), ('지점 예시 제시', 0.5113), ('목록 미각 감각', 0.4906), ('다양 분야 분야', 0.1214)]\n",
      "31.5145 sec\n",
      "[('긍정', 0.5866), ('순수', 0.4449), ('부모', 0.4007), ('하나', 0.3364), ('외세', 0.1504)]\n",
      "[('언급 순정', 0.7538), ('관심 관심', 0.5655), ('유학 파악', 0.5231), ('번째 의리', 0.4302), ('부모 부모', 0.4154)]\n",
      "[('간소 성의 충격', 0.7995), ('관심 관심 흥미', 0.6551), ('유학 파악 문화', 0.6481), ('숭배 조상 숭배', 0.6274), ('귀신 제사 제사', 0.4923)]\n",
      "25.2145 sec\n",
      "[('궁금증', 0.6769), ('프톨레마이오스', 0.6075), ('만큼', 0.4086), ('세포', 0.3643), ('콘웨이', 0.1568)]\n",
      "[('궁금증 정력', 0.7565), ('방식 파악', 0.5448), ('우주 우주', 0.4729), ('통과 양자', 0.463), ('위치 위치', 0.1433)]\n",
      "[('입장 처음 의문', 0.7667), ('플라톤 모형 뉴턴', 0.5853), ('우주 우주 우주', 0.4943), ('아무것 사람 마음', 0.4442), ('수수께끼 회자 슬릿', 0.1507)]\n",
      "101.9374 sec\n",
      "[('구석구석', 0.6852), ('선정', 0.5477), ('등등', 0.5213), ('나라', 0.3819), ('화폐', 0.2021)]\n",
      "[('구석구석 세상', 0.7753), ('인물 인물', 0.6453), ('여야 선정', 0.557), ('나라 대표', 0.508), ('세계 곳곳', 0.2041)]\n",
      "[('곳곳 구석구석 세상', 0.7815), ('언어 등등 해당', 0.6677), ('여야 선정 선정', 0.628), ('화폐 인물 지폐', 0.616), ('역사 역사 나라', 0.5604)]\n",
      "6.2350 sec\n",
      "[('고등학생', 0.6371), ('부분', 0.4444), ('각각', 0.4086), ('에테르', 0.3881), ('약물', 0.1547)]\n",
      "[('전문 고등학생', 0.7357), ('흥미 지난주', 0.6137), ('세포막 금속', 0.611), ('화학 화학', 0.4931), ('생명체 영향', 0.4516)]\n",
      "[('분자 인식 과정', 0.7606), ('독후감 말씀 고등학생', 0.6865), ('말씀 교수 말씀', 0.5581), ('기억 나이 화학', 0.5519), ('에테르 약물 미시', 0.5311)]\n",
      "15.7346 sec\n",
      "[('주인공', 0.574), ('목격', 0.4582), ('보트', 0.4115), ('나라', 0.3121), ('영향', 0.1614)]\n",
      "[('킨보트 주석', 0.7254), ('관련 내용', 0.619), ('작품 작품', 0.5), ('때문 자처', 0.4284), ('셰이드 때문', 0.1438)]\n",
      "[('순간 감정 이유', 0.7861), ('자처 내용 의도', 0.5941), ('주석 작품 작품', 0.5904), ('셰이드 킨보트 진짜', 0.5486), ('불꽃 머리말 셰이드', 0.4436)]\n",
      "14.5996 sec\n",
      "[('성균관대학교', 0.6747), ('적극', 0.5124), ('몽유병', 0.4945), ('터부', 0.3722), ('뒤르켐', 0.1517)]\n",
      "[('본문 성균관대학교', 0.7585), ('논의 과정', 0.5887), ('자살 무수', 0.5183), ('높이 착각', 0.4693), ('사회 위로', 0.1418)]\n",
      "[('존재 본문 성균관대학교', 0.7698), ('자체 암묵 터부', 0.6251), ('뒤르켐 논의 과정', 0.608), ('자살자 사람 자살', 0.5361), ('사회 위로 의미', 0.4475)]\n",
      "22.5674 sec\n",
      "[('정신', 0.4901), ('마음', 0.4033), ('추리', 0.3987), ('보호', 0.3614), ('예방', 0.1601)]\n",
      "[('출신 신경', 0.6845), ('독서 노트', 0.5176), ('착각 착각', 0.4588), ('만큼 깊이', 0.3853), ('분야 때문', 0.1315)]\n",
      "[('반전 내용 출신', 0.7476), ('소설 추리 소설', 0.552), ('분야 관심 만큼', 0.5275), ('착각 착각 착각', 0.503), ('이후 편향 취향', 0.4276)]\n",
      "13.2280 sec\n"
     ]
    }
   ],
   "source": [
    "for i in doc_list_load:\n",
    "    keyBERT_model_noun_mmr_whole(loaded_model_all_mpnet_base_v2, i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac270aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07be72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2fb70918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바르톨로메는 개가 아니다 (라헐 판 코에이 장편소설)\n",
      "[('와타나베', 0.7425), ('공허감', 0.7116), ('산들바람', 0.6982), ('마감', 0.6952), ('하루키', 0.6865)]\n",
      "[('와타나베 사랑', 0.7863), ('학원 자습', 0.7495), ('산들바람 억새풀', 0.714), ('기즈키 나오코', 0.7089), ('요양소 사람', 0.6993)]\n",
      "[('표류 와타나베 사랑', 0.7977), ('재수 학원 자습', 0.7518), ('나오코 여자 나오코', 0.7444), ('죽음 존재 죽음', 0.7311), ('상상 산들바람 억새풀', 0.7152)]\n",
      "23.8927 sec\n",
      "\n",
      "글로벌 거지 부부 (국적 초월, 나이 초월, 상식 초월, 9살 연상연하 커플의 무일푼 여행기)\n",
      "[('솓구', 0.7486), ('순리자', 0.7363), ('안정감', 0.7237), ('설명', 0.6959), ('한마디', 0.674)]\n",
      "[('마음 솓구', 0.777), ('순리자 자신', 0.7408), ('인간 본성', 0.7148), ('행복 인간', 0.7017), ('성공 방법', 0.6886)]\n",
      "[('인정 마음 솓구', 0.7894), ('경제 시간 자유', 0.7578), ('플루 추천 도서', 0.7554), ('행복 인간 본성', 0.7402), ('사회 성공 방법', 0.728)]\n",
      "9.8814 sec\n",
      "\n",
      "미스 플라이트 (박민정 장편소설)\n",
      "[('상태', 0.7265), ('텔레파시', 0.6957), ('모멸감', 0.679), ('본가', 0.6779), ('이틀간', 0.6606)]\n",
      "[('텔레파시 생각', 0.7503), ('이야기 전개', 0.7245), ('정세랑 덧니', 0.7076), ('중반부 구절', 0.7021), ('구절 인스타', 0.6897)]\n",
      "[('박서련 박상영 백수', 0.7687), ('주말 일과 모멸감', 0.7528), ('해파리 언니 정세랑', 0.7214), ('회충 혈관 사이', 0.7043), ('인생 이야기 이틀간', 0.7033)]\n",
      "23.3718 sec\n",
      "\n",
      "보험 속의 경제학 (보험, 경제를 살리다)\n",
      "[('선자', 0.7486), ('파친코', 0.7336), ('폐결핵', 0.7199), ('마찰음', 0.7106), ('조선인', 0.6496)]\n",
      "[('파친코 선자', 0.781), ('이야기 이전', 0.7552), ('이삭 폐결핵', 0.755), ('재외 동포', 0.7193), ('의성어 구슬', 0.695)]\n",
      "[('선자 이삭 관계', 0.8009), ('폐결핵 가난 장애', 0.7801), ('양진 집안 하숙집', 0.75), ('재외 동포 심볼', 0.748), ('게임 마찰음 의성어', 0.7153)]\n",
      "30.7514 sec\n",
      "\n",
      "브람스를 좋아하세요\n",
      "[('고유', 0.7017), ('파운틴헤드', 0.6918), ('변칙', 0.6661), ('인간상', 0.6643), ('중간중간', 0.6354)]\n",
      "[('의미 문학', 0.7334), ('파운틴헤드 싯다르타', 0.7223), ('가리의 변칙', 0.7117), ('니나 니나', 0.6997), ('무라카미 하루키', 0.6427)]\n",
      "[('파운틴헤드 의미 문학', 0.7682), ('사람 긍정 효과', 0.7362), ('니나 언니 니나', 0.7174), ('헤세 싯다르타 데미안', 0.7112), ('작품 무라카미 하루키', 0.6753)]\n",
      "32.6746 sec\n",
      "\n",
      "베네치아에서의 죽음\n",
      "[('에블린', 0.7876), ('프루스트', 0.7308), ('문학가', 0.7286), ('몰매', 0.7252), ('아일랜드', 0.6849)]\n",
      "[('인상 에블린', 0.8216), ('경야 초반부', 0.761), ('연인 사이', 0.7594), ('영역 문학가', 0.7446), ('어머니 어머니', 0.6954)]\n",
      "[('에블린 마지막 장면', 0.8424), ('예술가 초상 율리시스', 0.7622), ('문장 적재적소 문장', 0.7618), ('작가 마르셀 프루스트', 0.7385), ('어머니 어머니 희망', 0.7376)]\n",
      "20.0977 sec\n",
      "\n",
      "인어가 잠든 집 (人魚の眠る家)\n",
      "[('어물렁대', 0.739), ('세르반테스', 0.7379), ('등등', 0.7196), ('내용', 0.6879), ('황금기', 0.6551)]\n",
      "[('고골 도스토옙스키', 0.7856), ('키하노 세르반테스', 0.7726), ('황금기 년대', 0.7278), ('푸쉬킨 플로베르', 0.7176), ('의무 부담', 0.6728)]\n",
      "[('키하노 세르반테스 자신', 0.8009), ('년대 초기 소설', 0.733), ('상상력 자극 이야기', 0.7291), ('가치 대목 시대', 0.7241), ('정도 의무 부담', 0.6919)]\n",
      "21.6808 sec\n",
      "\n",
      "노자 (자연과 더불어 세계와 소통하다)\n",
      "[('획기적', 0.732), ('강조', 0.7118), ('내용', 0.7), ('창업가', 0.6926), ('두루마리', 0.6742)]\n",
      "[('수치 중요', 0.7655), ('배미 창업가', 0.7434), ('획기적 발명', 0.7306), ('배미 이벤트', 0.7301), ('마케팅 홍보', 0.7165)]\n",
      "[('이벤트 소비 중심', 0.8053), ('이야기 배미 창업가', 0.7597), ('페르소나 기업 이미지', 0.7408), ('획기적 발명 기술', 0.7408), ('사람 기념일 생일', 0.7075)]\n",
      "23.0732 sec\n",
      "\n",
      "혼자가 좋은데 혼자라서 싫다 (혼자라는그고독과처절함속에서도누구보다기꺼이멋지게살아가고있는당신에게)\n",
      "[('챕터', 0.794), ('글렌', 0.7586), ('지푸라기', 0.7569), ('내용', 0.7351), ('김성곤', 0.7272)]\n",
      "[('경험 챕터', 0.8185), ('방법 지푸라기', 0.7714), ('가정 가장', 0.738), ('주인공 김성곤', 0.7354), ('경우 경우', 0.7257)]\n",
      "[('경우 대부분 챕터', 0.8261), ('절망 상황 김성곤', 0.7602), ('롤러코스터 레일 레일', 0.7434), ('사업가 글렌 굴드', 0.7379), ('추천 하루 하루', 0.7109)]\n",
      "21.7313 sec\n",
      "\n",
      "루쉰전집 2: 외침 방황 (외침, 방황)\n",
      "[('왈가닥', 0.7584), ('파반느', 0.7246), ('따위', 0.7239), ('물음표', 0.7117), ('피부', 0.7051)]\n",
      "[('왈가닥 성격', 0.7793), ('의미 가치', 0.7595), ('파반느 물음표', 0.7579), ('부모 사랑', 0.7231), ('사람 사람', 0.6915)]\n",
      "[('파반느 물음표 이야기', 0.8075), ('가치 사람 가치', 0.7559), ('자신 타인 타인', 0.7157), ('부합 성징 피부', 0.7127), ('팔다리 삐뚤빼뚤 치아', 0.697)]\n",
      "16.1321 sec\n",
      "\n",
      "223.2879 sec\n"
     ]
    }
   ],
   "source": [
    "roberta_s = TransformerDocumentEmbeddings('klue/roberta-small')\n",
    "total_start = time.time()\n",
    "for i in doc_list:\n",
    "    print(data['title'][i[0]])\n",
    "    keyBERT_model_noun_mmr(roberta_s, i[1])\n",
    "    print()\n",
    "print(f\"{time.time()-total_start:.4f} sec\") # 수행시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c500c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choiceExtract(docData):\n",
    "    print('키워드 추출을 진행하시겠습니까? y/n')\n",
    "    choice = input();\n",
    "    if(choice.lower() == 'y'):\n",
    "        try:\n",
    "            print(\"키워드 추출 중... 10~20여초 가량 소요됩니다.\")\n",
    "            keyBERT_model_noun_mmr('klue/roberta-small', docData['report_text'])\n",
    "        except extractError:\n",
    "            print(\"Extract Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b78872a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDetail(data):\n",
    "    print('세부사항을 확인할 데이터 열의 인덱스를 입력하세요')\n",
    "    idx = int(input())\n",
    "    try:\n",
    "        print(data.loc[idx])\n",
    "        choiceExtract(data.loc[idx])\n",
    "    except KeyError:\n",
    "        print(\"Key Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f6992a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def insertData(data):\n",
    "    print('추가할 독서 리뷰 저자를 입력하세요.')\n",
    "    writer = input()\n",
    "    print('추가할 도서 제목을 입력하세요')\n",
    "    title = input()\n",
    "    print('도서 저자를 입력하세요')\n",
    "    book_writer = input()\n",
    "    print('출판사를 입력하세요')\n",
    "    company = input()\n",
    "    print('도서 출간일을 입력하세요')\n",
    "    book_date = input()\n",
    "    print('독서 리뷰 본문을 입력하세요')\n",
    "    report_text = input()\n",
    "    now = datetime.datetime.now()\n",
    "    formattedDate = now.strftime(\"%Y/%m/%d\")\n",
    "    newData = pd.DataFrame({'report_writer' : [writer], 'date_writer':[formattedDate],'title' : [title], 'book_writer' : [book_writer], 'book_company':[company],\n",
    "                       'book_date':[book_date], 'report_text':[report_text]})\n",
    "    try:\n",
    "        data = pd.concat([data,newData], ignore_index = True)\n",
    "        print(\"입력 성공\")\n",
    "        print(data.loc[len(data)-1])\n",
    "        choiceExtract(data.loc[len(data)-1])\n",
    "    except insertErr:\n",
    "        print(\"insertErr\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "11c8c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchTitle(data):\n",
    "    print('1. 제목 검색/키워드 추출\\n')\n",
    "    print('키워드를 추출할 도서 제목을 입력해주세요.')\n",
    "    title = input()\n",
    "    df = data[data['title'].str.contains(title)]\n",
    "    print('검색된 데이터 개수',len(df))\n",
    "    print(df[['title', 'report_writer', 'report_text']])\n",
    "    printDetail(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "20936eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu():\n",
    "    print(\"\"\" -------------------------------------\n",
    "수행할 작업 입력\n",
    "1. 제목 검색/키워드 추출\n",
    "2. 신규 문서 추가/키워드 추출\n",
    "3. 자료 id로 검색/키워드 추출\n",
    "4. 이외 입력. 종료\n",
    "-------------------------------------\"\"\")\n",
    "    user_in = input()\n",
    "    if(user_in == '1'):\n",
    "        searchTitle(data)\n",
    "        return True;\n",
    "    elif(user_in == '2'):\n",
    "        print('2. 신규 문서 추가/키워드 추출\\n')\n",
    "        insertData(data)\n",
    "        return True;\n",
    "    elif(user_in == '3'):\n",
    "        printDetail(data)\n",
    "        return True;\n",
    "    else:\n",
    "        print('이외 입력. 종료')\n",
    "        return False;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0506af3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------------\n",
      "수행할 작업 입력\n",
      "1. 제목 검색/키워드 추출\n",
      "2. 신규 문서 추가/키워드 추출\n",
      "3. 자료 id로 검색/키워드 추출\n",
      "4. 이외 입력. 종료\n",
      "-------------------------------------\n",
      "2\n",
      "2. 신규 문서 추가/키워드 추출\n",
      "\n",
      "추가할 독서 리뷰 저자를 입력하세요.\n",
      "지구인\n",
      "추가할 도서 제목을 입력하세요\n",
      "우주인\n",
      "도서 저자를 입력하세요\n",
      "태양인\n",
      "출판사를 입력하세요\n",
      "외계인\n",
      "도서 출간일을 입력하세요\n",
      "2022/12/23\n",
      "독서 리뷰 본문을 입력하세요\n",
      "봄누 머ㅓ어\n",
      "입력 성공\n",
      "report_writer           지구인\n",
      "date_writer      2023/09/28\n",
      "title                   우주인\n",
      "book_writer             태양인\n",
      "book_company            외계인\n",
      "book_date        2022/12/23\n",
      "report_text          봄누 머ㅓ어\n",
      "Name: 1657, dtype: object\n",
      "키워드 추출을 진행하시겠습니까? y/n\n",
      "n\n",
      " -------------------------------------\n",
      "수행할 작업 입력\n",
      "1. 제목 검색/키워드 추출\n",
      "2. 신규 문서 추가/키워드 추출\n",
      "3. 자료 id로 검색/키워드 추출\n",
      "4. 이외 입력. 종료\n",
      "-------------------------------------\n",
      "4\n",
      "이외 입력. 종료\n"
     ]
    }
   ],
   "source": [
    "chk = True\n",
    "while(chk):\n",
    "    chk = menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0c51e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------------\n",
      "수행할 작업 입력\n",
      "1. 제목 검색/키워드 추출\n",
      "2. 신규 문서 추가/키워드 추출\n",
      "3. 자료 id로 검색/키워드 추출\n",
      "4. 이외 입력. 종료\n",
      "-------------------------------------\n",
      "1\n",
      "1. 제목 검색/키워드 추출\n",
      "\n",
      "키워드를 추출할 도서 제목을 입력해주세요.\n",
      "노르웨이의 숲\n",
      "검색된 데이터 개수 22\n",
      "                              title             report_writer  \\\n",
      "0                           노르웨이의 숲                       조장환   \n",
      "81                          노르웨이의 숲                       김가영   \n",
      "262                         노르웨이의 숲                       zen   \n",
      "1322                        노르웨이의 숲                        휴고   \n",
      "1442            상실의 시대(원제: 노르웨이의 숲)  유생 선배님들은 귀차니즘을 어떻게 이겨냈을까   \n",
      "1892            상실의 시대 (원제 노르웨이의 숲)                        다나   \n",
      "2721                        노르웨이의 숲                        이담   \n",
      "2983            상실의 시대 (원제 노르웨이의 숲)                        스지   \n",
      "3337   노르웨이의 숲 (세계문학전집 310,ノルウェイの森)                    이승현123   \n",
      "3469                        노르웨이의 숲                       좋은비   \n",
      "4171                        노르웨이의 숲                       이경아   \n",
      "4233                        노르웨이의 숲                        우버   \n",
      "4247                        노르웨이의 숲                        회생   \n",
      "4825                        노르웨이의 숲                     언어의정원   \n",
      "5107            상실의 시대 (원제 노르웨이의 숲)                     moana   \n",
      "5650                        노르웨이의 숲                       작가명   \n",
      "7222                        노르웨이의 숲                       책책첵   \n",
      "8057                        노르웨이의 숲                       조약돌   \n",
      "9695                        노르웨이의 숲                       닉네임   \n",
      "18527             상실의 시대:원제 노르웨이의 숲                   mengary   \n",
      "18933             상실의 시대:원제 노르웨이의 숲                      hway   \n",
      "21145                     노르웨이의 숲세트                        홀든   \n",
      "\n",
      "                                             report_text  \n",
      "0            \"그때 나는 보잉 747기기 좌석에 앉아있었다.\" 1982년에 자신을 회...  \n",
      "81        ﻿기억이란 참 이상하다. 실제로 그 속에 있을 때 나는 풍경에 아무 관심도 없...  \n",
      "262       상실의 시대라는 제목으로 익숙한 \"노르웨이의 숲\"이 비틀즈의 노래 제목인 것을...  \n",
      "1322        적지 않은 책을 읽어오면서, 읽고서 즉시 후기에 대해 이야기하며 토론을 하...  \n",
      "1442       “인간은 사회적 동물이다.” 고대 그리스의 철학자 아리스토텔레스가 남긴 말이...  \n",
      "1892      무라카미 하루키 소설은 처음이었는데, 기대를 많이 한만큼 재미있었다. 일본의 ...  \n",
      "2721       우리나라에서는 『상실의 시대』라는 제목으로 더 잘 알려진 무라카미 하루키의 ...  \n",
      "2983      책을 다 읽고 난 후의 느낌을 한 단어로 표현하자면 ‘우울함’이라고 할 수 있...  \n",
      "3337       사람은 자신의 영역 밖에 있는 일을 할 때 초인적인 힘이 나오곤 한다. 새로...  \n",
      "3469       살면서 무라카미 하루키를 두 번 경험했다. 그와의 첫 만남은 '색채가 없는 ...  \n",
      "4171      무라카미 하루키는 ‘하루키 신드롬’을 일으킬 정도로 유명한 작가고, 그의 책 ...  \n",
      "4233      <노르웨이의 숲>      무라카미 하루키의 소설을 읽어본 것은 <해변의 카프...  \n",
      "4247      무라카미 하루키는 일본 현지뿐 아니라 세계적으로도 유명하고 영향력 있는 작가이...  \n",
      "4825      사람은 모두 각자의 번뇌가 있다불교에서는 우리의 삶이란 번뇌로 가득 차 있는 ...  \n",
      "5107        우리 모두 걸어가고 있는 상실의 시대 속에서    스무 살, 성인이 된다는...  \n",
      "5650      하루키 특유의 문체나 인물에 대한 담담하면서 상세한 묘사는 좋은 책. 음울하고...  \n",
      "7222      “당신은 무엇을 상실한 채 살아가고 있나요?”  (‘상실의 시대’가 번안 제목...  \n",
      "8057      이것은 절대 연애 소설이 아니다. - 무라카미 하루키,    내가 이 책을 읽...  \n",
      "9695       임경선 작가의 「어디까지나 개인적인:내 방식으로 읽고 쓰고 생활한다는 것」을...  \n",
      "18527     각박하게 살아가는 외로운 학우분들에게 추천합니다... ^^'노르웨이의 숲'  ...  \n",
      "18933     영화에 무척 관심이 많은 나는 얼마전에 상실의 시대 포스터를 보았다.상실의 시...  \n",
      "21145      국내에서 상실의 시대란 제목으로 널리 알려진 무라카미 하루키의 대표작 노르웨...  \n",
      "세부사항을 확인할 데이터 열의 인덱스를 입력하세요\n",
      "81\n",
      "report_writer                                                  김가영\n",
      "date_writer                                             2023/08/28\n",
      "title                                                      노르웨이의 숲\n",
      "book_writer                                               무라카미 하루키\n",
      "book_company                                                   민음사\n",
      "book_date                                               2017/08/07\n",
      "report_text         ﻿기억이란 참 이상하다. 실제로 그 속에 있을 때 나는 풍경에 아무 관심도 없...\n",
      "is_classic                                                     NaN\n",
      "Name: 81, dtype: object\n",
      "키워드 추출을 진행하시겠습니까? y/n\n",
      "y\n",
      "키워드 추출 중... 10~20여초 가량 소요됩니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\liber/.cache\\torch\\sentence_transformers\\klue_roberta-small. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('와타나베', 0.4462), ('공중전화', 0.4384), ('대극', 0.4192), ('기즈키', 0.3883), ('노르웨이', 0.3674)]\n",
      "[('사람 사이', 0.5022), ('와타나베 나오코', 0.4955), ('공중전화 부스', 0.4656), ('이야기 의미', 0.4646), ('기즈키 연결', 0.4235)]\n",
      "[('와타나베 자신 구절', 0.5446), ('풍경 따위 자신', 0.5263), ('등장인물 중심 이야기', 0.518), ('조차 사람 사이', 0.4975), ('공중전화 부스 주변', 0.4797)]\n",
      "7.3877 sec\n",
      " -------------------------------------\n",
      "수행할 작업 입력\n",
      "1. 제목 검색/키워드 추출\n",
      "2. 신규 문서 추가/키워드 추출\n",
      "3. 자료 id로 검색/키워드 추출\n",
      "4. 이외 입력. 종료\n",
      "-------------------------------------\n",
      "4\n",
      "이외 입력. 종료\n"
     ]
    }
   ],
   "source": [
    "chk = True\n",
    "while(chk):\n",
    "    chk = menu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
